ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:                    input_data.index_copy_(feature_dim, feature, sparsified)
ao/ns/fx/graph_passes.py:# TODO(future PR): look into using copy_node API instead
ao/ns/fx/graph_passes.py:def _copy_node_from_a_to_c(
ao/ns/fx/graph_passes.py:        node_a_copy_name = \
ao/ns/fx/graph_passes.py:            get_new_attr_name_with_prefix(node_a.name + '_shadow_copy_')(gm_b)
ao/ns/fx/graph_passes.py:        setattr(gm_b, node_a_copy_name, node_a_obj)
ao/ns/fx/graph_passes.py:            node_a.op, node_a_copy_name, (), {}, node_a_copy_name)
ao/ns/fx/graph_passes.py:            arg_copy = _copy_node_from_a_to_c(
ao/ns/fx/graph_passes.py:            node_a_copy_name = \
ao/ns/fx/graph_passes.py:                get_new_attr_name_with_prefix(node_a.name + '_shadow_copy_')(gm_b)
ao/ns/fx/graph_passes.py:                node_a.op, node_a.target, (arg_copy,), {}, node_a_copy_name)
ao/ns/fx/graph_passes.py:            arg_copy = _copy_node_from_a_to_c(
ao/ns/fx/graph_passes.py:            node_a_copy_name = \
ao/ns/fx/graph_passes.py:                get_new_attr_name_with_prefix(node_a.name + '_shadow_copy_')(gm_b)
ao/ns/fx/graph_passes.py:                {}, node_a_copy_name)
ao/ns/fx/graph_passes.py:def _can_insert_copy_of_subgraph_a(
ao/ns/fx/graph_passes.py:    `_insert_copy_of_subgraph_a_after_input_node_c`. This usually means
ao/ns/fx/graph_passes.py:    # logic in `_insert_copy_of_subgraph_a_after_input_node_c`.
ao/ns/fx/graph_passes.py:def _insert_copy_of_subgraph_a_after_input_node_c(
ao/ns/fx/graph_passes.py:    cur_node_c = _insert_copy_of_node_a_after_input_node_c(
ao/ns/fx/graph_passes.py:        cur_node_c = _insert_copy_of_node_a_after_input_node_c(
ao/ns/fx/graph_passes.py:def _insert_copy_of_node_a_after_input_node_c(
ao/ns/fx/graph_passes.py:    def _copy_arg(arg):
ao/ns/fx/graph_passes.py:            arg = _copy_node_from_a_to_c(arg, gm_a, gm_b, graph_c)
ao/ns/fx/graph_passes.py:            new_arg = _copy_arg(norm_args[cur_idx])
ao/ns/fx/graph_passes.py:            new_kwargs[kwarg_name] = _copy_arg(kwarg_val)
ao/ns/fx/graph_passes.py:        new_mod_copy_name = \
ao/ns/fx/graph_passes.py:        setattr(gm_b, new_mod_copy_name, mod_a)
ao/ns/fx/graph_passes.py:            node_a.op, new_mod_copy_name, new_args,
ao/ns/fx/graph_passes.py:            if not _can_insert_copy_of_subgraph_a(subgraph_a, gm_a, num_non_param_args_node_a):
ao/ns/fx/graph_passes.py:                node_a_shadows_c = _insert_copy_of_subgraph_a_after_input_node_c(
ao/ns/fx/graph_passes.py:                    subgraph_a, gm_a, gm_b, node_c.name + '_shadow_copy_')
ao/ns/fx/n_shadows_utils.py:        orig_mod_copy_wrapped = create_submodule_from_subgraph(
ao/ns/fx/n_shadows_utils.py:            orig_mod_copy_wrapped, subgraph_idx, subgraph_candidate_idx,
ao/ns/fx/n_shadows_utils.py:            orig_mod_copy_wrapped = torch.ao.quantization.quantize_fx.prepare_fx(
ao/ns/fx/n_shadows_utils.py:                orig_mod_copy_wrapped, qconfig_mapping, example_inputs=example_inputs,
ao/ns/fx/n_shadows_utils.py:            orig_mod_copy_wrapped = custom_prepare_fn(
ao/ns/fx/n_shadows_utils.py:                orig_mod_copy_wrapped,
ao/ns/fx/n_shadows_utils.py:        setattr(mt, attr_name, orig_mod_copy_wrapped)
Binary file ao/nn/quantized/modules/__pycache__/conv.cpython-310.pyc matches
ao/nn/quantized/modules/conv.py:    def __deepcopy__(self, memo):
ao/nn/quantized/modules/conv.py:    def __copy__(self):
ao/nn/quantized/modules/conv.py:        return self.__deepcopy__({})
ao/quantization/observer.py:        self.min_val.copy_(min_val)
ao/quantization/observer.py:        self.max_val.copy_(max_val)
ao/quantization/observer.py:        self.min_val.copy_(torch.tensor(float("inf")))
ao/quantization/observer.py:        self.max_val.copy_(torch.tensor(float("-inf")))
ao/quantization/observer.py:        self.min_val.copy_(min_val)
ao/quantization/observer.py:        self.max_val.copy_(max_val)
ao/quantization/observer.py:        self.min_val.copy_(min_val)
ao/quantization/observer.py:        self.max_val.copy_(max_val)
ao/quantization/observer.py:                        self.min_val.copy_(val)
ao/quantization/observer.py:                        self.max_val.copy_(val)
ao/quantization/observer.py:        self.min_val.copy_(min_val)
ao/quantization/observer.py:        self.max_val.copy_(max_val)
ao/quantization/observer.py:            self.min_val.copy_(min_val)
ao/quantization/observer.py:            self.max_val.copy_(max_val)
ao/quantization/observer.py:            self.histogram.copy_(combined_histogram)
ao/quantization/observer.py:            self.min_val.copy_(combined_min)
ao/quantization/observer.py:            self.max_val.copy_(combined_max)
ao/quantization/fake_quantize.py:            self.scale.copy_(_scale)
ao/quantization/fake_quantize.py:            self.zero_point.copy_(_zero_point)
ao/quantization/fake_quantize.py:                        self.scale.copy_(val)
ao/quantization/fake_quantize.py:                        self.zero_point.copy_(val)
ao/quantization/fx/_lower_to_native_backend.py:def is_copy_node(node, modules):
ao/quantization/fx/_lower_to_native_backend.py:    for checker in [is_fixed_qparams_node, is_default_node, is_copy_node, is_general_tensor_shape_node, is_other_node]:
ao/quantization/fx/graph_module.py:    # of vanilla nn.Module.  So, we override __deepcopy__ in order
ao/quantization/fx/graph_module.py:    def __deepcopy__(self, memo):
ao/quantization/fx/graph_module.py:    # of vanilla nn.Module.  So, we override __deepcopy__ in order
ao/quantization/fx/graph_module.py:    def __deepcopy__(self, memo):
ao/quantization/fx/graph_module.py:    def __deepcopy__(self, memo):
ao/quantization/fx/graph_module.py:    def __deepcopy__(self, memo):
ao/quantization/fx/_model_report/model_report_observer.py:        self.epoch_activation_min.copy_(epoch_min_val)
ao/quantization/fx/_model_report/model_report_observer.py:        self.epoch_activation_max.copy_(epoch_max_val)
ao/quantization/fx/_model_report/model_report_observer.py:        self.min_val.copy_(min_val)
ao/quantization/fx/_model_report/model_report_observer.py:        self.max_val.copy_(max_val)
ao/quantization/fx/_model_report/model_report_observer.py:        self.percentile_batches_tracked.copy_(new_number_of_batches)
ao/quantization/fx/_model_report/model_report_observer.py:        self.average_percentile_ratio.copy_(new_ratios)
ao/quantization/fx/_model_report/model_report_observer.py:        self.constant_channels.copy_(new_constant_count)
Binary file ao/quantization/__pycache__/observer.cpython-310.pyc matches
Binary file ao/quantization/__pycache__/fake_quantize.cpython-310.pyc matches
ao/quantization/_learnable_fake_quantize.py:            self.scale.data.copy_(_scale)
ao/quantization/_learnable_fake_quantize.py:            self.zero_point.data.copy_(_zero_point)
autograd/_functions/tensor.py:            tensor.copy_(tensor)
autograd/graph.py:            packed.copy_(tensor)
Binary file autograd/__pycache__/gradcheck.cpython-310.pyc matches
Binary file autograd/__pycache__/graph.cpython-310.pyc matches
autograd/gradcheck.py:    entry.copy_(orig - v)
autograd/gradcheck.py:    entry.copy_(orig + v)
autograd/gradcheck.py:    entry.copy_(orig)
autograd/gradcheck.py:                fw_grad.copy_(u.view_as(fw_grad))
autograd/gradcheck.py:                        jacobians[i][index_o].copy_(res.reshape(-1))
autograd/gradcheck.py:                            jacobians[i][index_o][lin_idx].copy_(res.reshape(-1))
autograd/gradcheck.py:        # Clone because input may require grad, and copy_ calls resize_,
autograd/gradcheck.py:            fw_grad.copy_(u.view_as(fw_grad))
Binary file bin/protoc-3.13.0.0 matches
Binary file bin/test_edge_op_registration matches
Binary file bin/test_jit matches
Binary file bin/test_api matches
Binary file bin/test_lazy matches
_C/__init__.pyi:    def copy_(self, src: Tensor, non_blocking: _bool=False) -> Tensor: ...
_C/__init__.pyi:    def index_copy_(self, dim: _int, index: Tensor, source: Tensor) -> Tensor: ...
_C/__init__.pyi:    def index_copy_(self, dim: Union[str, ellipsis, None], index: Tensor, source: Tensor) -> Tensor: ...
_C/_VariableFunctions.pyi:def _copy_from(input: Tensor, dst: Tensor, non_blocking: _bool=False) -> Tensor: ...
_C/_VariableFunctions.pyi:def _copy_from_and_resize(input: Tensor, dst: Tensor) -> Tensor: ...
_C/_VariableFunctions.pyi:def _has_compatible_shallow_copy_type(input: Tensor, from_: Tensor) -> _bool: ...
_C/_VariableFunctions.pyi: '_convolution_mode', '_copy_from', '_copy_from_and_resize', '_ctc_loss', '_cudnn_ctc_loss',
_C/_VariableFunctions.pyi: '_fw_primal_copy', '_grid_sampler_2d_cpu_fallback', '_has_compatible_shallow_copy_type',
csrc/StorageSharing.cpp:#include <torch/csrc/copy_utils.h>
csrc/autograd/VariableTypeManual.cpp:Tensor& copy_(
csrc/autograd/VariableTypeManual.cpp:    at::redispatch::copy_(
csrc/autograd/VariableTypeManual.cpp:        new_fw_grad = self_fw_grad.copy_(src_fw_grad);
csrc/autograd/VariableTypeManual.cpp:      "copy_",
csrc/autograd/VariableTypeManual.cpp:      torch::dispatch(DispatchKey::Autograd, TORCH_FN(VariableType::copy_)));
csrc/autograd/VariableTypeManual.cpp:Tensor& copy_(
csrc/autograd/VariableTypeManual.cpp:    at::redispatch::copy_(
csrc/autograd/VariableTypeManual.cpp:      "copy_",
csrc/autograd/VariableTypeManual.cpp:          DispatchKey::ADInplaceOrView, TORCH_FN(ADInplaceOrView::copy_)));
csrc/autograd/python_variable_indexing.cpp:    at::indexing::copy_to(sliced, value);
csrc/autograd/functions/tensor.cpp:  result.copy_(grad);
csrc/autograd/functions/tensor.cpp:        grad_slice.copy_(res[i]);
csrc/autograd/python_variable.cpp:    self_real.copy_(real_);
csrc/autograd/python_variable.cpp:    self_imag.copy_(imag_);
csrc/autograd/FunctionsManual.cpp:void copy_range(variable_list& out, IndexRange range, const Tensor& t) {
csrc/autograd/FunctionsManual.cpp:void copy_range(variable_list& out, IndexRange range, at::ArrayRef<Tensor> t) {
csrc/autograd/FunctionsManual.cpp://     Before: at::zeros(input.sizes(), grad.options()).copy_(grad)
csrc/autograd/FunctionsManual.cpp://     After:  grad.new_zeros(input.sizes()).copy_(grad)
csrc/autograd/FunctionsManual.cpp:// safely scatter (`storage.as_strided(output_geometry).copy_(grad)`);
csrc/autograd/FunctionsManual.cpp:        .copy_(grad);
csrc/autograd/FunctionsManual.cpp:  result_slice.copy_(grad_slice);
csrc/autograd/FunctionsManual.cpp:        ret.diagonal(0, -2, -1).copy_(gL);
csrc/autograd/FunctionsManual.cpp:    meta_grad.narrow(-2, 0, n).narrow(-1, 0, n).copy_(A);
csrc/autograd/FunctionsManual.cpp:    meta_grad.narrow(-2, n, n).narrow(-1, n, n).copy_(A);
csrc/autograd/FunctionsManual.cpp:    meta_grad.narrow(-2, 0, n).narrow(-1, n, n).copy_(grad);
csrc/autograd/FunctionsManual.cpp:        .copy_(grad);
csrc/autograd/FunctionsManual.cpp:      input_grad.select(-1, i).copy_(v_i_grad.squeeze(-1));
csrc/autograd/FunctionsManual.cpp:      tau_grad.select(-1, i).copy_(tau_i_grad.squeeze(-1));
csrc/autograd/FunctionsManual.cpp:Tensor _to_copy_backward(
csrc/autograd/variable.cpp:    auto copy_slices = std::make_shared<CopySlices>(
csrc/autograd/variable.cpp:    set_gradient_edge(view_info.base_, {std::move(copy_slices), 0});
csrc/autograd/variable.cpp:  auto self_impl_copy = self.unsafeGetTensorImpl()->shallow_copy_and_detach(
csrc/autograd/variable.cpp:  auto self_impl_copy = self.unsafeGetTensorImpl()->shallow_copy_and_detach(
csrc/autograd/variable.cpp:      _has_compatible_shallow_copy_type(self, new_data),
csrc/autograd/variable.cpp:  self.unsafeGetTensorImpl()->shallow_copy_from(new_data.getIntrusivePtr());
csrc/autograd/variable.h:///     base[1] = var  # i.e., base[1].copy_(var)
csrc/autograd/variable.h:///     base.copy_(var)
csrc/autograd/variable.h:///     base[1] = var  # i.e., base[1].copy_(var)
csrc/autograd/variable.h:///     base.copy_(var)
csrc/autograd/variable.h:///     view.copy_(var)
csrc/autograd/variable.h:    auto data_impl_copy = data.getIntrusivePtr()->shallow_copy_and_detach(
csrc/autograd/variable.h:      auto data_impl_copy = data.getIntrusivePtr()->shallow_copy_and_detach(
csrc/autograd/variable.h:    auto data_impl_copy = data.getIntrusivePtr()->shallow_copy_and_detach(
csrc/autograd/FunctionsManual.h:void copy_range(variable_list& out, IndexRange range, const at::Tensor& t);
csrc/autograd/FunctionsManual.h:void copy_range(
csrc/autograd/FunctionsManual.h:Tensor _to_copy_backward(
csrc/autograd/generated/python_torch_functionsEverything.cpp:#include <ATen/ops/_copy_from.h>
csrc/autograd/generated/python_torch_functionsEverything.cpp:#include <ATen/ops/_copy_from_and_resize.h>
csrc/autograd/generated/python_torch_functionsEverything.cpp:#include <ATen/ops/_has_compatible_shallow_copy_type.h>
csrc/autograd/generated/python_torch_functionsEverything.cpp:static PyObject * THPVariable__copy_from(PyObject* self_, PyObject* args, PyObject* kwargs);
csrc/autograd/generated/python_torch_functionsEverything.cpp:static PyObject * THPVariable__copy_from_and_resize(PyObject* self_, PyObject* args, PyObject* kwargs);
csrc/autograd/generated/python_torch_functionsEverything.cpp:static PyObject * THPVariable__has_compatible_shallow_copy_type(PyObject* self_, PyObject* args, PyObject* kwargs);
csrc/autograd/generated/python_torch_functionsEverything.cpp:  {"_copy_from", castPyCFunctionWithKeywords(THPVariable__copy_from), METH_VARARGS | METH_KEYWORDS | METH_STATIC, NULL},
csrc/autograd/generated/python_torch_functionsEverything.cpp:  {"_copy_from_and_resize", castPyCFunctionWithKeywords(THPVariable__copy_from_and_resize), METH_VARARGS | METH_KEYWORDS | METH_STATIC, NULL},
csrc/autograd/generated/python_torch_functionsEverything.cpp:  {"_has_compatible_shallow_copy_type", castPyCFunctionWithKeywords(THPVariable__has_compatible_shallow_copy_type), METH_VARARGS | METH_KEYWORDS | METH_STATIC, NULL},
csrc/autograd/generated/python_torch_functionsEverything.cpp:// _copy_from
csrc/autograd/generated/python_torch_functionsEverything.cpp:static PyObject * THPVariable__copy_from(PyObject* self_, PyObject* args, PyObject* kwargs)
csrc/autograd/generated/python_torch_functionsEverything.cpp:    "_copy_from(Tensor input, Tensor dst, bool non_blocking=False)",
csrc/autograd/generated/python_torch_functionsEverything.cpp:  // aten::_copy_from(Tensor self, Tensor dst, bool non_blocking=False) -> Tensor
csrc/autograd/generated/python_torch_functionsEverything.cpp:  auto dispatch__copy_from = [](const at::Tensor & self, const at::Tensor & dst, bool non_blocking) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return at::_copy_from(self, dst, non_blocking);
csrc/autograd/generated/python_torch_functionsEverything.cpp:  return wrap(dispatch__copy_from(_r.tensor(0), _r.tensor(1), _r.toBool(2)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:// _copy_from_and_resize
csrc/autograd/generated/python_torch_functionsEverything.cpp:static PyObject * THPVariable__copy_from_and_resize(PyObject* self_, PyObject* args, PyObject* kwargs)
csrc/autograd/generated/python_torch_functionsEverything.cpp:    "_copy_from_and_resize(Tensor input, Tensor dst)",
csrc/autograd/generated/python_torch_functionsEverything.cpp:  // aten::_copy_from_and_resize(Tensor self, Tensor dst) -> Tensor
csrc/autograd/generated/python_torch_functionsEverything.cpp:  auto dispatch__copy_from_and_resize = [](const at::Tensor & self, const at::Tensor & dst) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return at::_copy_from_and_resize(self, dst);
csrc/autograd/generated/python_torch_functionsEverything.cpp:  return wrap(dispatch__copy_from_and_resize(_r.tensor(0), _r.tensor(1)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:        auto dispatch_index_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:          return at::index_copy_out(out, self, dim, index, source);
csrc/autograd/generated/python_torch_functionsEverything.cpp:        return wrap(dispatch_index_copy_out(_r.tensor(4), _r.tensor(0), _r.toInt64(1), _r.tensor(2), _r.tensor(3)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return self.narrow_copy_symint(dim, start, length);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_narrow_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::narrow_copy_symint_out(out, self, dim, start, length);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_narrow_copy_out(_r.tensor(4), _r.tensor(0), _r.toInt64(1), _r.toSymInt(2), _r.toSymInt(3)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:// _has_compatible_shallow_copy_type
csrc/autograd/generated/python_torch_functionsEverything.cpp:static PyObject * THPVariable__has_compatible_shallow_copy_type(PyObject* self_, PyObject* args, PyObject* kwargs)
csrc/autograd/generated/python_torch_functionsEverything.cpp:    "_has_compatible_shallow_copy_type(Tensor input, Tensor from)",
csrc/autograd/generated/python_torch_functionsEverything.cpp:  // aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool
csrc/autograd/generated/python_torch_functionsEverything.cpp:  auto dispatch__has_compatible_shallow_copy_type = [](const at::Tensor & self, const at::Tensor & from) -> bool {
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return at::_has_compatible_shallow_copy_type(self, from);
csrc/autograd/generated/python_torch_functionsEverything.cpp:  return wrap(dispatch__has_compatible_shallow_copy_type(_r.tensor(0), _r.tensor(1)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch__fw_primal_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t level) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::_fw_primal_copy_out(out, self, level);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch__fw_primal_copy_out(_r.tensor(2), _r.tensor(0), _r.toInt64(1)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch__make_dual_copy_out = [](at::Tensor out, const at::Tensor & primal, const at::Tensor & tangent, int64_t level) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::_make_dual_copy_out(out, primal, tangent, level);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch__make_dual_copy_out(_r.tensor(3), _r.tensor(0), _r.tensor(1), _r.toInt64(2)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_view_as_real_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::view_as_real_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_view_as_real_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_view_as_complex_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::view_as_complex_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_view_as_complex_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch__conj_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::_conj_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch__conj_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch__neg_view_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::_neg_view_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch__neg_view_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::as_strided_copy_symint(self, size, stride, storage_offset);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_as_strided_copy_out = [](at::Tensor out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::as_strided_copy_symint_out(out, self, size, stride, storage_offset);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_as_strided_copy_out(_r.tensor(4), _r.tensor(0), _r.symintlist(1), _r.symintlist(2), _r.toSymIntOptional(3)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch__sparse_broadcast_to_copy_out = [](at::Tensor out, const at::Tensor & self, at::IntArrayRef size) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::_sparse_broadcast_to_copy_out(out, self, size);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch__sparse_broadcast_to_copy_out(_r.tensor(2), _r.tensor(0), _r.intlist(1)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_diagonal_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::diagonal_copy_out(out, self, offset, dim1, dim2);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_diagonal_copy_out(_r.tensor(4), _r.tensor(0), _r.toInt64(1), _r.toInt64(2), _r.toInt64(3)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::expand_copy_symint(self, size, implicit);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_expand_copy_out = [](at::Tensor out, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::expand_copy_symint_out(out, self, size, implicit);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_expand_copy_out(_r.tensor(3), _r.tensor(0), _r.symintlist(1), _r.toBool(2)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_permute_copy_out = [](at::Tensor out, const at::Tensor & self, at::IntArrayRef dims) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::permute_copy_out(out, self, dims);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_permute_copy_out(_r.tensor(2), _r.tensor(0), _r.intlist(1)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::_reshape_alias_copy_symint(self, size, stride);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch__reshape_alias_copy_out = [](at::Tensor out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::_reshape_alias_copy_symint_out(out, self, size, stride);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch__reshape_alias_copy_out(_r.tensor(3), _r.tensor(0), _r.symintlist(1), _r.symintlist(2)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::select_copy_symint(self, dim, index);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_select_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim, c10::SymInt index) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::select_copy_symint_out(out, self, dim, index);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_select_copy_out(_r.tensor(3), _r.tensor(0), _r.toInt64(1), _r.toSymInt(2)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_detach_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::detach_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_detach_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::slice_copy_symint(self, dim, start, end, step);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_slice_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::slice_copy_symint_out(out, self, dim, start, end, step);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_slice_copy_out(_r.tensor(5), _r.tensor(0), _r.toInt64(1), _r.toSymIntOptional(2), _r.toSymIntOptional(3), _r.toSymInt(4)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::split_copy_symint(self, split_size, dim);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_split_copy_out = [](at::TensorList out, const at::Tensor & self, c10::SymInt split_size, int64_t dim) -> void {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      at::split_copy_symint_out(out, self, split_size, dim);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    dispatch_split_copy_out(_r.tensorlist(3), _r.tensor(0), _r.toSymInt(1), _r.toInt64(2));
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::split_with_sizes_copy_symint(self, split_sizes, dim);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_split_with_sizes_copy_out = [](at::TensorList out, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim) -> void {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      at::split_with_sizes_copy_symint_out(out, self, split_sizes, dim);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    dispatch_split_with_sizes_copy_out(_r.tensorlist(3), _r.tensor(0), _r.symintlist(1), _r.toInt64(2));
csrc/autograd/generated/python_torch_functionsEverything.cpp:        auto dispatch_squeeze_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:          return at::squeeze_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:        return wrap(dispatch_squeeze_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:        auto dispatch_squeeze_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:          return at::squeeze_copy_out(out, self, dim);
csrc/autograd/generated/python_torch_functionsEverything.cpp:        return wrap(dispatch_squeeze_copy_out(_r.tensor(2), _r.tensor(0), _r.toInt64(1)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:        auto dispatch_squeeze_copy_out = [](at::Tensor out, const at::Tensor & self, at::IntArrayRef dim) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:          return at::squeeze_copy_out(out, self, dim);
csrc/autograd/generated/python_torch_functionsEverything.cpp:        return wrap(dispatch_squeeze_copy_out(_r.tensor(2), _r.tensor(0), _r.intlist(1)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_t_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::t_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_t_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_transpose_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim0, int64_t dim1) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::transpose_copy_out(out, self, dim0, dim1);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_transpose_copy_out(_r.tensor(3), _r.tensor(0), _r.toInt64(1), _r.toInt64(2)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_unsqueeze_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::unsqueeze_copy_out(out, self, dim);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_unsqueeze_copy_out(_r.tensor(2), _r.tensor(0), _r.toInt64(1)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch__indices_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::_indices_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch__indices_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch__values_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::_values_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch__values_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_indices_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::indices_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_indices_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_values_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::values_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_values_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_crow_indices_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::crow_indices_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_crow_indices_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_col_indices_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::col_indices_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_col_indices_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_unbind_copy_out = [](at::TensorList out, const at::Tensor & self, int64_t dim) -> void {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      at::unbind_copy_out(out, self, dim);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    dispatch_unbind_copy_out(_r.tensorlist(2), _r.tensor(0), _r.toInt64(1));
csrc/autograd/generated/python_torch_functionsEverything.cpp:        auto dispatch_view_copy_out = [](at::Tensor out, const at::Tensor & self, at::ScalarType dtype) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:          return at::view_copy_out(out, self, dtype);
csrc/autograd/generated/python_torch_functionsEverything.cpp:        return wrap(dispatch_view_copy_out(_r.tensor(2), _r.tensor(0), _r.scalartype(1)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:          return at::view_copy_symint(self, size);
csrc/autograd/generated/python_torch_functionsEverything.cpp:        auto dispatch_view_copy_out = [](at::Tensor out, const at::Tensor & self, c10::SymIntArrayRef size) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:          return at::view_copy_symint_out(out, self, size);
csrc/autograd/generated/python_torch_functionsEverything.cpp:        return wrap(dispatch_view_copy_out(_r.tensor(2), _r.tensor(0), _r.symintlist(1)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_unfold_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::unfold_copy_out(out, self, dimension, size, step);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_unfold_copy_out(_r.tensor(4), _r.tensor(0), _r.toInt64(1), _r.toInt64(2), _r.toInt64(3)));
csrc/autograd/generated/python_torch_functionsEverything.cpp:    auto dispatch_alias_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functionsEverything.cpp:      return at::alias_copy_out(out, self);
csrc/autograd/generated/python_torch_functionsEverything.cpp:    return wrap(dispatch_alias_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, batch1_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, batch2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, tensor1_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, tensor2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, tensor1_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, tensor2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mat1_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mat2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mat1_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mat2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mat_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, vec_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, vec1_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, vec2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, theta_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, other_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, batch1_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, batch2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, p_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mat2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, other_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, tensors_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input2_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, min_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, max_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, min_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, max_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    auto grad_result = any_grad_defined ? (_to_copy_backward(grad, self_options)) : Tensor();
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, imag_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, real_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, abs_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, angle_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, log_probs_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, log_probs_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, A_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, A_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, tensors_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, tensor_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, input_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mask_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, scale_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, zero_point_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, scale_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, zero_point_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, value_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, value_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grid_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grid_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grid_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, source_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, source_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, source_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, value_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, values_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, values_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, A_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, end_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, end_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, weight_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, b_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, A_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, A_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, B_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, LU_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, LU_data_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, value_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, source_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mat2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, vec_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grad_out_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, save_invstd_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, save_mean_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, bias_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grad_out_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mean_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, rstd_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, pdist_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, x1_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, x2_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, x1_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, x2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, cdist_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, x1_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, x2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mean_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, std_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mean_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, std_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, tau_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input2_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input3_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, exponent_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, exponent_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, source_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, A_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, src_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, src_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, src_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, src_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, src_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, src_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, A_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, B_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, A_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, A_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, A_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, B_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_in_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, v_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, g_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, values_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, i1_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, i2_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, i3_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, target_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, target_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, target_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, weight_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, per_sample_weights_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, weight_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, target_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, target_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, target_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_out_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, weight_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, other_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grad_output_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grad_output_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grad_output_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grad_output_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_or_result_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, target_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mat1_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, mat2_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, target_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, target_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, log_probs_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, log_probs_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grid_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, theta_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grad_output_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, reserveSpace_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, save_mean_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, save_var_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, hx_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, params_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, hx_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, cx_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<3>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, cx_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_cy_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_hy_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, grad_output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, hx_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, input_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, output_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, weight_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, grad_output_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, save_mean_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, save_var_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, hx_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, cx_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<3>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight0_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight1_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight2_ix, std::get<3>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight3_ix, std::get<4>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, hx__ix, std::get<5>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, cx__ix, std::get<6>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, weight_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, bias_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, list_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, t_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, padded_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, query_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, key_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, value_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, query_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, key_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, value_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, tensors_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_gates_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, hidden_gates_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, cx_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_bias_ix, std::get<3>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, hidden_bias_ix, std::get<4>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_gates_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, hidden_gates_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, hx_ix, std::get<2>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, input_bias_ix, std::get<3>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, hidden_bias_ix, std::get<4>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, input_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, data_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, self_ix, std::get<0>(grad_result));
csrc/autograd/generated/Functions.cpp:        copy_range(grad_inputs, src_ix, std::get<1>(grad_result));
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/Functions.cpp:    copy_range(grad_inputs, self_ix, grad_result);
csrc/autograd/generated/python_functions_0.cpp:PyObject* THPAsStridedBackward0_copy_size_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_0.cpp:PyObject* THPAsStridedBackward0_copy_stride_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_0.cpp:PyObject* THPAsStridedBackward0_copy_storage_offset_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_0.cpp:static struct PyGetSetDef AsStridedBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_0.cpp:  {(char*)"_saved_size", (getter)THPAsStridedBackward0_copy_size_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_0.cpp:  {(char*)"_saved_stride", (getter)THPAsStridedBackward0_copy_stride_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_0.cpp:  {(char*)"_saved_storage_offset", (getter)THPAsStridedBackward0_copy_storage_offset_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_0.cpp:static struct PyGetSetDef ConjBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_0.cpp:static struct PyGetSetDef NegViewBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_0.cpp:static struct PyGetSetDef ViewAsComplexBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_0.cpp:static struct PyGetSetDef NestedViewFromBufferBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_0.cpp:  addClass<AsStridedBackward0_copy>(module, AsStridedBackward0_copyClass, "AsStridedBackward0_copy", AsStridedBackward0_copy_properties);
csrc/autograd/generated/python_functions_0.cpp:  addClass<ConjBackward0_copy>(module, ConjBackward0_copyClass, "ConjBackward0_copy", ConjBackward0_copy_properties);
csrc/autograd/generated/python_functions_0.cpp:  addClass<NegViewBackward0_copy>(module, NegViewBackward0_copyClass, "NegViewBackward0_copy", NegViewBackward0_copy_properties);
csrc/autograd/generated/python_functions_0.cpp:  addClass<ViewAsComplexBackward0_copy>(module, ViewAsComplexBackward0_copyClass, "ViewAsComplexBackward0_copy", ViewAsComplexBackward0_copy_properties);
csrc/autograd/generated/python_functions_0.cpp:  addClass<NestedViewFromBufferBackward0_copy>(module, NestedViewFromBufferBackward0_copyClass, "NestedViewFromBufferBackward0_copy", NestedViewFromBufferBackward0_copy_properties);
csrc/autograd/generated/VariableType_1.cpp:at::Tensor & values_copy_out_out_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_1.cpp:    at::redispatch::values_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_1.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with values_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(maybe_multiply(self_t, beta) + maybe_multiply(mat1_t.mm(mat2_p), alpha) + maybe_multiply(mat1_p.mm(mat2_t), alpha)) : maybe_multiply(self_t, beta) + maybe_multiply(mat1_t.mm(mat2_p), alpha) + maybe_multiply(mat1_p.mm(mat2_t), alpha);
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(maybe_multiply(self_t, beta) + maybe_multiply(vec1_t.outer(vec2_p), alpha) + maybe_multiply(vec1_p.outer(vec2_t), alpha)) : maybe_multiply(self_t, beta) + maybe_multiply(vec1_t.outer(vec2_p), alpha) + maybe_multiply(vec1_p.outer(vec2_t), alpha);
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * (-original_self_p * original_self_p + 1).rsqrt().conj()).conj()) : (original_self_t.conj() * (-original_self_p * original_self_p + 1).rsqrt().conj()).conj();
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((-2.0 / sqrt(M_PI) * exp(-(original_self_p.pow(2))) * original_self_t.conj()).conj()) : (-2.0 / sqrt(M_PI) * exp(-(original_self_p.pow(2))) * original_self_t.conj()).conj();
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t) : self_t;
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((hardsigmoid_backward(original_self_t.conj(), original_self_p)).conj()) : (hardsigmoid_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableType_1.cpp:at::Tensor & indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_1.cpp:    at::redispatch::indices_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_1.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with indices_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::lerp(self_t, end_t, weight)) : at::lerp(self_t, end_t, weight);
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::lerp(original_self_t, end_t, weight_p) + weight_t * (end_p - original_self_p)) : at::lerp(original_self_t, end_t, weight_p) + weight_t * (end_p - original_self_p);
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(other_t * original_self_p + original_self_t * other_p) : other_t * original_self_p + original_self_t * other_p;
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t * other) : self_t * other;
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((pow_backward(original_self_t.conj(), original_self_p, exponent)).conj()) : (pow_backward(original_self_t.conj(), original_self_p, exponent)).conj();
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((pow_backward_self(original_self_t.conj(), original_self_p, exponent_p) + pow_backward_exponent(exponent_t.conj(), original_self_p, exponent_p, self_p)).conj()) : (pow_backward_self(original_self_t.conj(), original_self_p, exponent_p) + pow_backward_exponent(exponent_t.conj(), original_self_p, exponent_p, self_p)).conj();
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((-0.5 * self_t.conj() * self_p.pow(3).conj()).conj()) : (-0.5 * self_t.conj() * self_p.pow(3).conj()).conj();
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj() * (1 + self_p.pow(2)).conj()).conj()) : (self_t.conj() * (1 + self_p.pow(2)).conj()).conj();
csrc/autograd/generated/VariableType_1.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::tril(self_t, diagonal)) : at::tril(self_t, diagonal);
csrc/autograd/generated/VariableType_1.cpp:at::Tensor & values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_1.cpp:    at::redispatch::values_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_1.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with values_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_1.cpp:       TORCH_FN(VariableType::values_copy_out_out_AutogradNestedTensor)
csrc/autograd/generated/VariableType_1.cpp:       TORCH_FN(VariableType::indices_copy_out_out)
csrc/autograd/generated/VariableType_1.cpp:       TORCH_FN(VariableType::values_copy_out_out)
csrc/autograd/generated/python_torch_functions_1.cpp:#include <ATen/ops/_has_compatible_shallow_copy_type.h>
csrc/autograd/generated/python_torch_functions_1.cpp:static PyObject * THPVariable__has_compatible_shallow_copy_type(PyObject* self_, PyObject* args, PyObject* kwargs);
csrc/autograd/generated/python_torch_functions_1.cpp:  {"_has_compatible_shallow_copy_type", castPyCFunctionWithKeywords(THPVariable__has_compatible_shallow_copy_type), METH_VARARGS | METH_KEYWORDS | METH_STATIC, NULL},
csrc/autograd/generated/python_torch_functions_1.cpp:      return self.narrow_copy_symint(dim, start, length);
csrc/autograd/generated/python_torch_functions_1.cpp:    auto dispatch_narrow_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_1.cpp:      return at::narrow_copy_symint_out(out, self, dim, start, length);
csrc/autograd/generated/python_torch_functions_1.cpp:    return wrap(dispatch_narrow_copy_out(_r.tensor(4), _r.tensor(0), _r.toInt64(1), _r.toSymInt(2), _r.toSymInt(3)));
csrc/autograd/generated/python_torch_functions_1.cpp:// _has_compatible_shallow_copy_type
csrc/autograd/generated/python_torch_functions_1.cpp:static PyObject * THPVariable__has_compatible_shallow_copy_type(PyObject* self_, PyObject* args, PyObject* kwargs)
csrc/autograd/generated/python_torch_functions_1.cpp:    "_has_compatible_shallow_copy_type(Tensor input, Tensor from)",
csrc/autograd/generated/python_torch_functions_1.cpp:  // aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool
csrc/autograd/generated/python_torch_functions_1.cpp:  auto dispatch__has_compatible_shallow_copy_type = [](const at::Tensor & self, const at::Tensor & from) -> bool {
csrc/autograd/generated/python_torch_functions_1.cpp:    return at::_has_compatible_shallow_copy_type(self, from);
csrc/autograd/generated/python_torch_functions_1.cpp:  return wrap(dispatch__has_compatible_shallow_copy_type(_r.tensor(0), _r.tensor(1)));
csrc/autograd/generated/python_torch_functions_1.cpp:    auto dispatch__conj_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_1.cpp:      return at::_conj_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_1.cpp:    return wrap(dispatch__conj_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_1.cpp:    auto dispatch__sparse_broadcast_to_copy_out = [](at::Tensor out, const at::Tensor & self, at::IntArrayRef size) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_1.cpp:      return at::_sparse_broadcast_to_copy_out(out, self, size);
csrc/autograd/generated/python_torch_functions_1.cpp:    return wrap(dispatch__sparse_broadcast_to_copy_out(_r.tensor(2), _r.tensor(0), _r.intlist(1)));
csrc/autograd/generated/python_torch_functions_1.cpp:      return at::select_copy_symint(self, dim, index);
csrc/autograd/generated/python_torch_functions_1.cpp:    auto dispatch_select_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim, c10::SymInt index) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_1.cpp:      return at::select_copy_symint_out(out, self, dim, index);
csrc/autograd/generated/python_torch_functions_1.cpp:    return wrap(dispatch_select_copy_out(_r.tensor(3), _r.tensor(0), _r.toInt64(1), _r.toSymInt(2)));
csrc/autograd/generated/python_torch_functions_1.cpp:        auto dispatch_squeeze_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_1.cpp:          return at::squeeze_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_1.cpp:        return wrap(dispatch_squeeze_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_1.cpp:        auto dispatch_squeeze_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_1.cpp:          return at::squeeze_copy_out(out, self, dim);
csrc/autograd/generated/python_torch_functions_1.cpp:        return wrap(dispatch_squeeze_copy_out(_r.tensor(2), _r.tensor(0), _r.toInt64(1)));
csrc/autograd/generated/python_torch_functions_1.cpp:        auto dispatch_squeeze_copy_out = [](at::Tensor out, const at::Tensor & self, at::IntArrayRef dim) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_1.cpp:          return at::squeeze_copy_out(out, self, dim);
csrc/autograd/generated/python_torch_functions_1.cpp:        return wrap(dispatch_squeeze_copy_out(_r.tensor(2), _r.tensor(0), _r.intlist(1)));
csrc/autograd/generated/python_torch_functions_1.cpp:    auto dispatch_transpose_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim0, int64_t dim1) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_1.cpp:      return at::transpose_copy_out(out, self, dim0, dim1);
csrc/autograd/generated/python_torch_functions_1.cpp:    return wrap(dispatch_transpose_copy_out(_r.tensor(3), _r.tensor(0), _r.toInt64(1), _r.toInt64(2)));
csrc/autograd/generated/python_torch_functions_1.cpp:    auto dispatch_values_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_1.cpp:      return at::values_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_1.cpp:    return wrap(dispatch_values_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_1.cpp:    auto dispatch_unfold_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_1.cpp:      return at::unfold_copy_out(out, self, dimension, size, step);
csrc/autograd/generated/python_torch_functions_1.cpp:    return wrap(dispatch_unfold_copy_out(_r.tensor(4), _r.tensor(0), _r.toInt64(1), _r.toInt64(2), _r.toInt64(3)));
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPDiagonalBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPDiagonalBackward0_copy_offset_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPDiagonalBackward0_copy_dim1_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPDiagonalBackward0_copy_dim2_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:static struct PyGetSetDef DiagonalBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPDiagonalBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_offset", (getter)THPDiagonalBackward0_copy_offset_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_dim1", (getter)THPDiagonalBackward0_copy_dim1_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_dim2", (getter)THPDiagonalBackward0_copy_dim2_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPExpandBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:static struct PyGetSetDef ExpandBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPExpandBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPPermuteBackward0_copy_dims_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:static struct PyGetSetDef PermuteBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_dims", (getter)THPPermuteBackward0_copy_dims_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPReshapeAliasBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:static struct PyGetSetDef ReshapeAliasBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPReshapeAliasBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:static struct PyGetSetDef TBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPUnsqueezeBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:static struct PyGetSetDef UnsqueezeBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_dim", (getter)THPUnsqueezeBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPViewBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:static struct PyGetSetDef ViewBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPViewBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPViewBackwardAutogradNestedTensor0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPViewBackwardAutogradNestedTensor0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:static struct PyGetSetDef ViewBackwardAutogradNestedTensor0_copy_properties[] = {
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_self", (getter)THPViewBackwardAutogradNestedTensor0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_raw_saved_self", (getter)THPViewBackwardAutogradNestedTensor0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPTestAutogradMultipleDispatchViewBackward0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPTestAutogradMultipleDispatchViewBackward0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:static struct PyGetSetDef TestAutogradMultipleDispatchViewBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_self", (getter)THPTestAutogradMultipleDispatchViewBackward0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_raw_saved_self", (getter)THPTestAutogradMultipleDispatchViewBackward0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPTestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:PyObject* THPTestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_2.cpp:static struct PyGetSetDef TestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_properties[] = {
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_saved_self", (getter)THPTestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:  {(char*)"_raw_saved_self", (getter)THPTestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_2.cpp:  addClass<DiagonalBackward0_copy>(module, DiagonalBackward0_copyClass, "DiagonalBackward0_copy", DiagonalBackward0_copy_properties);
csrc/autograd/generated/python_functions_2.cpp:  addClass<ExpandBackward0_copy>(module, ExpandBackward0_copyClass, "ExpandBackward0_copy", ExpandBackward0_copy_properties);
csrc/autograd/generated/python_functions_2.cpp:  addClass<PermuteBackward0_copy>(module, PermuteBackward0_copyClass, "PermuteBackward0_copy", PermuteBackward0_copy_properties);
csrc/autograd/generated/python_functions_2.cpp:  addClass<ReshapeAliasBackward0_copy>(module, ReshapeAliasBackward0_copyClass, "ReshapeAliasBackward0_copy", ReshapeAliasBackward0_copy_properties);
csrc/autograd/generated/python_functions_2.cpp:  addClass<TBackward0_copy>(module, TBackward0_copyClass, "TBackward0_copy", TBackward0_copy_properties);
csrc/autograd/generated/python_functions_2.cpp:  addClass<UnsqueezeBackward0_copy>(module, UnsqueezeBackward0_copyClass, "UnsqueezeBackward0_copy", UnsqueezeBackward0_copy_properties);
csrc/autograd/generated/python_functions_2.cpp:  addClass<ViewBackward0_copy>(module, ViewBackward0_copyClass, "ViewBackward0_copy", ViewBackward0_copy_properties);
csrc/autograd/generated/python_functions_2.cpp:  addClass<ViewBackwardAutogradNestedTensor0_copy>(module, ViewBackwardAutogradNestedTensor0_copyClass, "ViewBackwardAutogradNestedTensor0_copy", ViewBackwardAutogradNestedTensor0_copy_properties);
csrc/autograd/generated/python_functions_2.cpp:  addClass<TestAutogradMultipleDispatchViewBackward0_copy>(module, TestAutogradMultipleDispatchViewBackward0_copyClass, "TestAutogradMultipleDispatchViewBackward0_copy", TestAutogradMultipleDispatchViewBackward0_copy_properties);
csrc/autograd/generated/python_functions_2.cpp:  addClass<TestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy>(module, TestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copyClass, "TestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy", TestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef AliasBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPAsStridedBackward0_copy_size_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPAsStridedBackward0_copy_stride_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPAsStridedBackward0_copy_storage_offset_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef AsStridedBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_size", (getter)THPAsStridedBackward0_copy_size_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_stride", (getter)THPAsStridedBackward0_copy_stride_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_storage_offset", (getter)THPAsStridedBackward0_copy_storage_offset_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef ConjBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef NegViewBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPDiagonalBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPDiagonalBackward0_copy_offset_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPDiagonalBackward0_copy_dim1_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPDiagonalBackward0_copy_dim2_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef DiagonalBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPDiagonalBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_offset", (getter)THPDiagonalBackward0_copy_offset_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim1", (getter)THPDiagonalBackward0_copy_dim1_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim2", (getter)THPDiagonalBackward0_copy_dim2_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPExpandBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef ExpandBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPExpandBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPPermuteBackward0_copy_dims_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef PermuteBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dims", (getter)THPPermuteBackward0_copy_dims_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPReshapeAliasBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef ReshapeAliasBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPReshapeAliasBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSelectBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSelectBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSelectBackward0_copy_index_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef SelectBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSelectBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPSelectBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_index", (getter)THPSelectBackward0_copy_index_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSelectBackwardAutogradNestedTensor0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSelectBackwardAutogradNestedTensor0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSelectBackwardAutogradNestedTensor0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSelectBackwardAutogradNestedTensor0_copy_index_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef SelectBackwardAutogradNestedTensor0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self", (getter)THPSelectBackwardAutogradNestedTensor0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_raw_saved_self", (getter)THPSelectBackwardAutogradNestedTensor0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPSelectBackwardAutogradNestedTensor0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_index", (getter)THPSelectBackwardAutogradNestedTensor0_copy_index_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSliceBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSliceBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSliceBackward0_copy_start_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSliceBackward0_copy_end_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSliceBackward0_copy_step_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef SliceBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSliceBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPSliceBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_start", (getter)THPSliceBackward0_copy_start_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_end", (getter)THPSliceBackward0_copy_end_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_step", (getter)THPSliceBackward0_copy_step_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSplitBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSplitBackward0_copy_split_size_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSplitBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef SplitBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSplitBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_split_size", (getter)THPSplitBackward0_copy_split_size_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPSplitBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSplitWithSizesBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSplitWithSizesBackward0_copy_split_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSplitWithSizesBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef SplitWithSizesBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSplitWithSizesBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_split_sizes", (getter)THPSplitWithSizesBackward0_copy_split_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPSplitWithSizesBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSqueezeBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef SqueezeBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSqueezeBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSqueezeBackward1_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSqueezeBackward1_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef SqueezeBackward1_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSqueezeBackward1_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPSqueezeBackward1_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSqueezeBackwardAutogradNestedTensor0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef SqueezeBackwardAutogradNestedTensor0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPSqueezeBackwardAutogradNestedTensor0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSqueezeBackward2_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSqueezeBackward2_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef SqueezeBackward2_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSqueezeBackward2_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPSqueezeBackward2_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSqueezeBackwardAutogradNestedTensor1_copy_self_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPSqueezeBackwardAutogradNestedTensor1_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef SqueezeBackwardAutogradNestedTensor1_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_dim", (getter)THPSqueezeBackwardAutogradNestedTensor1_copy_self_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPSqueezeBackwardAutogradNestedTensor1_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef TBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPTransposeBackward0_copy_dim0_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPTransposeBackward0_copy_dim1_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef TransposeBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim0", (getter)THPTransposeBackward0_copy_dim0_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim1", (getter)THPTransposeBackward0_copy_dim1_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPUnfoldBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPUnfoldBackward0_copy_dimension_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPUnfoldBackward0_copy_size_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPUnfoldBackward0_copy_step_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef UnfoldBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPUnfoldBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dimension", (getter)THPUnfoldBackward0_copy_dimension_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_size", (getter)THPUnfoldBackward0_copy_size_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_step", (getter)THPUnfoldBackward0_copy_step_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef LiftFreshBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPUnsqueezeBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef UnsqueezeBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPUnsqueezeBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPViewBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef ViewBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPViewBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPViewBackwardAutogradNestedTensor0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPViewBackwardAutogradNestedTensor0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef ViewBackwardAutogradNestedTensor0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self", (getter)THPViewBackwardAutogradNestedTensor0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_raw_saved_self", (getter)THPViewBackwardAutogradNestedTensor0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef ViewAsRealBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef ViewAsComplexBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPValuesBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPValuesBackward0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPValuesBackward0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef ValuesBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPValuesBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self", (getter)THPValuesBackward0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_raw_saved_self", (getter)THPValuesBackward0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPValuesBackwardAutogradNestedTensor0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPValuesBackwardAutogradNestedTensor0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef ValuesBackwardAutogradNestedTensor0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self", (getter)THPValuesBackwardAutogradNestedTensor0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_raw_saved_self", (getter)THPValuesBackwardAutogradNestedTensor0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef NestedViewFromBufferBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPUnbindBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef UnbindBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_dim", (getter)THPUnbindBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPTestAutogradMultipleDispatchViewBackward0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPTestAutogradMultipleDispatchViewBackward0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef TestAutogradMultipleDispatchViewBackward0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self", (getter)THPTestAutogradMultipleDispatchViewBackward0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_raw_saved_self", (getter)THPTestAutogradMultipleDispatchViewBackward0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPTestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:PyObject* THPTestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functionsEverything.cpp:static struct PyGetSetDef TestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_properties[] = {
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_saved_self", (getter)THPTestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  {(char*)"_raw_saved_self", (getter)THPTestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<AliasBackward0_copy>(module, AliasBackward0_copyClass, "AliasBackward0_copy", AliasBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<AsStridedBackward0_copy>(module, AsStridedBackward0_copyClass, "AsStridedBackward0_copy", AsStridedBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<ConjBackward0_copy>(module, ConjBackward0_copyClass, "ConjBackward0_copy", ConjBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<NegViewBackward0_copy>(module, NegViewBackward0_copyClass, "NegViewBackward0_copy", NegViewBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<DiagonalBackward0_copy>(module, DiagonalBackward0_copyClass, "DiagonalBackward0_copy", DiagonalBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<ExpandBackward0_copy>(module, ExpandBackward0_copyClass, "ExpandBackward0_copy", ExpandBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<PermuteBackward0_copy>(module, PermuteBackward0_copyClass, "PermuteBackward0_copy", PermuteBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<ReshapeAliasBackward0_copy>(module, ReshapeAliasBackward0_copyClass, "ReshapeAliasBackward0_copy", ReshapeAliasBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<SelectBackward0_copy>(module, SelectBackward0_copyClass, "SelectBackward0_copy", SelectBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<SelectBackwardAutogradNestedTensor0_copy>(module, SelectBackwardAutogradNestedTensor0_copyClass, "SelectBackwardAutogradNestedTensor0_copy", SelectBackwardAutogradNestedTensor0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<SliceBackward0_copy>(module, SliceBackward0_copyClass, "SliceBackward0_copy", SliceBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<SplitBackward0_copy>(module, SplitBackward0_copyClass, "SplitBackward0_copy", SplitBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<SplitWithSizesBackward0_copy>(module, SplitWithSizesBackward0_copyClass, "SplitWithSizesBackward0_copy", SplitWithSizesBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<SqueezeBackward0_copy>(module, SqueezeBackward0_copyClass, "SqueezeBackward0_copy", SqueezeBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<SqueezeBackward1_copy>(module, SqueezeBackward1_copyClass, "SqueezeBackward1_copy", SqueezeBackward1_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<SqueezeBackwardAutogradNestedTensor0_copy>(module, SqueezeBackwardAutogradNestedTensor0_copyClass, "SqueezeBackwardAutogradNestedTensor0_copy", SqueezeBackwardAutogradNestedTensor0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<SqueezeBackward2_copy>(module, SqueezeBackward2_copyClass, "SqueezeBackward2_copy", SqueezeBackward2_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<SqueezeBackwardAutogradNestedTensor1_copy>(module, SqueezeBackwardAutogradNestedTensor1_copyClass, "SqueezeBackwardAutogradNestedTensor1_copy", SqueezeBackwardAutogradNestedTensor1_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<TBackward0_copy>(module, TBackward0_copyClass, "TBackward0_copy", TBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<TransposeBackward0_copy>(module, TransposeBackward0_copyClass, "TransposeBackward0_copy", TransposeBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<UnfoldBackward0_copy>(module, UnfoldBackward0_copyClass, "UnfoldBackward0_copy", UnfoldBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<LiftFreshBackward0_copy>(module, LiftFreshBackward0_copyClass, "LiftFreshBackward0_copy", LiftFreshBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<UnsqueezeBackward0_copy>(module, UnsqueezeBackward0_copyClass, "UnsqueezeBackward0_copy", UnsqueezeBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<ViewBackward0_copy>(module, ViewBackward0_copyClass, "ViewBackward0_copy", ViewBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<ViewBackwardAutogradNestedTensor0_copy>(module, ViewBackwardAutogradNestedTensor0_copyClass, "ViewBackwardAutogradNestedTensor0_copy", ViewBackwardAutogradNestedTensor0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<ViewAsRealBackward0_copy>(module, ViewAsRealBackward0_copyClass, "ViewAsRealBackward0_copy", ViewAsRealBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<ViewAsComplexBackward0_copy>(module, ViewAsComplexBackward0_copyClass, "ViewAsComplexBackward0_copy", ViewAsComplexBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<ValuesBackward0_copy>(module, ValuesBackward0_copyClass, "ValuesBackward0_copy", ValuesBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<ValuesBackwardAutogradNestedTensor0_copy>(module, ValuesBackwardAutogradNestedTensor0_copyClass, "ValuesBackwardAutogradNestedTensor0_copy", ValuesBackwardAutogradNestedTensor0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<NestedViewFromBufferBackward0_copy>(module, NestedViewFromBufferBackward0_copyClass, "NestedViewFromBufferBackward0_copy", NestedViewFromBufferBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<UnbindBackward0_copy>(module, UnbindBackward0_copyClass, "UnbindBackward0_copy", UnbindBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<TestAutogradMultipleDispatchViewBackward0_copy>(module, TestAutogradMultipleDispatchViewBackward0_copyClass, "TestAutogradMultipleDispatchViewBackward0_copy", TestAutogradMultipleDispatchViewBackward0_copy_properties);
csrc/autograd/generated/python_functionsEverything.cpp:  addClass<TestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy>(module, TestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copyClass, "TestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy", TestAutogradMultipleDispatchViewBackwardAutogradCUDA0_copy_properties);
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/_to_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/_make_dual_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/view_as_complex_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/_neg_view_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/expand_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/unsqueeze_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/crow_indices_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/_make_dual_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/view_as_complex_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/_neg_view_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/expand_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/unsqueeze_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/crow_indices_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
csrc/autograd/generated/TraceType_0.cpp:#include <ATen/ops/_to_copy_ops.h>
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & index_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out) {
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("index_copy_out", out);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::index_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index, source, out);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & index_copy_(c10::DispatchKeySet ks, at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
csrc/autograd/generated/TraceType_0.cpp:      op_name = c10::Symbol::fromQualString("aten::index_copy_");
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("index_copy_", self);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::index_copy_::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index, source);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & index_copy__dimname(c10::DispatchKeySet ks, at::Tensor & self, at::Dimname dim, const at::Tensor & index, const at::Tensor & source) {
csrc/autograd/generated/TraceType_0.cpp:      op_name = c10::Symbol::fromQualString("aten::index_copy_");
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("index_copy_", self);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::index_copy__dimname::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index, source);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor index_copy_dimname(c10::DispatchKeySet ks, const at::Tensor & self, at::Dimname dim, const at::Tensor & index, const at::Tensor & source) {
csrc/autograd/generated/TraceType_0.cpp:  auto result =at::_ops::index_copy_dimname::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index, source);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & copy_sparse_to_sparse_(c10::DispatchKeySet ks, at::Tensor & self, const at::Tensor & src, bool non_blocking) {
csrc/autograd/generated/TraceType_0.cpp:      op_name = c10::Symbol::fromQualString("aten::copy_sparse_to_sparse");
csrc/autograd/generated/TraceType_0.cpp:      op_name = c10::Symbol::fromQualString("aten::copy_sparse_to_sparse_");
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("copy_sparse_to_sparse_", self);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::copy_sparse_to_sparse_::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, src, non_blocking);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & _make_dual_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & primal, const at::Tensor & tangent, int64_t level, at::Tensor & out) {
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_make_dual_copy_out", out);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::_make_dual_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), primal, tangent, level, out);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & view_as_complex_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("view_as_complex_copy_out", out);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::view_as_complex_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & _neg_view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_neg_view_copy_out", out);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::_neg_view_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & expand_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out) {
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("expand_copy_out", out);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::expand_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, size, implicit, out);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & unsqueeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("unsqueeze_copy_out", out);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::unsqueeze_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, out);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & crow_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("crow_indices_copy_out", out);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::crow_indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & copy_sparse_to_sparse_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/TraceType_0.cpp:    op_name = c10::Symbol::fromQualString("aten::copy_sparse_to_sparse");
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("copy_sparse_to_sparse_out", out);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::copy_sparse_to_sparse_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, src, non_blocking, out);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor copy_sparse_to_sparse(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & src, bool non_blocking) {
csrc/autograd/generated/TraceType_0.cpp:    op_name = c10::Symbol::fromQualString("aten::copy_sparse_to_sparse");
csrc/autograd/generated/TraceType_0.cpp:  auto result =at::_ops::copy_sparse_to_sparse::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, src, non_blocking);
csrc/autograd/generated/TraceType_0.cpp:at::Tensor & _to_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, bool non_blocking, c10::optional<at::MemoryFormat> memory_format, at::Tensor & out) {
csrc/autograd/generated/TraceType_0.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_to_copy_out", out);
csrc/autograd/generated/TraceType_0.cpp:  at::_ops::_to_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, non_blocking, memory_format, out);
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::index_copy_out_out)
csrc/autograd/generated/TraceType_0.cpp:  m.impl("index_copy_",
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::index_copy_)
csrc/autograd/generated/TraceType_0.cpp:  m.impl("index_copy_.dimname",
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::index_copy__dimname)
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::index_copy_dimname)
csrc/autograd/generated/TraceType_0.cpp:  m.impl("copy_sparse_to_sparse_",
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::copy_sparse_to_sparse_)
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::_make_dual_copy_out_out)
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::view_as_complex_copy_out_out)
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::_neg_view_copy_out_out)
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::expand_copy_out_out)
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::unsqueeze_copy_out_out)
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::crow_indices_copy_out_out)
csrc/autograd/generated/TraceType_0.cpp:  m.impl("copy_sparse_to_sparse.out",
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::copy_sparse_to_sparse_out_out)
csrc/autograd/generated/TraceType_0.cpp:  m.impl("copy_sparse_to_sparse",
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::copy_sparse_to_sparse)
csrc/autograd/generated/TraceType_0.cpp:         TORCH_FN(TraceType::_to_copy_out_out)
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/_copy_from_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/_reshape_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/_nested_view_from_buffer_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/diagonal_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/permute_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/select_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/slice_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/split_with_sizes_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/t_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/col_indices_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/unbind_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/alias_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/diagonal_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/permute_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/select_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/slice_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/split_with_sizes_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/t_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/col_indices_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/unbind_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/alias_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/_copy_from_ops.h>
csrc/autograd/generated/TraceType_4.cpp:#include <ATen/ops/_nested_view_from_buffer_copy_ops.h>
csrc/autograd/generated/TraceType_4.cpp:at::Tensor _copy_from(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst, bool non_blocking) {
csrc/autograd/generated/TraceType_4.cpp:    op_name = c10::Symbol::fromQualString("aten::_copy_from");
csrc/autograd/generated/TraceType_4.cpp:  auto result =at::_ops::_copy_from::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dst, non_blocking);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor select_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index) {
csrc/autograd/generated/TraceType_4.cpp:  auto result =at::_ops::select_copy_int::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor slice_copy_Tensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step) {
csrc/autograd/generated/TraceType_4.cpp:  auto result =at::_ops::slice_copy_Tensor::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, start, end, step);
csrc/autograd/generated/TraceType_4.cpp:::std::vector<at::Tensor> unbind_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim) {
csrc/autograd/generated/TraceType_4.cpp:  auto result =at::_ops::unbind_copy_int::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor & diagonal_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out) {
csrc/autograd/generated/TraceType_4.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("diagonal_copy_out", out);
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::diagonal_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, offset, dim1, dim2, out);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor & permute_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out) {
csrc/autograd/generated/TraceType_4.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("permute_copy_out", out);
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::permute_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dims, out);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor & select_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
csrc/autograd/generated/TraceType_4.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("select_copy_out", out);
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::select_copy_int_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index, out);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor & slice_copy_out_Tensor_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out) {
csrc/autograd/generated/TraceType_4.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("slice_copy_out", out);
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::slice_copy_Tensor_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, start, end, step, out);
csrc/autograd/generated/TraceType_4.cpp:void split_with_sizes_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim, at::TensorList out) {
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::split_with_sizes_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, split_sizes, dim, out);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor & t_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_4.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("t_copy_out", out);
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::t_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor & col_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_4.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("col_indices_copy_out", out);
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::col_indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_4.cpp:void unbind_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::TensorList out) {
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::unbind_copy_int_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, out);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor & alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_4.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("alias_copy_out", out);
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::alias_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor & _copy_from_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/TraceType_4.cpp:    op_name = c10::Symbol::fromQualString("aten::_copy_from");
csrc/autograd/generated/TraceType_4.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_copy_from_out", out);
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::_copy_from_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dst, non_blocking, out);
csrc/autograd/generated/TraceType_4.cpp:at::Tensor & _nested_view_from_buffer_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets, at::Tensor & out) {
csrc/autograd/generated/TraceType_4.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_nested_view_from_buffer_copy_out", out);
csrc/autograd/generated/TraceType_4.cpp:  at::_ops::_nested_view_from_buffer_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, nested_size, nested_strides, offsets, out);
csrc/autograd/generated/TraceType_4.cpp:  m.impl("_copy_from",
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::_copy_from)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::select_copy_int)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::slice_copy_Tensor)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::unbind_copy_int)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::diagonal_copy_out_out)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::permute_copy_out_out)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::select_copy_out_int_out)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::slice_copy_out_Tensor_out)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::split_with_sizes_copy_out_out)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::t_copy_out_out)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::col_indices_copy_out_out)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::unbind_copy_out_int_out)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::alias_copy_out_out)
csrc/autograd/generated/TraceType_4.cpp:  m.impl("_copy_from.out",
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::_copy_from_out_out)
csrc/autograd/generated/TraceType_4.cpp:         TORCH_FN(TraceType::_nested_view_from_buffer_copy_out_out)
csrc/autograd/generated/VariableType_3.cpp:at::Tensor _test_autograd_multiple_dispatch_view_copy_AutogradCUDA(c10::DispatchKeySet ks, const at::Tensor & self) {
csrc/autograd/generated/VariableType_3.cpp:at::Tensor squeeze_copy_dim_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim) {
csrc/autograd/generated/VariableType_3.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: squeeze_copy_dim");
csrc/autograd/generated/VariableType_3.cpp:    AT_ASSERT(result.use_count() <= 1, "function: squeeze_copy_dim");
csrc/autograd/generated/VariableType_3.cpp:at::Tensor squeeze_copy_dims_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim) {
csrc/autograd/generated/VariableType_3.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: squeeze_copy_dims");
csrc/autograd/generated/VariableType_3.cpp:    AT_ASSERT(result.use_count() <= 1, "function: squeeze_copy_dims");
csrc/autograd/generated/VariableType_3.cpp:at::Tensor & view_copy_out_out_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/VariableType_3.cpp:    at::redispatch::view_copy_symint_outf(ks & c10::after_autograd_keyset, self_, size, out_);
csrc/autograd/generated/VariableType_3.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with view_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_3.cpp:at::Tensor & _conj_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_3.cpp:    at::redispatch::_conj_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_3.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with _conj_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_3.cpp:at::Tensor & _neg_view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_3.cpp:    at::redispatch::_neg_view_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_3.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with _neg_view_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_3.cpp:    return at::redispatch::_reshape_alias_copy_symint(ks & c10::after_autograd_keyset, self_, size, stride);
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t + maybe_multiply(other_t, alpha)) : self_t + maybe_multiply(other_t, alpha);
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t.clone()) : self_t.clone();
csrc/autograd/generated/VariableType_3.cpp:at::Tensor & alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_3.cpp:    at::redispatch::alias_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_3.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with alias_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_3.cpp:    return at::redispatch::as_strided_copy_symint(ks & c10::after_autograd_keyset, self_, size, stride, storage_offset);
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t.copy_(elu_backward(original_self_t, alpha, 1, 1.0/alpha.toFloat(), /* is_result */ true, self_p));
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * original_self_p.sinh().conj()).conj()) : (original_self_t.conj() * original_self_p.sinh().conj()).conj();
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t - other_t * self_p) / other_p) : (self_t - other_t * self_p) / other_p;
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(rounding_mode.has_value() ? self_p.new_zeros_symint(self_p.sym_sizes()) : original_self_t / other_p - other_t * (original_self_p / other_p) / other_p) : rounding_mode.has_value() ? self_p.new_zeros_symint(self_p.sym_sizes()) : original_self_t / other_p - other_t * (original_self_p / other_p) / other_p;
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t / other) : self_t / other;
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(rounding_mode.has_value() ? self_p.new_zeros_symint(self_p.sym_sizes()) : self_t / other) : rounding_mode.has_value() ? self_p.new_zeros_symint(self_p.sym_sizes()) : self_t / other;
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((2.0 / sqrt(M_PI) * exp(-(original_self_p.pow(2))) * original_self_t.conj()).conj()) : (2.0 / sqrt(M_PI) * exp(-(original_self_p.pow(2))) * original_self_t.conj()).conj();
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj() * self_p * M_LN2).conj()) : (self_t.conj() * self_p * M_LN2).conj();
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(original_self_t * original_self_p / self_p + other_t * other_p / self_p) : original_self_t * original_self_p / self_p + other_t * other_p / self_p;
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((GradMode::is_enabled() ? infinitely_differentiable_mish_backward(original_self_t.conj(), original_self_p) : mish_backward(original_self_t.conj(), original_self_p)).conj()) : (GradMode::is_enabled() ? infinitely_differentiable_mish_backward(original_self_t.conj(), original_self_p) : mish_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((mvlgamma_backward(original_self_t.conj(), original_self_p, p)).conj()) : (mvlgamma_backward(original_self_t.conj(), original_self_p, p)).conj();
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((-self_t.conj() * (self_p * self_p).conj()).conj()) : (-self_t.conj() * (self_p * self_p).conj()).conj();
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj()).conj()) : (self_t.conj()).conj();
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(original_self_t - other_t * original_self_p.div(other_p, /*rounding_mode=*/"floor")) : original_self_t - other_t * original_self_p.div(other_p, /*rounding_mode=*/"floor");
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(scatter_add(self_t, dim, index, src_t)) : scatter_add(self_t, dim, index, src_t);
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * original_self_p.cosh().conj()).conj()) : (original_self_t.conj() * original_self_p.cosh().conj()).conj();
csrc/autograd/generated/VariableType_3.cpp:at::Tensor & slice_copy_out_Tensor_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out) {
csrc/autograd/generated/VariableType_3.cpp:    at::redispatch::slice_copy_symint_outf(ks & c10::after_autograd_keyset, self_, dim, start, end, step, out_);
csrc/autograd/generated/VariableType_3.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with slice_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_3.cpp:::std::vector<at::Tensor> split_copy_Tensor(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymInt split_size, int64_t dim) {
csrc/autograd/generated/VariableType_3.cpp:    return at::redispatch::split_copy_symint(ks & c10::after_autograd_keyset, self_, split_size, dim);
csrc/autograd/generated/VariableType_3.cpp:void split_copy_out_Tensor_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymInt split_size, int64_t dim, at::TensorList out) {
csrc/autograd/generated/VariableType_3.cpp:    at::redispatch::split_copy_symint_outf(ks & c10::after_autograd_keyset, self_, split_size, dim, out_);
csrc/autograd/generated/VariableType_3.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefinedTensorList(out))), "Trying to use forward AD with split_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_3.cpp:void split_with_sizes_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim, at::TensorList out) {
csrc/autograd/generated/VariableType_3.cpp:    at::redispatch::split_with_sizes_copy_symint_outf(ks & c10::after_autograd_keyset, self_, split_sizes, dim, out_);
csrc/autograd/generated/VariableType_3.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefinedTensorList(out))), "Trying to use forward AD with split_with_sizes_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_3.cpp:at::Tensor squeeze_copy_dim(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim) {
csrc/autograd/generated/VariableType_3.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: squeeze_copy_dim");
csrc/autograd/generated/VariableType_3.cpp:    AT_ASSERT(result.use_count() <= 1, "function: squeeze_copy_dim");
csrc/autograd/generated/VariableType_3.cpp:at::Tensor squeeze_copy_dims(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim) {
csrc/autograd/generated/VariableType_3.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: squeeze_copy_dims");
csrc/autograd/generated/VariableType_3.cpp:    AT_ASSERT(result.use_count() <= 1, "function: squeeze_copy_dims");
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((tanh_backward(self_t.conj(), self_p)).conj()) : (tanh_backward(self_t.conj(), self_p)).conj();
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::triu(self_t, diagonal)) : at::triu(self_t, diagonal);
csrc/autograd/generated/VariableType_3.cpp:at::Tensor & view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/VariableType_3.cpp:    at::redispatch::view_copy_symint_outf(ks & c10::after_autograd_keyset, self_, size, out_);
csrc/autograd/generated/VariableType_3.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with view_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_3.cpp:at::Tensor & view_copy_out_dtype_out(c10::DispatchKeySet ks, const at::Tensor & self, at::ScalarType dtype, at::Tensor & out) {
csrc/autograd/generated/VariableType_3.cpp:    at::redispatch::view_copy_outf(ks & c10::after_autograd_keyset, self_, dtype, out_);
csrc/autograd/generated/VariableType_3.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with view_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::xlogy(original_self_t, other_p).masked_fill((original_self_p == 0.) & (other_p <= 0.), 0.) + other_t * original_self_p / other_p) : at::xlogy(original_self_t, other_p).masked_fill((original_self_p == 0.) & (other_p <= 0.), 0.) + other_t * original_self_p / other_p;
csrc/autograd/generated/VariableType_3.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((other.toDouble() > 0. ? at::xlogy(original_self_t.conj(),  other) : at::xlogy(original_self_t.conj(),  other).masked_fill(original_self_p == 0., 0.)).conj()) : (other.toDouble() > 0. ? at::xlogy(original_self_t.conj(),  other) : at::xlogy(original_self_t.conj(),  other).masked_fill(original_self_p == 0., 0.)).conj();
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::_test_autograd_multiple_dispatch_view_copy_AutogradCUDA)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::squeeze_copy_dim_AutogradNestedTensor)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::squeeze_copy_dims_AutogradNestedTensor)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::view_copy_out_out_AutogradNestedTensor)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::_conj_copy_out_out)
csrc/autograd/generated/VariableType_3.cpp:m.impl("_copy_from_and_resize", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::_neg_view_copy_out_out)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::alias_copy_out_out)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::slice_copy_out_Tensor_out)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::split_copy_Tensor)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::split_copy_out_Tensor_out)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::split_with_sizes_copy_out_out)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::squeeze_copy_dim)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::squeeze_copy_dims)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::view_copy_out_out)
csrc/autograd/generated/VariableType_3.cpp:       TORCH_FN(VariableType::view_copy_out_dtype_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/_copy_from_and_resize_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/_fw_primal_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/_indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/_reshape_alias_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/_sparse_broadcast_to_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/_values_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/alias_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/as_strided_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/col_indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/crow_indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/expand_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/lift_fresh_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/narrow_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/select_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/unsqueeze_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/values_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & _copy_from_and_resize_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::_copy_from_and_resize_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dst, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & _fw_primal_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t level, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::_fw_primal_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, level, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & _indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::_indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & _reshape_alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::_reshape_alias_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, size, stride, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & _sparse_broadcast_to_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::_sparse_broadcast_to_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, size, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & _values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::_values_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::alias_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & as_strided_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::as_strided_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, size, stride, storage_offset, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & col_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::col_indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & copy_sparse_to_sparse_(c10::DispatchKeySet ks, at::Tensor & self, const at::Tensor & src, bool non_blocking) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::copy_sparse_to_sparse_::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, src, non_blocking);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & copy_sparse_to_sparse_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::copy_sparse_to_sparse_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, src, non_blocking, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & crow_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::crow_indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & expand_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::expand_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, size, implicit, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & index_copy_(c10::DispatchKeySet ks, at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::index_copy_::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, index, source);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & index_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::index_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, index, source, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & lift_fresh_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::lift_fresh_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & narrow_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::narrow_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, start, length, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & select_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::select_copy_int_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, index, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & squeeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::squeeze_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & squeeze_copy_out_dim_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::squeeze_copy_dim_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & squeeze_copy_out_dims_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::squeeze_copy_dims_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & unsqueeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::unsqueeze_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::values_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::view_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, size, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:at::Tensor & view_copy_out_dtype_out(c10::DispatchKeySet ks, const at::Tensor & self, at::ScalarType dtype, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:    at::_ops::view_copy_dtype_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dtype, out);
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:  m.impl("_copy_from_and_resize.out",
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::_copy_from_and_resize_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::_fw_primal_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::_indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::_reshape_alias_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::_sparse_broadcast_to_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::_values_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::alias_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::as_strided_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::col_indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:  m.impl("copy_sparse_to_sparse_",
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::copy_sparse_to_sparse_)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:  m.impl("copy_sparse_to_sparse.out",
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::copy_sparse_to_sparse_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::crow_indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::expand_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:  m.impl("index_copy_",
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::index_copy_)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::index_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::lift_fresh_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::narrow_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::select_copy_out_int_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::squeeze_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::squeeze_copy_out_dim_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::squeeze_copy_out_dims_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::unsqueeze_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::values_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::view_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_1.cpp:         TORCH_FN(ADInplaceOrView::view_copy_out_dtype_out)
csrc/autograd/generated/python_torch_functions_0.cpp:#include <ATen/ops/_copy_from.h>
csrc/autograd/generated/python_torch_functions_0.cpp:#include <ATen/ops/_copy_from_and_resize.h>
csrc/autograd/generated/python_torch_functions_0.cpp:static PyObject * THPVariable__copy_from(PyObject* self_, PyObject* args, PyObject* kwargs);
csrc/autograd/generated/python_torch_functions_0.cpp:static PyObject * THPVariable__copy_from_and_resize(PyObject* self_, PyObject* args, PyObject* kwargs);
csrc/autograd/generated/python_torch_functions_0.cpp:  {"_copy_from", castPyCFunctionWithKeywords(THPVariable__copy_from), METH_VARARGS | METH_KEYWORDS | METH_STATIC, NULL},
csrc/autograd/generated/python_torch_functions_0.cpp:  {"_copy_from_and_resize", castPyCFunctionWithKeywords(THPVariable__copy_from_and_resize), METH_VARARGS | METH_KEYWORDS | METH_STATIC, NULL},
csrc/autograd/generated/python_torch_functions_0.cpp:// _copy_from
csrc/autograd/generated/python_torch_functions_0.cpp:static PyObject * THPVariable__copy_from(PyObject* self_, PyObject* args, PyObject* kwargs)
csrc/autograd/generated/python_torch_functions_0.cpp:    "_copy_from(Tensor input, Tensor dst, bool non_blocking=False)",
csrc/autograd/generated/python_torch_functions_0.cpp:  // aten::_copy_from(Tensor self, Tensor dst, bool non_blocking=False) -> Tensor
csrc/autograd/generated/python_torch_functions_0.cpp:  auto dispatch__copy_from = [](const at::Tensor & self, const at::Tensor & dst, bool non_blocking) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:    return at::_copy_from(self, dst, non_blocking);
csrc/autograd/generated/python_torch_functions_0.cpp:  return wrap(dispatch__copy_from(_r.tensor(0), _r.tensor(1), _r.toBool(2)));
csrc/autograd/generated/python_torch_functions_0.cpp:// _copy_from_and_resize
csrc/autograd/generated/python_torch_functions_0.cpp:static PyObject * THPVariable__copy_from_and_resize(PyObject* self_, PyObject* args, PyObject* kwargs)
csrc/autograd/generated/python_torch_functions_0.cpp:    "_copy_from_and_resize(Tensor input, Tensor dst)",
csrc/autograd/generated/python_torch_functions_0.cpp:  // aten::_copy_from_and_resize(Tensor self, Tensor dst) -> Tensor
csrc/autograd/generated/python_torch_functions_0.cpp:  auto dispatch__copy_from_and_resize = [](const at::Tensor & self, const at::Tensor & dst) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:    return at::_copy_from_and_resize(self, dst);
csrc/autograd/generated/python_torch_functions_0.cpp:  return wrap(dispatch__copy_from_and_resize(_r.tensor(0), _r.tensor(1)));
csrc/autograd/generated/python_torch_functions_0.cpp:        auto dispatch_index_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:          return at::index_copy_out(out, self, dim, index, source);
csrc/autograd/generated/python_torch_functions_0.cpp:        return wrap(dispatch_index_copy_out(_r.tensor(4), _r.tensor(0), _r.toInt64(1), _r.tensor(2), _r.tensor(3)));
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch__fw_primal_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t level) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::_fw_primal_copy_out(out, self, level);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch__fw_primal_copy_out(_r.tensor(2), _r.tensor(0), _r.toInt64(1)));
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch__make_dual_copy_out = [](at::Tensor out, const at::Tensor & primal, const at::Tensor & tangent, int64_t level) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::_make_dual_copy_out(out, primal, tangent, level);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch__make_dual_copy_out(_r.tensor(3), _r.tensor(0), _r.tensor(1), _r.toInt64(2)));
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch_view_as_complex_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::view_as_complex_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch_view_as_complex_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch__neg_view_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::_neg_view_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch__neg_view_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::as_strided_copy_symint(self, size, stride, storage_offset);
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch_as_strided_copy_out = [](at::Tensor out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::as_strided_copy_symint_out(out, self, size, stride, storage_offset);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch_as_strided_copy_out(_r.tensor(4), _r.tensor(0), _r.symintlist(1), _r.symintlist(2), _r.toSymIntOptional(3)));
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch_diagonal_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::diagonal_copy_out(out, self, offset, dim1, dim2);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch_diagonal_copy_out(_r.tensor(4), _r.tensor(0), _r.toInt64(1), _r.toInt64(2), _r.toInt64(3)));
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::expand_copy_symint(self, size, implicit);
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch_expand_copy_out = [](at::Tensor out, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::expand_copy_symint_out(out, self, size, implicit);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch_expand_copy_out(_r.tensor(3), _r.tensor(0), _r.symintlist(1), _r.toBool(2)));
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::_reshape_alias_copy_symint(self, size, stride);
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch__reshape_alias_copy_out = [](at::Tensor out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::_reshape_alias_copy_symint_out(out, self, size, stride);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch__reshape_alias_copy_out(_r.tensor(3), _r.tensor(0), _r.symintlist(1), _r.symintlist(2)));
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::slice_copy_symint(self, dim, start, end, step);
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch_slice_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::slice_copy_symint_out(out, self, dim, start, end, step);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch_slice_copy_out(_r.tensor(5), _r.tensor(0), _r.toInt64(1), _r.toSymIntOptional(2), _r.toSymIntOptional(3), _r.toSymInt(4)));
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::split_with_sizes_copy_symint(self, split_sizes, dim);
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch_split_with_sizes_copy_out = [](at::TensorList out, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim) -> void {
csrc/autograd/generated/python_torch_functions_0.cpp:      at::split_with_sizes_copy_symint_out(out, self, split_sizes, dim);
csrc/autograd/generated/python_torch_functions_0.cpp:    dispatch_split_with_sizes_copy_out(_r.tensorlist(3), _r.tensor(0), _r.symintlist(1), _r.toInt64(2));
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch_t_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::t_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch_t_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch_indices_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::indices_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch_indices_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch_crow_indices_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::crow_indices_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch_crow_indices_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_0.cpp:    auto dispatch_col_indices_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:      return at::col_indices_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_0.cpp:    return wrap(dispatch_col_indices_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_0.cpp:        auto dispatch_view_copy_out = [](at::Tensor out, const at::Tensor & self, at::ScalarType dtype) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:          return at::view_copy_out(out, self, dtype);
csrc/autograd/generated/python_torch_functions_0.cpp:        return wrap(dispatch_view_copy_out(_r.tensor(2), _r.tensor(0), _r.scalartype(1)));
csrc/autograd/generated/python_torch_functions_0.cpp:          return at::view_copy_symint(self, size);
csrc/autograd/generated/python_torch_functions_0.cpp:        auto dispatch_view_copy_out = [](at::Tensor out, const at::Tensor & self, c10::SymIntArrayRef size) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_0.cpp:          return at::view_copy_symint_out(out, self, size);
csrc/autograd/generated/python_torch_functions_0.cpp:        return wrap(dispatch_view_copy_out(_r.tensor(2), _r.tensor(0), _r.symintlist(1)));
csrc/autograd/generated/VariableType_0.cpp:at::Tensor & select_copy_out_int_out_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
csrc/autograd/generated/VariableType_0.cpp:    at::redispatch::select_copy_symint_outf(ks & c10::after_autograd_keyset, self_, dim, index, out_);
csrc/autograd/generated/VariableType_0.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with select_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t + maybe_multiply(tensor1_t * tensor2_p, value) + maybe_multiply(tensor2_t * tensor1_p, value)) : self_t + maybe_multiply(tensor1_t * tensor2_p, value) + maybe_multiply(tensor2_t * tensor1_p, value);
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(maybe_multiply(self_t, beta) + maybe_multiply(mat_t.mv(vec_p), alpha) + maybe_multiply(mat_p.mv(vec_t), alpha)) : maybe_multiply(self_t, beta) + maybe_multiply(mat_t.mv(vec_p), alpha) + maybe_multiply(mat_p.mv(vec_t), alpha);
csrc/autograd/generated/VariableType_0.cpp:at::Tensor & as_strided_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out) {
csrc/autograd/generated/VariableType_0.cpp:    at::redispatch::as_strided_copy_symint_outf(ks & c10::after_autograd_keyset, self_, size, stride, storage_offset, out_);
csrc/autograd/generated/VariableType_0.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with as_strided_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((clamp_backward(original_self_t.conj(), original_self_p, min, max)).conj()) : (clamp_backward(original_self_t.conj(), original_self_p, min, max)).conj();
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(clamp_jvp(original_self_p, original_self_t, min_p, min_t, max_p, max_t)) : clamp_jvp(original_self_p, original_self_t, min_p, min_t, max_p, max_t);
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((where(original_self_p >= min, original_self_t.conj(), at::scalar_tensor(0., original_self_t.conj().options()))).conj()) : (where(original_self_p >= min, original_self_t.conj(), at::scalar_tensor(0., original_self_t.conj().options()))).conj();
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(where(original_self_p >= min_p, original_self_t, min_t)) : where(original_self_p >= min_p, original_self_t, min_t);
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * polygamma(1, original_self_p)).conj()) : (original_self_t.conj() * polygamma(1, original_self_p)).conj();
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj() * self_p.conj()).conj()) : (self_t.conj() * self_p.conj()).conj();
csrc/autograd/generated/VariableType_0.cpp:    return at::redispatch::expand_copy_symint(ks & c10::after_autograd_keyset, self_, size, implicit);
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableType_0.cpp:at::Tensor & index_copy_(c10::DispatchKeySet ks, at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
csrc/autograd/generated/VariableType_0.cpp:    at::redispatch::index_copy_(ks & c10::after_autograd_keyset, self_, dim, index_, source_);
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.index_copy_(dim, index, source_t) : self_t.index_copy(dim, index, source_t);
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * digamma(original_self_p)).conj()) : (original_self_t.conj() * digamma(original_self_p)).conj();
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() / (original_self_p.conj() * 2.3025850929940456)).conj()) : (original_self_t.conj() / (original_self_p.conj() * 2.3025850929940456)).conj();
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj().div(original_self_p.conj())).conj()) : (original_self_t.conj().div(original_self_p.conj())).conj();
csrc/autograd/generated/VariableType_0.cpp:at::Tensor & permute_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out) {
csrc/autograd/generated/VariableType_0.cpp:    at::redispatch::permute_copy_outf(ks & c10::after_autograd_keyset, self_, dims, out_);
csrc/autograd/generated/VariableType_0.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with permute_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_0.cpp:at::Tensor & select_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
csrc/autograd/generated/VariableType_0.cpp:    at::redispatch::select_copy_symint_outf(ks & c10::after_autograd_keyset, self_, dim, index, out_);
csrc/autograd/generated/VariableType_0.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with select_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((sigmoid_backward(self_t.conj(), self_p)).conj()) : (sigmoid_backward(self_t.conj(), self_p)).conj();
csrc/autograd/generated/VariableType_0.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj() / (2 * self_p.conj())).conj()) : (self_t.conj() / (2 * self_p.conj())).conj();
csrc/autograd/generated/VariableType_0.cpp:void unbind_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::TensorList out) {
csrc/autograd/generated/VariableType_0.cpp:    at::redispatch::unbind_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableType_0.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefinedTensorList(out))), "Trying to use forward AD with unbind_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_0.cpp:at::Tensor & unfold_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out) {
csrc/autograd/generated/VariableType_0.cpp:    at::redispatch::unfold_copy_outf(ks & c10::after_autograd_keyset, self_, dimension, size, step, out_);
csrc/autograd/generated/VariableType_0.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with unfold_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_0.cpp:       TORCH_FN(VariableType::select_copy_out_int_out_AutogradNestedTensor)
csrc/autograd/generated/VariableType_0.cpp:       TORCH_FN(VariableType::as_strided_copy_out_out)
csrc/autograd/generated/VariableType_0.cpp:m.impl("copy_sparse_to_sparse", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableType_0.cpp:m.impl("copy_sparse_to_sparse_", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableType_0.cpp:m.impl("copy_sparse_to_sparse.out", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableType_0.cpp:m.impl("index_copy_",
csrc/autograd/generated/VariableType_0.cpp:       TORCH_FN(VariableType::index_copy_)
csrc/autograd/generated/VariableType_0.cpp:       TORCH_FN(VariableType::permute_copy_out_out)
csrc/autograd/generated/VariableType_0.cpp:       TORCH_FN(VariableType::select_copy_out_int_out)
csrc/autograd/generated/VariableType_0.cpp:       TORCH_FN(VariableType::unbind_copy_out_int_out)
csrc/autograd/generated/VariableType_0.cpp:       TORCH_FN(VariableType::unfold_copy_out_out)
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/_copy_from_and_resize_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/narrow_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/narrow_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/_has_compatible_shallow_copy_type_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/_fw_primal_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/view_as_real_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/as_strided_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/_reshape_alias_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/split_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/indices_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/ccol_indices_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/_fw_primal_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/view_as_real_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/as_strided_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/_reshape_alias_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/split_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/indices_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/_copy_from_and_resize_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:#include <ATen/ops/ccol_indices_copy_ops.h>
csrc/autograd/generated/TraceType_3.cpp:at::Tensor _copy_from_and_resize(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst) {
csrc/autograd/generated/TraceType_3.cpp:    op_name = c10::Symbol::fromQualString("aten::_copy_from_and_resize");
csrc/autograd/generated/TraceType_3.cpp:  auto result =at::_ops::_copy_from_and_resize::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dst);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & narrow_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("narrow_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::narrow_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, start, length, out);
csrc/autograd/generated/TraceType_3.cpp:bool _has_compatible_shallow_copy_type(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & from) {
csrc/autograd/generated/TraceType_3.cpp:  auto result =at::_ops::_has_compatible_shallow_copy_type::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, from);
csrc/autograd/generated/TraceType_3.cpp:::std::vector<at::Tensor> split_copy_Tensor(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymInt split_size, int64_t dim) {
csrc/autograd/generated/TraceType_3.cpp:  auto result =at::_ops::split_copy_Tensor::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, split_size, dim);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor squeeze_copy_dim(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim) {
csrc/autograd/generated/TraceType_3.cpp:  auto result =at::_ops::squeeze_copy_dim::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor squeeze_copy_dims(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim) {
csrc/autograd/generated/TraceType_3.cpp:  auto result =at::_ops::squeeze_copy_dims::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & _fw_primal_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t level, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_fw_primal_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::_fw_primal_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, level, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & view_as_real_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("view_as_real_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::view_as_real_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & as_strided_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("as_strided_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::as_strided_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, size, stride, storage_offset, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & _reshape_alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_reshape_alias_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::_reshape_alias_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, size, stride, out);
csrc/autograd/generated/TraceType_3.cpp:void split_copy_out_Tensor_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymInt split_size, int64_t dim, at::TensorList out) {
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::split_copy_Tensor_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, split_size, dim, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & squeeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("squeeze_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::squeeze_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & squeeze_copy_out_dim_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("squeeze_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::squeeze_copy_dim_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & squeeze_copy_out_dims_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("squeeze_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::squeeze_copy_dims_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("indices_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, src, non_blocking, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & _copy_from_and_resize_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    op_name = c10::Symbol::fromQualString("aten::_copy_from_and_resize");
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_copy_from_and_resize_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::_copy_from_and_resize_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dst, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & _test_autograd_multiple_dispatch_view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_test_autograd_multiple_dispatch_view_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::_test_autograd_multiple_dispatch_view_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_3.cpp:at::Tensor & ccol_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_3.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("ccol_indices_copy_out", out);
csrc/autograd/generated/TraceType_3.cpp:  at::_ops::ccol_indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_3.cpp:  m.impl("_copy_from_and_resize",
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::_copy_from_and_resize)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::narrow_copy_out_out)
csrc/autograd/generated/TraceType_3.cpp:  m.impl("_has_compatible_shallow_copy_type",
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::_has_compatible_shallow_copy_type)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::split_copy_Tensor)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::squeeze_copy_dim)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::squeeze_copy_dims)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::_fw_primal_copy_out_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::view_as_real_copy_out_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::as_strided_copy_out_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::_reshape_alias_copy_out_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::split_copy_out_Tensor_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::squeeze_copy_out_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::squeeze_copy_out_dim_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::squeeze_copy_out_dims_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::indices_copy_out_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::copy_out_out)
csrc/autograd/generated/TraceType_3.cpp:  m.impl("_copy_from_and_resize.out",
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::_copy_from_and_resize_out_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::_test_autograd_multiple_dispatch_view_copy_out_out)
csrc/autograd/generated/TraceType_3.cpp:         TORCH_FN(TraceType::ccol_indices_copy_out_out)
csrc/autograd/generated/TraceType_1.cpp:#include <ATen/ops/lift_fresh_copy_ops.h>
csrc/autograd/generated/TraceType_1.cpp:#include <ATen/ops/_conj_copy_ops.h>
csrc/autograd/generated/TraceType_1.cpp:#include <ATen/ops/detach_copy_ops.h>
csrc/autograd/generated/TraceType_1.cpp:#include <ATen/ops/row_indices_copy_ops.h>
csrc/autograd/generated/TraceType_1.cpp:#include <ATen/ops/_conj_copy_ops.h>
csrc/autograd/generated/TraceType_1.cpp:#include <ATen/ops/detach_copy_ops.h>
csrc/autograd/generated/TraceType_1.cpp:#include <ATen/ops/lift_fresh_copy_ops.h>
csrc/autograd/generated/TraceType_1.cpp:#include <ATen/ops/row_indices_copy_ops.h>
csrc/autograd/generated/TraceType_1.cpp:at::Tensor & _conj_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_1.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_conj_copy_out", out);
csrc/autograd/generated/TraceType_1.cpp:  at::_ops::_conj_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_1.cpp:at::Tensor & detach_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_1.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("detach_copy_out", out);
csrc/autograd/generated/TraceType_1.cpp:  at::_ops::detach_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_1.cpp:at::Tensor & lift_fresh_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_1.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("lift_fresh_copy_out", out);
csrc/autograd/generated/TraceType_1.cpp:  at::_ops::lift_fresh_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_1.cpp:at::Tensor & row_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_1.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("row_indices_copy_out", out);
csrc/autograd/generated/TraceType_1.cpp:  at::_ops::row_indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_1.cpp:         TORCH_FN(TraceType::_conj_copy_out_out)
csrc/autograd/generated/TraceType_1.cpp:         TORCH_FN(TraceType::detach_copy_out_out)
csrc/autograd/generated/TraceType_1.cpp:         TORCH_FN(TraceType::lift_fresh_copy_out_out)
csrc/autograd/generated/TraceType_1.cpp:         TORCH_FN(TraceType::row_indices_copy_out_out)
csrc/autograd/generated/python_variable_methods.cpp:static Tensor dispatch_copy_(const Tensor & self, const Tensor & other, bool non_blocking) {
csrc/autograd/generated/python_variable_methods.cpp:  return self.copy_(other, non_blocking);
csrc/autograd/generated/python_variable_methods.cpp: static PyObject * THPVariable_copy_(PyObject* self, PyObject* args, PyObject* kwargs)
csrc/autograd/generated/python_variable_methods.cpp:    "copy_(Tensor other, bool non_blocking=False)",
csrc/autograd/generated/python_variable_methods.cpp:    "copy_(Tensor other, bool async=False)|deprecated"
csrc/autograd/generated/python_variable_methods.cpp:  return THPVariable_Wrap(dispatch_copy_(self_, r.tensor(0), r.toBool(1)));
csrc/autograd/generated/python_variable_methods.cpp:// index_copy_
csrc/autograd/generated/python_variable_methods.cpp:static PyObject * THPVariable_index_copy_(PyObject* self_, PyObject* args, PyObject* kwargs)
csrc/autograd/generated/python_variable_methods.cpp:    "index_copy_(int64_t dim, Tensor index, Tensor source)",
csrc/autograd/generated/python_variable_methods.cpp:    "index_copy_(Dimname dim, Tensor index, Tensor source)",
csrc/autograd/generated/python_variable_methods.cpp:      // aten::index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -> Tensor(a!)
csrc/autograd/generated/python_variable_methods.cpp:      auto dispatch_index_copy_ = [](const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) -> at::Tensor {
csrc/autograd/generated/python_variable_methods.cpp:        return self.index_copy_(dim, index, source);
csrc/autograd/generated/python_variable_methods.cpp:      return wrap(dispatch_index_copy_(self, _r.toInt64(0), _r.tensor(1), _r.tensor(2)));
csrc/autograd/generated/python_variable_methods.cpp:      // aten::index_copy_.dimname(Tensor(a!) self, Dimname dim, Tensor index, Tensor source) -> Tensor(a!)
csrc/autograd/generated/python_variable_methods.cpp:      auto dispatch_index_copy_ = [](const at::Tensor & self, at::Dimname dim, const at::Tensor & index, const at::Tensor & source) -> at::Tensor {
csrc/autograd/generated/python_variable_methods.cpp:        return self.index_copy_(dim, index, source);
csrc/autograd/generated/python_variable_methods.cpp:      return wrap(dispatch_index_copy_(self, _r.dimname(0), _r.tensor(1), _r.tensor(2)));
csrc/autograd/generated/python_variable_methods.cpp:    return self.narrow_copy_symint(dim, start, length);
csrc/autograd/generated/python_variable_methods.cpp:  {"copy_", castPyCFunctionWithKeywords(THPVariable_copy_), METH_VARARGS | METH_KEYWORDS, NULL},
csrc/autograd/generated/python_variable_methods.cpp:  {"index_copy_", castPyCFunctionWithKeywords(THPVariable_index_copy_), METH_VARARGS | METH_KEYWORDS, NULL},
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_copy_from_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_copy_from_and_resize_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/narrow_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/narrow_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_reshape_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_nested_view_from_buffer_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_has_compatible_shallow_copy_type_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_to_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/lift_fresh_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_fw_primal_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_make_dual_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/view_as_real_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/view_as_complex_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_conj_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_neg_view_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/as_strided_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_sparse_broadcast_to_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/diagonal_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/expand_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/permute_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_reshape_alias_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/select_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/detach_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/slice_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/split_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/split_with_sizes_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/t_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/transpose_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/unsqueeze_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_values_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/values_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/crow_indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/col_indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/ccol_indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/row_indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/unbind_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/unfold_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/alias_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_fw_primal_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_make_dual_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/view_as_real_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/view_as_complex_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_conj_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_neg_view_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/as_strided_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_sparse_broadcast_to_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/diagonal_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/expand_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/permute_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_reshape_alias_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/select_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/detach_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/slice_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/split_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/split_with_sizes_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/t_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/transpose_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/unsqueeze_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_values_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/values_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/crow_indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/col_indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/unbind_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/unfold_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/alias_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_copy_from_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_copy_from_and_resize_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_nested_view_from_buffer_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_to_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/lift_fresh_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/ccol_indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:#include <ATen/ops/row_indices_copy_ops.h>
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor _copy_from(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst, bool non_blocking) {
csrc/autograd/generated/TraceTypeEverything.cpp:    op_name = c10::Symbol::fromQualString("aten::_copy_from");
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::_copy_from::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dst, non_blocking);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor _copy_from_and_resize(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst) {
csrc/autograd/generated/TraceTypeEverything.cpp:    op_name = c10::Symbol::fromQualString("aten::_copy_from_and_resize");
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::_copy_from_and_resize::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dst);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & index_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("index_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::index_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index, source, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & index_copy_(c10::DispatchKeySet ks, at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
csrc/autograd/generated/TraceTypeEverything.cpp:      op_name = c10::Symbol::fromQualString("aten::index_copy_");
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("index_copy_", self);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::index_copy_::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index, source);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & index_copy__dimname(c10::DispatchKeySet ks, at::Tensor & self, at::Dimname dim, const at::Tensor & index, const at::Tensor & source) {
csrc/autograd/generated/TraceTypeEverything.cpp:      op_name = c10::Symbol::fromQualString("aten::index_copy_");
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("index_copy_", self);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::index_copy__dimname::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index, source);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor index_copy_dimname(c10::DispatchKeySet ks, const at::Tensor & self, at::Dimname dim, const at::Tensor & index, const at::Tensor & source) {
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::index_copy_dimname::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index, source);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & narrow_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("narrow_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::narrow_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, start, length, out);
csrc/autograd/generated/TraceTypeEverything.cpp:bool _has_compatible_shallow_copy_type(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & from) {
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::_has_compatible_shallow_copy_type::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, from);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & copy_sparse_to_sparse_(c10::DispatchKeySet ks, at::Tensor & self, const at::Tensor & src, bool non_blocking) {
csrc/autograd/generated/TraceTypeEverything.cpp:      op_name = c10::Symbol::fromQualString("aten::copy_sparse_to_sparse");
csrc/autograd/generated/TraceTypeEverything.cpp:      op_name = c10::Symbol::fromQualString("aten::copy_sparse_to_sparse_");
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("copy_sparse_to_sparse_", self);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::copy_sparse_to_sparse_::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, src, non_blocking);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor select_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index) {
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::select_copy_int::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor slice_copy_Tensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step) {
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::slice_copy_Tensor::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, start, end, step);
csrc/autograd/generated/TraceTypeEverything.cpp:::std::vector<at::Tensor> split_copy_Tensor(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymInt split_size, int64_t dim) {
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::split_copy_Tensor::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, split_size, dim);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor squeeze_copy_dim(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim) {
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::squeeze_copy_dim::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor squeeze_copy_dims(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim) {
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::squeeze_copy_dims::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor transpose_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim0, int64_t dim1) {
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::transpose_copy_int::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim0, dim1);
csrc/autograd/generated/TraceTypeEverything.cpp:::std::vector<at::Tensor> unbind_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim) {
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::unbind_copy_int::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor view_copy_dtype(c10::DispatchKeySet ks, const at::Tensor & self, at::ScalarType dtype) {
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::view_copy_dtype::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dtype);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _fw_primal_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t level, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_fw_primal_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_fw_primal_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, level, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _make_dual_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & primal, const at::Tensor & tangent, int64_t level, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_make_dual_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_make_dual_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), primal, tangent, level, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & view_as_real_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("view_as_real_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::view_as_real_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & view_as_complex_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("view_as_complex_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::view_as_complex_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _conj_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_conj_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_conj_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _neg_view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_neg_view_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_neg_view_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & as_strided_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("as_strided_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::as_strided_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, size, stride, storage_offset, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _sparse_broadcast_to_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_sparse_broadcast_to_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_sparse_broadcast_to_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, size, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & diagonal_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("diagonal_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::diagonal_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, offset, dim1, dim2, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & expand_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("expand_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::expand_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, size, implicit, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & permute_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("permute_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::permute_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dims, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _reshape_alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_reshape_alias_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_reshape_alias_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, size, stride, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & select_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("select_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::select_copy_int_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, index, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & detach_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("detach_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::detach_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & slice_copy_out_Tensor_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("slice_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::slice_copy_Tensor_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, start, end, step, out);
csrc/autograd/generated/TraceTypeEverything.cpp:void split_copy_out_Tensor_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymInt split_size, int64_t dim, at::TensorList out) {
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::split_copy_Tensor_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, split_size, dim, out);
csrc/autograd/generated/TraceTypeEverything.cpp:void split_with_sizes_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim, at::TensorList out) {
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::split_with_sizes_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, split_sizes, dim, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & squeeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("squeeze_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::squeeze_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & squeeze_copy_out_dim_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("squeeze_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::squeeze_copy_dim_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & squeeze_copy_out_dims_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("squeeze_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::squeeze_copy_dims_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & t_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("t_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::t_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & transpose_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("transpose_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::transpose_copy_int_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim0, dim1, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & unsqueeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("unsqueeze_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::unsqueeze_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_indices_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_values_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_values_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("indices_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("values_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::values_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & crow_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("crow_indices_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::crow_indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & col_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("col_indices_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::col_indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:void unbind_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::TensorList out) {
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::unbind_copy_int_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("view_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::view_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, size, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & view_copy_out_dtype_out(c10::DispatchKeySet ks, const at::Tensor & self, at::ScalarType dtype, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("view_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::view_copy_dtype_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dtype, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & unfold_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("unfold_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::unfold_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dimension, size, step, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("alias_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::alias_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, src, non_blocking, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _copy_from_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    op_name = c10::Symbol::fromQualString("aten::_copy_from");
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_copy_from_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_copy_from_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dst, non_blocking, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _copy_from_and_resize_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    op_name = c10::Symbol::fromQualString("aten::_copy_from_and_resize");
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_copy_from_and_resize_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_copy_from_and_resize_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dst, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _nested_view_from_buffer_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_nested_view_from_buffer_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_nested_view_from_buffer_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, nested_size, nested_strides, offsets, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & copy_sparse_to_sparse_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    op_name = c10::Symbol::fromQualString("aten::copy_sparse_to_sparse");
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("copy_sparse_to_sparse_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::copy_sparse_to_sparse_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, src, non_blocking, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor copy_sparse_to_sparse(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & src, bool non_blocking) {
csrc/autograd/generated/TraceTypeEverything.cpp:    op_name = c10::Symbol::fromQualString("aten::copy_sparse_to_sparse");
csrc/autograd/generated/TraceTypeEverything.cpp:  auto result =at::_ops::copy_sparse_to_sparse::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, src, non_blocking);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _to_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, bool non_blocking, c10::optional<at::MemoryFormat> memory_format, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_to_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_to_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, non_blocking, memory_format, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & lift_fresh_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("lift_fresh_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::lift_fresh_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & _test_autograd_multiple_dispatch_view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_test_autograd_multiple_dispatch_view_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::_test_autograd_multiple_dispatch_view_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & ccol_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("ccol_indices_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::ccol_indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:at::Tensor & row_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceTypeEverything.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("row_indices_copy_out", out);
csrc/autograd/generated/TraceTypeEverything.cpp:  at::_ops::row_indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceTypeEverything.cpp:  m.impl("_copy_from",
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_copy_from)
csrc/autograd/generated/TraceTypeEverything.cpp:  m.impl("_copy_from_and_resize",
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_copy_from_and_resize)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::index_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:  m.impl("index_copy_",
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::index_copy_)
csrc/autograd/generated/TraceTypeEverything.cpp:  m.impl("index_copy_.dimname",
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::index_copy__dimname)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::index_copy_dimname)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::narrow_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:  m.impl("_has_compatible_shallow_copy_type",
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_has_compatible_shallow_copy_type)
csrc/autograd/generated/TraceTypeEverything.cpp:  m.impl("copy_sparse_to_sparse_",
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::copy_sparse_to_sparse_)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::select_copy_int)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::slice_copy_Tensor)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::split_copy_Tensor)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::squeeze_copy_dim)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::squeeze_copy_dims)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::transpose_copy_int)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::unbind_copy_int)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::view_copy_dtype)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_fw_primal_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_make_dual_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::view_as_real_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::view_as_complex_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_conj_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_neg_view_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::as_strided_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_sparse_broadcast_to_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::diagonal_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::expand_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::permute_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_reshape_alias_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::select_copy_out_int_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::detach_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::slice_copy_out_Tensor_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::split_copy_out_Tensor_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::split_with_sizes_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::squeeze_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::squeeze_copy_out_dim_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::squeeze_copy_out_dims_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::t_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::transpose_copy_out_int_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::unsqueeze_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_indices_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_values_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::indices_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::values_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::crow_indices_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::col_indices_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::unbind_copy_out_int_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::view_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::view_copy_out_dtype_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::unfold_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::alias_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:  m.impl("_copy_from.out",
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_copy_from_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:  m.impl("_copy_from_and_resize.out",
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_copy_from_and_resize_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_nested_view_from_buffer_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:  m.impl("copy_sparse_to_sparse.out",
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::copy_sparse_to_sparse_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:  m.impl("copy_sparse_to_sparse",
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::copy_sparse_to_sparse)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_to_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::lift_fresh_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::_test_autograd_multiple_dispatch_view_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::ccol_indices_copy_out_out)
csrc/autograd/generated/TraceTypeEverything.cpp:         TORCH_FN(TraceType::row_indices_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor _test_autograd_multiple_dispatch_view_copy_AutogradCUDA(c10::DispatchKeySet ks, const at::Tensor & self) {
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor select_copy_int_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index) {
csrc/autograd/generated/VariableTypeEverything.cpp:      return at::redispatch::select_copy_symint(ks & c10::after_autograd_keyset, self_, dim, index);
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: select_copy_int");
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.use_count() <= 1, "function: select_copy_int");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & select_copy_out_int_out_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::select_copy_symint_outf(ks & c10::after_autograd_keyset, self_, dim, index, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with select_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor squeeze_copy_dim_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim) {
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: squeeze_copy_dim");
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.use_count() <= 1, "function: squeeze_copy_dim");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor squeeze_copy_dims_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim) {
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: squeeze_copy_dims");
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.use_count() <= 1, "function: squeeze_copy_dims");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & squeeze_copy_out_dim_out_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::squeeze_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with squeeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & squeeze_copy_out_dims_out_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::squeeze_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with squeeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor values_copy_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self) {
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & values_copy_out_out_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::values_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with values_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor view_copy_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size) {
csrc/autograd/generated/VariableTypeEverything.cpp:    return at::redispatch::view_copy_symint(ks & c10::after_autograd_keyset, self_, size);
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & view_copy_out_out_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::view_copy_symint_outf(ks & c10::after_autograd_keyset, self_, size, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with view_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & _conj_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::_conj_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with _conj_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & _indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::_indices_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with _indices_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & _neg_view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::_neg_view_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with _neg_view_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:    return at::redispatch::_reshape_alias_copy_symint(ks & c10::after_autograd_keyset, self_, size, stride);
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & _reshape_alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::_reshape_alias_copy_symint_outf(ks & c10::after_autograd_keyset, self_, size, stride, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with _reshape_alias_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:    return at::redispatch::_reshape_copy_symint(ks & c10::after_autograd_keyset, self_, size);
csrc/autograd/generated/VariableTypeEverything.cpp:      result_new_fw_grad_opt = at::_reshape_copy_symint(self_t, size);
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & _values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::_values_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with _values_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(handle_r_to_c(self_p.scalar_type(), original_self_t.conj() * original_self_p.sgn())) : handle_r_to_c(self_p.scalar_type(), original_self_t.conj() * original_self_p.sgn());
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * -((-original_self_p * original_self_p + 1).rsqrt()).conj()).conj()) : (original_self_t.conj() * -((-original_self_p * original_self_p + 1).rsqrt()).conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t + maybe_multiply(other_t, alpha)) : self_t + maybe_multiply(other_t, alpha);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t.clone()) : self_t.clone();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(maybe_multiply(self_t, beta) + maybe_multiply(batch1_t.bmm(batch2_p).sum(0), alpha) + maybe_multiply(batch1_p.bmm(batch2_t).sum(0), alpha)) : maybe_multiply(self_t, beta) + maybe_multiply(batch1_t.bmm(batch2_p).sum(0), alpha) + maybe_multiply(batch1_p.bmm(batch2_t).sum(0), alpha);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t + maybe_multiply(tensor1_t / tensor2_p, value) - maybe_multiply(tensor2_t * (tensor1_p / tensor2_p) / tensor2_p, value)) : self_t + maybe_multiply(tensor1_t / tensor2_p, value) - maybe_multiply(tensor2_t * (tensor1_p / tensor2_p) / tensor2_p, value);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t + maybe_multiply(tensor1_t * tensor2_p, value) + maybe_multiply(tensor2_t * tensor1_p, value)) : self_t + maybe_multiply(tensor1_t * tensor2_p, value) + maybe_multiply(tensor2_t * tensor1_p, value);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(maybe_multiply(self_t, beta) + maybe_multiply(mat1_t.mm(mat2_p), alpha) + maybe_multiply(mat1_p.mm(mat2_t), alpha)) : maybe_multiply(self_t, beta) + maybe_multiply(mat1_t.mm(mat2_p), alpha) + maybe_multiply(mat1_p.mm(mat2_t), alpha);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(maybe_multiply(self_t, beta) + maybe_multiply(mat_t.mv(vec_p), alpha) + maybe_multiply(mat_p.mv(vec_t), alpha)) : maybe_multiply(self_t, beta) + maybe_multiply(mat_t.mv(vec_p), alpha) + maybe_multiply(mat_p.mv(vec_t), alpha);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(maybe_multiply(self_t, beta) + maybe_multiply(vec1_t.outer(vec2_p), alpha) + maybe_multiply(vec1_p.outer(vec2_t), alpha)) : maybe_multiply(self_t, beta) + maybe_multiply(vec1_t.outer(vec2_p), alpha) + maybe_multiply(vec1_p.outer(vec2_t), alpha);
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::alias_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with alias_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:    return at::redispatch::as_strided_copy_symint(ks & c10::after_autograd_keyset, self_, size, stride, storage_offset);
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & as_strided_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::as_strided_copy_symint_outf(ks & c10::after_autograd_keyset, self_, size, stride, storage_offset, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with as_strided_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * (-original_self_p * original_self_p + 1).rsqrt().conj()).conj()) : (original_self_t.conj() * (-original_self_p * original_self_p + 1).rsqrt().conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((-original_self_p * other_t + other_p * original_self_t) / (original_self_p.pow(2) + other_p.pow(2))) : (-original_self_p * other_t + other_p * original_self_t) / (original_self_p.pow(2) + other_p.pow(2));
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() / (original_self_p * original_self_p + 1).conj()).conj()) : (original_self_t.conj() / (original_self_p * original_self_p + 1).conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(maybe_multiply(self_t, beta) + maybe_multiply(batch1_t.bmm(batch2_p), alpha) + maybe_multiply(batch1_p.bmm(batch2_t), alpha)) : maybe_multiply(self_t, beta) + maybe_multiply(batch1_t.bmm(batch2_p), alpha) + maybe_multiply(batch1_p.bmm(batch2_t), alpha);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t.copy_(elu_backward(original_self_t, alpha, 1, 1.0/alpha.toFloat(), /* is_result */ true, self_p));
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((clamp_backward(original_self_t.conj(), original_self_p, min, max)).conj()) : (clamp_backward(original_self_t.conj(), original_self_p, min, max)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(clamp_jvp(original_self_p, original_self_t, min_p, min_t, max_p, max_t)) : clamp_jvp(original_self_p, original_self_t, min_p, min_t, max_p, max_t);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((where(original_self_p <= max, original_self_t.conj(), at::scalar_tensor(0., original_self_t.conj().options()))).conj()) : (where(original_self_p <= max, original_self_t.conj(), at::scalar_tensor(0., original_self_t.conj().options()))).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(where(original_self_p <= max_p, original_self_t, max_t)) : where(original_self_p <= max_p, original_self_t, max_t);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((where(original_self_p >= min, original_self_t.conj(), at::scalar_tensor(0., original_self_t.conj().options()))).conj()) : (where(original_self_p >= min, original_self_t.conj(), at::scalar_tensor(0., original_self_t.conj().options()))).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(where(original_self_p >= min_p, original_self_t, min_t)) : where(original_self_p >= min_p, original_self_t, min_t);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(copysign_tensor_self_backward(original_self_t, original_self_p, self_p)) : copysign_tensor_self_backward(original_self_t, original_self_p, self_p);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((copysign_tensor_self_backward(original_self_t.conj(), original_self_p, self_p)).conj()) : (copysign_tensor_self_backward(original_self_t.conj(), original_self_p, self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * -original_self_p.sin().conj()).conj()) : (original_self_t.conj() * -original_self_p.sin().conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * original_self_p.sinh().conj()).conj()) : (original_self_t.conj() * original_self_p.sinh().conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(cumprod_jvp(original_self_t, original_self_p, self_p, dim).to(dtype.has_value() ? *dtype : original_self_p.scalar_type())) : cumprod_jvp(original_self_t, original_self_p, self_p, dim).to(dtype.has_value() ? *dtype : original_self_p.scalar_type());
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::cumsum(self_t, dim, dtype)) : at::cumsum(self_t, dim, dtype);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((deg2rad_backward(self_t.conj())).conj()) : (deg2rad_backward(self_t.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & diagonal_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::diagonal_copy_outf(ks & c10::after_autograd_keyset, self_, offset, dim1, dim2, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with diagonal_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * polygamma(1, original_self_p)).conj()) : (original_self_t.conj() * polygamma(1, original_self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t - other_t * self_p) / other_p) : (self_t - other_t * self_p) / other_p;
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(rounding_mode.has_value() ? self_p.new_zeros_symint(self_p.sym_sizes()) : original_self_t / other_p - other_t * (original_self_p / other_p) / other_p) : rounding_mode.has_value() ? self_p.new_zeros_symint(self_p.sym_sizes()) : original_self_t / other_p - other_t * (original_self_p / other_p) / other_p;
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t / other) : self_t / other;
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(rounding_mode.has_value() ? self_p.new_zeros_symint(self_p.sym_sizes()) : self_t / other) : rounding_mode.has_value() ? self_p.new_zeros_symint(self_p.sym_sizes()) : self_t / other;
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t.copy_(elu_backward(original_self_t, alpha, scale, input_scale, /* is_result */ true, self_p));
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((2.0 / sqrt(M_PI) * exp(-(original_self_p.pow(2))) * original_self_t.conj()).conj()) : (2.0 / sqrt(M_PI) * exp(-(original_self_p.pow(2))) * original_self_t.conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((-2.0 / sqrt(M_PI) * exp(-(original_self_p.pow(2))) * original_self_t.conj()).conj()) : (-2.0 / sqrt(M_PI) * exp(-(original_self_p.pow(2))) * original_self_t.conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((0.5 * sqrt(M_PI) * exp(original_self_p.erfinv().pow(2)) * original_self_t.conj()).conj()) : (0.5 * sqrt(M_PI) * exp(original_self_p.erfinv().pow(2)) * original_self_t.conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj() * self_p * M_LN2).conj()) : (self_t.conj() * self_p * M_LN2).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj() * self_p.conj()).conj()) : (self_t.conj() * self_p.conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:    return at::redispatch::expand_copy_symint(ks & c10::after_autograd_keyset, self_, size, implicit);
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & expand_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::expand_copy_symint_outf(ks & c10::after_autograd_keyset, self_, size, implicit, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with expand_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj() * (self_p + 1)).conj()) : (self_t.conj() * (self_p + 1)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj()).conj()) : (self_t.conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(original_self_t - other_t * original_self_p.div(other_p, /*rounding_mode=*/"trunc")) : original_self_t - other_t * original_self_p.div(other_p, /*rounding_mode=*/"trunc");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t) : self_t;
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((gelu_backward(original_self_t.conj(), original_self_p, approximate)).conj()) : (gelu_backward(original_self_t.conj(), original_self_p, approximate)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((hardsigmoid_backward(original_self_t.conj(), original_self_p)).conj()) : (hardsigmoid_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((hardswish_backward(original_self_t.conj(), original_self_p)).conj()) : (hardswish_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((hardtanh_backward(original_self_t.conj(), original_self_p, min_val, max_val)).conj()) : (hardtanh_backward(original_self_t.conj(), original_self_p, min_val, max_val)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(original_self_t * original_self_p / self_p + other_t * other_p / self_p) : original_self_t * original_self_p / self_p + other_t * other_p / self_p;
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * at::special_i1(original_self_p)).conj()) : (original_self_t.conj() * at::special_i1(original_self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::index_add(self_t, dim, index, maybe_multiply(source_t, alpha))) : at::index_add(self_t, dim, index, maybe_multiply(source_t, alpha));
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & index_copy_(c10::DispatchKeySet ks, at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::index_copy_(ks & c10::after_autograd_keyset, self_, dim, index_, source_);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.index_copy_(dim, index, source_t) : self_t.index_copy(dim, index, source_t);
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & index_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::index_copy_outf(ks & c10::after_autograd_keyset, self_, dim, index_, source_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(source) || isFwGradDefined(out))), "Trying to use forward AD with index_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::indices_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with indices_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t.copy_(leaky_relu_backward(original_self_t.conj(), self_p, negative_slope, true).conj());
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::lerp(self_t, end_t, weight)) : at::lerp(self_t, end_t, weight);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::lerp(original_self_t, end_t, weight_p) + weight_t * (end_p - original_self_p)) : at::lerp(original_self_t, end_t, weight_p) + weight_t * (end_p - original_self_p);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * digamma(original_self_p)).conj()) : (original_self_t.conj() * digamma(original_self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() / (original_self_p.conj() * 2.3025850929940456)).conj()) : (original_self_t.conj() / (original_self_p.conj() * 2.3025850929940456)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((log1p_backward(original_self_t.conj(), original_self_p)).conj()) : (log1p_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() / (original_self_p.conj() * 0.6931471805599453)).conj()) : (original_self_t.conj() / (original_self_p.conj() * 0.6931471805599453)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj().div(original_self_p.conj())).conj()) : (original_self_t.conj().div(original_self_p.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((GradMode::is_enabled() ? infinitely_differentiable_logit_backward(original_self_t.conj(), original_self_p, eps) : logit_backward(original_self_t.conj(), original_self_p, eps)).conj()) : (GradMode::is_enabled() ? infinitely_differentiable_logit_backward(original_self_t.conj(), original_self_p, eps) : logit_backward(original_self_t.conj(), original_self_p, eps)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((GradMode::is_enabled() ? infinitely_differentiable_mish_backward(original_self_t.conj(), original_self_p) : mish_backward(original_self_t.conj(), original_self_p)).conj()) : (GradMode::is_enabled() ? infinitely_differentiable_mish_backward(original_self_t.conj(), original_self_p) : mish_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(other_t * original_self_p + original_self_t * other_p) : other_t * original_self_p + original_self_t * other_p;
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t * other) : self_t * other;
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((mvlgamma_backward(original_self_t.conj(), original_self_p, p)).conj()) : (mvlgamma_backward(original_self_t.conj(), original_self_p, p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * at::isfinite(original_self_p)).conj()) : (original_self_t.conj() * at::isfinite(original_self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj().neg()).conj()) : (self_t.conj().neg()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & permute_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::permute_copy_outf(ks & c10::after_autograd_keyset, self_, dims, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with permute_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((pow_backward(original_self_t.conj(), original_self_p, exponent)).conj()) : (pow_backward(original_self_t.conj(), original_self_p, exponent)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((pow_backward_self(original_self_t.conj(), original_self_p, exponent_p) + pow_backward_exponent(exponent_t.conj(), original_self_p, exponent_p, self_p)).conj()) : (pow_backward_self(original_self_t.conj(), original_self_p, exponent_p) + pow_backward_exponent(exponent_t.conj(), original_self_p, exponent_p, self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((rad2deg_backward(self_t.conj())).conj()) : (rad2deg_backward(self_t.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((-self_t.conj() * (self_p * self_p).conj()).conj()) : (-self_t.conj() * (self_p * self_p).conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((threshold_backward(self_t.conj(), self_p, 0)).conj()) : (threshold_backward(self_t.conj(), self_p, 0)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj()).conj()) : (self_t.conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(original_self_t - other_t * original_self_p.div(other_p, /*rounding_mode=*/"floor")) : original_self_t - other_t * original_self_p.div(other_p, /*rounding_mode=*/"floor");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((-0.5 * self_t.conj() * self_p.pow(3).conj()).conj()) : (-0.5 * self_t.conj() * self_p.pow(3).conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(scatter_add(self_t, dim, index, src_t)) : scatter_add(self_t, dim, index, src_t);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(scatter_reduce_jvp(original_self_p, original_self_t, dim, index, src_p, src_t, reduce, include_self, self_p)) : scatter_reduce_jvp(original_self_p, original_self_t, dim, index, src_p, src_t, reduce, include_self, self_p);
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor select_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index) {
csrc/autograd/generated/VariableTypeEverything.cpp:    return at::redispatch::select_copy_symint(ks & c10::after_autograd_keyset, self_, dim, index);
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: select_copy_int");
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.use_count() <= 1, "function: select_copy_int");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & select_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::select_copy_symint_outf(ks & c10::after_autograd_keyset, self_, dim, index, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with select_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(sgn_backward(original_self_p, original_self_t, self_p)) : sgn_backward(original_self_p, original_self_t, self_p);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((sigmoid_backward(self_t.conj(), self_p)).conj()) : (sigmoid_backward(self_t.conj(), self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((GradMode::is_enabled() ? infinitely_differentiable_silu_backward(original_self_t.conj(), original_self_p) : silu_backward(original_self_t.conj(), original_self_p)).conj()) : (GradMode::is_enabled() ? infinitely_differentiable_silu_backward(original_self_t.conj(), original_self_p) : silu_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * original_self_p.cos().conj()).conj()) : (original_self_t.conj() * original_self_p.cos().conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((sinc_backward(original_self_t.conj(), original_self_p)).conj()) : (sinc_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * original_self_p.cosh().conj()).conj()) : (original_self_t.conj() * original_self_p.cosh().conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor slice_copy_Tensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step) {
csrc/autograd/generated/VariableTypeEverything.cpp:    return at::redispatch::slice_copy_symint(ks & c10::after_autograd_keyset, self_, dim, start, end, step);
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: slice_copy_Tensor");
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.use_count() <= 1, "function: slice_copy_Tensor");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & slice_copy_out_Tensor_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::slice_copy_symint_outf(ks & c10::after_autograd_keyset, self_, dim, start, end, step, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with slice_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:::std::vector<at::Tensor> split_copy_Tensor(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymInt split_size, int64_t dim) {
csrc/autograd/generated/VariableTypeEverything.cpp:    return at::redispatch::split_copy_symint(ks & c10::after_autograd_keyset, self_, split_size, dim);
csrc/autograd/generated/VariableTypeEverything.cpp:void split_copy_out_Tensor_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymInt split_size, int64_t dim, at::TensorList out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::split_copy_symint_outf(ks & c10::after_autograd_keyset, self_, split_size, dim, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefinedTensorList(out))), "Trying to use forward AD with split_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:    return at::redispatch::split_with_sizes_copy_symint(ks & c10::after_autograd_keyset, self_, split_sizes, dim);
csrc/autograd/generated/VariableTypeEverything.cpp:void split_with_sizes_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim, at::TensorList out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::split_with_sizes_copy_symint_outf(ks & c10::after_autograd_keyset, self_, split_sizes, dim, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefinedTensorList(out))), "Trying to use forward AD with split_with_sizes_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj() / (2 * self_p.conj())).conj()) : (self_t.conj() / (2 * self_p.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor squeeze_copy_dim(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim) {
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: squeeze_copy_dim");
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.use_count() <= 1, "function: squeeze_copy_dim");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor squeeze_copy_dims(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim) {
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: squeeze_copy_dims");
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.use_count() <= 1, "function: squeeze_copy_dims");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & squeeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::squeeze_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with squeeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & squeeze_copy_out_dim_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::squeeze_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with squeeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & squeeze_copy_out_dims_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::squeeze_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with squeeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t - maybe_multiply(other_t, alpha)) : self_t - maybe_multiply(other_t, alpha);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((handle_r_to_c(original_self_p.scalar_type(), original_self_t.conj())).conj()) : (handle_r_to_c(original_self_p.scalar_type(), original_self_t.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & t_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::t_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with t_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj() * (1 + self_p.pow(2)).conj()).conj()) : (self_t.conj() * (1 + self_p.pow(2)).conj()).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((tanh_backward(self_t.conj(), self_p)).conj()) : (tanh_backward(self_t.conj(), self_p)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t.copy_(threshold_backward(self_t.conj(), original_self_p, threshold).conj());
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor transpose_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim0, int64_t dim1) {
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: transpose_copy_int");
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.use_count() <= 1, "function: transpose_copy_int");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & transpose_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::transpose_copy_outf(ks & c10::after_autograd_keyset, self_, dim0, dim1, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with transpose_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::tril(self_t, diagonal)) : at::tril(self_t, diagonal);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::triu(self_t, diagonal)) : at::triu(self_t, diagonal);
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:::std::vector<at::Tensor> unbind_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim) {
csrc/autograd/generated/VariableTypeEverything.cpp:void unbind_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::TensorList out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::unbind_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefinedTensorList(out))), "Trying to use forward AD with unbind_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & unfold_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::unfold_copy_outf(ks & c10::after_autograd_keyset, self_, dimension, size, step, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with unfold_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & unsqueeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::unsqueeze_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with unsqueeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::values_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with values_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & view_as_complex_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::view_as_complex_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with view_as_complex_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & view_as_real_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::view_as_real_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with view_as_real_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:    return at::redispatch::view_copy_symint(ks & c10::after_autograd_keyset, self_, size);
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor view_copy_dtype(c10::DispatchKeySet ks, const at::Tensor & self, at::ScalarType dtype) {
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: view_copy_dtype");
csrc/autograd/generated/VariableTypeEverything.cpp:    AT_ASSERT(result.use_count() <= 1, "function: view_copy_dtype");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::view_copy_symint_outf(ks & c10::after_autograd_keyset, self_, size, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with view_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:at::Tensor & view_copy_out_dtype_out(c10::DispatchKeySet ks, const at::Tensor & self, at::ScalarType dtype, at::Tensor & out) {
csrc/autograd/generated/VariableTypeEverything.cpp:    at::redispatch::view_copy_outf(ks & c10::after_autograd_keyset, self_, dtype, out_);
csrc/autograd/generated/VariableTypeEverything.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with view_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::xlogy(original_self_t, other_p).masked_fill((original_self_p == 0.) & (other_p <= 0.), 0.) + other_t * original_self_p / other_p) : at::xlogy(original_self_t, other_p).masked_fill((original_self_p == 0.) & (other_p <= 0.), 0.) + other_t * original_self_p / other_p;
csrc/autograd/generated/VariableTypeEverything.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((other.toDouble() > 0. ? at::xlogy(original_self_t.conj(),  other) : at::xlogy(original_self_t.conj(),  other).masked_fill(original_self_p == 0., 0.)).conj()) : (other.toDouble() > 0. ? at::xlogy(original_self_t.conj(),  other) : at::xlogy(original_self_t.conj(),  other).masked_fill(original_self_p == 0., 0.)).conj();
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::_test_autograd_multiple_dispatch_view_copy_AutogradCUDA)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::select_copy_int_AutogradNestedTensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::select_copy_out_int_out_AutogradNestedTensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::squeeze_copy_dim_AutogradNestedTensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::squeeze_copy_dims_AutogradNestedTensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::squeeze_copy_out_dim_out_AutogradNestedTensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::squeeze_copy_out_dims_out_AutogradNestedTensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::values_copy_AutogradNestedTensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::values_copy_out_out_AutogradNestedTensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::view_copy_AutogradNestedTensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::view_copy_out_out_AutogradNestedTensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::_conj_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:m.impl("_copy_from", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableTypeEverything.cpp:m.impl("_copy_from_and_resize", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableTypeEverything.cpp:m.impl("_copy_from_and_resize.out", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableTypeEverything.cpp:m.impl("_copy_from.out", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::_indices_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::_neg_view_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::_reshape_alias_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::_values_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::alias_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::as_strided_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:m.impl("copy_sparse_to_sparse", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableTypeEverything.cpp:m.impl("copy_sparse_to_sparse_", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableTypeEverything.cpp:m.impl("copy_sparse_to_sparse.out", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::diagonal_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::expand_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:m.impl("index_copy_",
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::index_copy_)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::index_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::indices_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::permute_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::select_copy_int)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::select_copy_out_int_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::slice_copy_Tensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::slice_copy_out_Tensor_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::split_copy_Tensor)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::split_copy_out_Tensor_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::split_with_sizes_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::squeeze_copy_dim)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::squeeze_copy_dims)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::squeeze_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::squeeze_copy_out_dim_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::squeeze_copy_out_dims_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::t_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::transpose_copy_int)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::transpose_copy_out_int_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::unbind_copy_int)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::unbind_copy_out_int_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::unfold_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::unsqueeze_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::values_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::view_as_complex_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::view_as_real_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::view_copy_dtype)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::view_copy_out_out)
csrc/autograd/generated/VariableTypeEverything.cpp:       TORCH_FN(VariableType::view_copy_out_dtype_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/_conj_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/_copy_from_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/_make_dual_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/_neg_view_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/_nested_view_from_buffer_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/_to_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/ccol_indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/detach_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/diagonal_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/permute_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/row_indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/slice_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/t_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/transpose_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/unfold_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/view_as_complex_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:#include <ATen/ops/view_as_real_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & _conj_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::_conj_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & _copy_from_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::_copy_from_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dst, non_blocking, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & _make_dual_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & primal, const at::Tensor & tangent, int64_t level, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::_make_dual_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, primal, tangent, level, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & _neg_view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::_neg_view_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & _nested_view_from_buffer_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::_nested_view_from_buffer_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, nested_size, nested_strides, offsets, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & _test_autograd_multiple_dispatch_view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::_test_autograd_multiple_dispatch_view_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & _to_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, bool non_blocking, c10::optional<at::MemoryFormat> memory_format, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::_to_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, non_blocking, memory_format, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & ccol_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::ccol_indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, src, non_blocking, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & detach_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::detach_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & diagonal_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::diagonal_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, offset, dim1, dim2, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & permute_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::permute_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dims, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & row_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::row_indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & slice_copy_out_Tensor_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::slice_copy_Tensor_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, start, end, step, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & t_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::t_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & transpose_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::transpose_copy_int_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim0, dim1, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & unfold_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::unfold_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dimension, size, step, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & view_as_complex_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::view_as_complex_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:at::Tensor & view_as_real_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:    at::_ops::view_as_real_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::_conj_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:  m.impl("_copy_from.out",
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::_copy_from_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::_make_dual_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::_neg_view_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::_nested_view_from_buffer_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::_test_autograd_multiple_dispatch_view_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::_to_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::ccol_indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::detach_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::diagonal_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::permute_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::row_indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::slice_copy_out_Tensor_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::t_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::transpose_copy_out_int_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::unfold_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::view_as_complex_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewType_0.cpp:         TORCH_FN(ADInplaceOrView::view_as_real_copy_out_out)
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/_sparse_broadcast_to_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/transpose_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/_indices_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/_values_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/values_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/unfold_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/_sparse_broadcast_to_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/transpose_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/_indices_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/_values_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/values_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:#include <ATen/ops/unfold_copy_ops.h>
csrc/autograd/generated/TraceType_2.cpp:at::Tensor transpose_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim0, int64_t dim1) {
csrc/autograd/generated/TraceType_2.cpp:  auto result =at::_ops::transpose_copy_int::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim0, dim1);
csrc/autograd/generated/TraceType_2.cpp:at::Tensor view_copy_dtype(c10::DispatchKeySet ks, const at::Tensor & self, at::ScalarType dtype) {
csrc/autograd/generated/TraceType_2.cpp:  auto result =at::_ops::view_copy_dtype::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dtype);
csrc/autograd/generated/TraceType_2.cpp:at::Tensor & _sparse_broadcast_to_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/TraceType_2.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_sparse_broadcast_to_copy_out", out);
csrc/autograd/generated/TraceType_2.cpp:  at::_ops::_sparse_broadcast_to_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, size, out);
csrc/autograd/generated/TraceType_2.cpp:at::Tensor & transpose_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out) {
csrc/autograd/generated/TraceType_2.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("transpose_copy_out", out);
csrc/autograd/generated/TraceType_2.cpp:  at::_ops::transpose_copy_int_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dim0, dim1, out);
csrc/autograd/generated/TraceType_2.cpp:at::Tensor & _indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_2.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_indices_copy_out", out);
csrc/autograd/generated/TraceType_2.cpp:  at::_ops::_indices_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_2.cpp:at::Tensor & _values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_2.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("_values_copy_out", out);
csrc/autograd/generated/TraceType_2.cpp:  at::_ops::_values_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_2.cpp:at::Tensor & values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/TraceType_2.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("values_copy_out", out);
csrc/autograd/generated/TraceType_2.cpp:  at::_ops::values_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, out);
csrc/autograd/generated/TraceType_2.cpp:at::Tensor & view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/TraceType_2.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("view_copy_out", out);
csrc/autograd/generated/TraceType_2.cpp:  at::_ops::view_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, size, out);
csrc/autograd/generated/TraceType_2.cpp:at::Tensor & view_copy_out_dtype_out(c10::DispatchKeySet ks, const at::Tensor & self, at::ScalarType dtype, at::Tensor & out) {
csrc/autograd/generated/TraceType_2.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("view_copy_out", out);
csrc/autograd/generated/TraceType_2.cpp:  at::_ops::view_copy_dtype_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dtype, out);
csrc/autograd/generated/TraceType_2.cpp:at::Tensor & unfold_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out) {
csrc/autograd/generated/TraceType_2.cpp:    jit::tracer::ensureUniqueIfOutOfPlaced("unfold_copy_out", out);
csrc/autograd/generated/TraceType_2.cpp:  at::_ops::unfold_copy_out::redispatch(ks & c10::DispatchKeySet(c10::DispatchKeySet::FULL_AFTER, c10::DispatchKey::Tracer), self, dimension, size, step, out);
csrc/autograd/generated/TraceType_2.cpp:         TORCH_FN(TraceType::transpose_copy_int)
csrc/autograd/generated/TraceType_2.cpp:         TORCH_FN(TraceType::view_copy_dtype)
csrc/autograd/generated/TraceType_2.cpp:         TORCH_FN(TraceType::_sparse_broadcast_to_copy_out_out)
csrc/autograd/generated/TraceType_2.cpp:         TORCH_FN(TraceType::transpose_copy_out_int_out)
csrc/autograd/generated/TraceType_2.cpp:         TORCH_FN(TraceType::_indices_copy_out_out)
csrc/autograd/generated/TraceType_2.cpp:         TORCH_FN(TraceType::_values_copy_out_out)
csrc/autograd/generated/TraceType_2.cpp:         TORCH_FN(TraceType::values_copy_out_out)
csrc/autograd/generated/TraceType_2.cpp:         TORCH_FN(TraceType::view_copy_out_out)
csrc/autograd/generated/TraceType_2.cpp:         TORCH_FN(TraceType::view_copy_out_dtype_out)
csrc/autograd/generated/TraceType_2.cpp:         TORCH_FN(TraceType::unfold_copy_out_out)
csrc/autograd/generated/VariableType_4.cpp:at::Tensor select_copy_int_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index) {
csrc/autograd/generated/VariableType_4.cpp:      return at::redispatch::select_copy_symint(ks & c10::after_autograd_keyset, self_, dim, index);
csrc/autograd/generated/VariableType_4.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: select_copy_int");
csrc/autograd/generated/VariableType_4.cpp:    AT_ASSERT(result.use_count() <= 1, "function: select_copy_int");
csrc/autograd/generated/VariableType_4.cpp:at::Tensor & _indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_4.cpp:    at::redispatch::_indices_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_4.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with _indices_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_4.cpp:at::Tensor & _reshape_alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out) {
csrc/autograd/generated/VariableType_4.cpp:    at::redispatch::_reshape_alias_copy_symint_outf(ks & c10::after_autograd_keyset, self_, size, stride, out_);
csrc/autograd/generated/VariableType_4.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with _reshape_alias_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_4.cpp:    return at::redispatch::_reshape_copy_symint(ks & c10::after_autograd_keyset, self_, size);
csrc/autograd/generated/VariableType_4.cpp:      result_new_fw_grad_opt = at::_reshape_copy_symint(self_t, size);
csrc/autograd/generated/VariableType_4.cpp:at::Tensor & _values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_4.cpp:    at::redispatch::_values_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_4.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with _values_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(copysign_tensor_self_backward(original_self_t, original_self_p, self_p)) : copysign_tensor_self_backward(original_self_t, original_self_p, self_p);
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((copysign_tensor_self_backward(original_self_t.conj(), original_self_p, self_p)).conj()) : (copysign_tensor_self_backward(original_self_t.conj(), original_self_p, self_p)).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((deg2rad_backward(self_t.conj())).conj()) : (deg2rad_backward(self_t.conj())).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t.copy_(elu_backward(original_self_t, alpha, scale, input_scale, /* is_result */ true, self_p));
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((0.5 * sqrt(M_PI) * exp(original_self_p.erfinv().pow(2)) * original_self_t.conj()).conj()) : (0.5 * sqrt(M_PI) * exp(original_self_p.erfinv().pow(2)) * original_self_t.conj()).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((hardswish_backward(original_self_t.conj(), original_self_p)).conj()) : (hardswish_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((hardtanh_backward(original_self_t.conj(), original_self_p, min_val, max_val)).conj()) : (hardtanh_backward(original_self_t.conj(), original_self_p, min_val, max_val)).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * at::special_i1(original_self_p)).conj()) : (original_self_t.conj() * at::special_i1(original_self_p)).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::index_add(self_t, dim, index, maybe_multiply(source_t, alpha))) : at::index_add(self_t, dim, index, maybe_multiply(source_t, alpha));
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t.copy_(leaky_relu_backward(original_self_t.conj(), self_p, negative_slope, true).conj());
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((log1p_backward(original_self_t.conj(), original_self_p)).conj()) : (log1p_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() / (original_self_p.conj() * 0.6931471805599453)).conj()) : (original_self_t.conj() / (original_self_p.conj() * 0.6931471805599453)).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((GradMode::is_enabled() ? infinitely_differentiable_logit_backward(original_self_t.conj(), original_self_p, eps) : logit_backward(original_self_t.conj(), original_self_p, eps)).conj()) : (GradMode::is_enabled() ? infinitely_differentiable_logit_backward(original_self_t.conj(), original_self_p, eps) : logit_backward(original_self_t.conj(), original_self_p, eps)).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * at::isfinite(original_self_p)).conj()) : (original_self_t.conj() * at::isfinite(original_self_p)).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj().neg()).conj()) : (self_t.conj().neg()).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((rad2deg_backward(self_t.conj())).conj()) : (rad2deg_backward(self_t.conj())).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableType_4.cpp:at::Tensor select_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index) {
csrc/autograd/generated/VariableType_4.cpp:    return at::redispatch::select_copy_symint(ks & c10::after_autograd_keyset, self_, dim, index);
csrc/autograd/generated/VariableType_4.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: select_copy_int");
csrc/autograd/generated/VariableType_4.cpp:    AT_ASSERT(result.use_count() <= 1, "function: select_copy_int");
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((GradMode::is_enabled() ? infinitely_differentiable_silu_backward(original_self_t.conj(), original_self_p) : silu_backward(original_self_t.conj(), original_self_p)).conj()) : (GradMode::is_enabled() ? infinitely_differentiable_silu_backward(original_self_t.conj(), original_self_p) : silu_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableType_4.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((sinc_backward(original_self_t.conj(), original_self_p)).conj()) : (sinc_backward(original_self_t.conj(), original_self_p)).conj();
csrc/autograd/generated/VariableType_4.cpp:at::Tensor slice_copy_Tensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step) {
csrc/autograd/generated/VariableType_4.cpp:    return at::redispatch::slice_copy_symint(ks & c10::after_autograd_keyset, self_, dim, start, end, step);
csrc/autograd/generated/VariableType_4.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: slice_copy_Tensor");
csrc/autograd/generated/VariableType_4.cpp:    AT_ASSERT(result.use_count() <= 1, "function: slice_copy_Tensor");
csrc/autograd/generated/VariableType_4.cpp:    return at::redispatch::split_with_sizes_copy_symint(ks & c10::after_autograd_keyset, self_, split_sizes, dim);
csrc/autograd/generated/VariableType_4.cpp:::std::vector<at::Tensor> unbind_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim) {
csrc/autograd/generated/VariableType_4.cpp:at::Tensor & unsqueeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/VariableType_4.cpp:    at::redispatch::unsqueeze_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableType_4.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with unsqueeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_4.cpp:at::Tensor & view_as_complex_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_4.cpp:    at::redispatch::view_as_complex_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_4.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with view_as_complex_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_4.cpp:       TORCH_FN(VariableType::select_copy_int_AutogradNestedTensor)
csrc/autograd/generated/VariableType_4.cpp:m.impl("_copy_from", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableType_4.cpp:m.impl("_copy_from.out", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableType_4.cpp:       TORCH_FN(VariableType::_indices_copy_out_out)
csrc/autograd/generated/VariableType_4.cpp:       TORCH_FN(VariableType::_reshape_alias_copy_out_out)
csrc/autograd/generated/VariableType_4.cpp:       TORCH_FN(VariableType::_values_copy_out_out)
csrc/autograd/generated/VariableType_4.cpp:       TORCH_FN(VariableType::select_copy_int)
csrc/autograd/generated/VariableType_4.cpp:       TORCH_FN(VariableType::slice_copy_Tensor)
csrc/autograd/generated/VariableType_4.cpp:       TORCH_FN(VariableType::unbind_copy_int)
csrc/autograd/generated/VariableType_4.cpp:       TORCH_FN(VariableType::unsqueeze_copy_out_out)
csrc/autograd/generated/VariableType_4.cpp:       TORCH_FN(VariableType::view_as_complex_copy_out_out)
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSliceBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSliceBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSliceBackward0_copy_start_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSliceBackward0_copy_end_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSliceBackward0_copy_step_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:static struct PyGetSetDef SliceBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSliceBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_dim", (getter)THPSliceBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_start", (getter)THPSliceBackward0_copy_start_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_end", (getter)THPSliceBackward0_copy_end_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_step", (getter)THPSliceBackward0_copy_step_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSplitWithSizesBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSplitWithSizesBackward0_copy_split_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSplitWithSizesBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:static struct PyGetSetDef SplitWithSizesBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSplitWithSizesBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_split_sizes", (getter)THPSplitWithSizesBackward0_copy_split_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_dim", (getter)THPSplitWithSizesBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSqueezeBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:static struct PyGetSetDef SqueezeBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSqueezeBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSqueezeBackward1_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSqueezeBackward1_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:static struct PyGetSetDef SqueezeBackward1_copy_properties[] = {
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSqueezeBackward1_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_dim", (getter)THPSqueezeBackward1_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSqueezeBackwardAutogradNestedTensor0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:static struct PyGetSetDef SqueezeBackwardAutogradNestedTensor0_copy_properties[] = {
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_dim", (getter)THPSqueezeBackwardAutogradNestedTensor0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSqueezeBackward2_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSqueezeBackward2_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:static struct PyGetSetDef SqueezeBackward2_copy_properties[] = {
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSqueezeBackward2_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_dim", (getter)THPSqueezeBackward2_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSqueezeBackwardAutogradNestedTensor1_copy_self_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPSqueezeBackwardAutogradNestedTensor1_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:static struct PyGetSetDef SqueezeBackwardAutogradNestedTensor1_copy_properties[] = {
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_self_dim", (getter)THPSqueezeBackwardAutogradNestedTensor1_copy_self_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_dim", (getter)THPSqueezeBackwardAutogradNestedTensor1_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPValuesBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPValuesBackward0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPValuesBackward0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:static struct PyGetSetDef ValuesBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPValuesBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_self", (getter)THPValuesBackward0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_raw_saved_self", (getter)THPValuesBackward0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPValuesBackwardAutogradNestedTensor0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:PyObject* THPValuesBackwardAutogradNestedTensor0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_4.cpp:static struct PyGetSetDef ValuesBackwardAutogradNestedTensor0_copy_properties[] = {
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_saved_self", (getter)THPValuesBackwardAutogradNestedTensor0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  {(char*)"_raw_saved_self", (getter)THPValuesBackwardAutogradNestedTensor0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_4.cpp:  addClass<SliceBackward0_copy>(module, SliceBackward0_copyClass, "SliceBackward0_copy", SliceBackward0_copy_properties);
csrc/autograd/generated/python_functions_4.cpp:  addClass<SplitWithSizesBackward0_copy>(module, SplitWithSizesBackward0_copyClass, "SplitWithSizesBackward0_copy", SplitWithSizesBackward0_copy_properties);
csrc/autograd/generated/python_functions_4.cpp:  addClass<SqueezeBackward0_copy>(module, SqueezeBackward0_copyClass, "SqueezeBackward0_copy", SqueezeBackward0_copy_properties);
csrc/autograd/generated/python_functions_4.cpp:  addClass<SqueezeBackward1_copy>(module, SqueezeBackward1_copyClass, "SqueezeBackward1_copy", SqueezeBackward1_copy_properties);
csrc/autograd/generated/python_functions_4.cpp:  addClass<SqueezeBackwardAutogradNestedTensor0_copy>(module, SqueezeBackwardAutogradNestedTensor0_copyClass, "SqueezeBackwardAutogradNestedTensor0_copy", SqueezeBackwardAutogradNestedTensor0_copy_properties);
csrc/autograd/generated/python_functions_4.cpp:  addClass<SqueezeBackward2_copy>(module, SqueezeBackward2_copyClass, "SqueezeBackward2_copy", SqueezeBackward2_copy_properties);
csrc/autograd/generated/python_functions_4.cpp:  addClass<SqueezeBackwardAutogradNestedTensor1_copy>(module, SqueezeBackwardAutogradNestedTensor1_copyClass, "SqueezeBackwardAutogradNestedTensor1_copy", SqueezeBackwardAutogradNestedTensor1_copy_properties);
csrc/autograd/generated/python_functions_4.cpp:  addClass<ValuesBackward0_copy>(module, ValuesBackward0_copyClass, "ValuesBackward0_copy", ValuesBackward0_copy_properties);
csrc/autograd/generated/python_functions_4.cpp:  addClass<ValuesBackwardAutogradNestedTensor0_copy>(module, ValuesBackwardAutogradNestedTensor0_copyClass, "ValuesBackwardAutogradNestedTensor0_copy", ValuesBackwardAutogradNestedTensor0_copy_properties);
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPSelectBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPSelectBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPSelectBackward0_copy_index_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:static struct PyGetSetDef SelectBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSelectBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_saved_dim", (getter)THPSelectBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_saved_index", (getter)THPSelectBackward0_copy_index_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPSelectBackwardAutogradNestedTensor0_copy_self_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPSelectBackwardAutogradNestedTensor0_copy_self_raw_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPSelectBackwardAutogradNestedTensor0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPSelectBackwardAutogradNestedTensor0_copy_index_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:static struct PyGetSetDef SelectBackwardAutogradNestedTensor0_copy_properties[] = {
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_saved_self", (getter)THPSelectBackwardAutogradNestedTensor0_copy_self_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_raw_saved_self", (getter)THPSelectBackwardAutogradNestedTensor0_copy_self_raw_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_saved_dim", (getter)THPSelectBackwardAutogradNestedTensor0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_saved_index", (getter)THPSelectBackwardAutogradNestedTensor0_copy_index_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPUnfoldBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPUnfoldBackward0_copy_dimension_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPUnfoldBackward0_copy_size_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:PyObject* THPUnfoldBackward0_copy_step_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_3.cpp:static struct PyGetSetDef UnfoldBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPUnfoldBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_saved_dimension", (getter)THPUnfoldBackward0_copy_dimension_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_saved_size", (getter)THPUnfoldBackward0_copy_size_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:  {(char*)"_saved_step", (getter)THPUnfoldBackward0_copy_step_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_3.cpp:  addClass<SelectBackward0_copy>(module, SelectBackward0_copyClass, "SelectBackward0_copy", SelectBackward0_copy_properties);
csrc/autograd/generated/python_functions_3.cpp:  addClass<SelectBackwardAutogradNestedTensor0_copy>(module, SelectBackwardAutogradNestedTensor0_copyClass, "SelectBackwardAutogradNestedTensor0_copy", SelectBackwardAutogradNestedTensor0_copy_properties);
csrc/autograd/generated/python_functions_3.cpp:  addClass<UnfoldBackward0_copy>(module, UnfoldBackward0_copyClass, "UnfoldBackward0_copy", UnfoldBackward0_copy_properties);
csrc/autograd/generated/python_functions_1.cpp:static struct PyGetSetDef AliasBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_1.cpp:PyObject* THPSplitBackward0_copy_self_sym_sizes_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_1.cpp:PyObject* THPSplitBackward0_copy_split_size_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_1.cpp:PyObject* THPSplitBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_1.cpp:static struct PyGetSetDef SplitBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_1.cpp:  {(char*)"_saved_self_sym_sizes", (getter)THPSplitBackward0_copy_self_sym_sizes_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_1.cpp:  {(char*)"_saved_split_size", (getter)THPSplitBackward0_copy_split_size_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_1.cpp:  {(char*)"_saved_dim", (getter)THPSplitBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_1.cpp:PyObject* THPTransposeBackward0_copy_dim0_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_1.cpp:PyObject* THPTransposeBackward0_copy_dim1_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_1.cpp:static struct PyGetSetDef TransposeBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_1.cpp:  {(char*)"_saved_dim0", (getter)THPTransposeBackward0_copy_dim0_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_1.cpp:  {(char*)"_saved_dim1", (getter)THPTransposeBackward0_copy_dim1_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_1.cpp:static struct PyGetSetDef LiftFreshBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_1.cpp:static struct PyGetSetDef ViewAsRealBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_1.cpp:PyObject* THPUnbindBackward0_copy_dim_getter(THPCppFunction *self, void *_unused) {
csrc/autograd/generated/python_functions_1.cpp:static struct PyGetSetDef UnbindBackward0_copy_properties[] = {
csrc/autograd/generated/python_functions_1.cpp:  {(char*)"_saved_dim", (getter)THPUnbindBackward0_copy_dim_getter, nullptr, nullptr, nullptr},
csrc/autograd/generated/python_functions_1.cpp:  addClass<AliasBackward0_copy>(module, AliasBackward0_copyClass, "AliasBackward0_copy", AliasBackward0_copy_properties);
csrc/autograd/generated/python_functions_1.cpp:  addClass<SplitBackward0_copy>(module, SplitBackward0_copyClass, "SplitBackward0_copy", SplitBackward0_copy_properties);
csrc/autograd/generated/python_functions_1.cpp:  addClass<TransposeBackward0_copy>(module, TransposeBackward0_copyClass, "TransposeBackward0_copy", TransposeBackward0_copy_properties);
csrc/autograd/generated/python_functions_1.cpp:  addClass<LiftFreshBackward0_copy>(module, LiftFreshBackward0_copyClass, "LiftFreshBackward0_copy", LiftFreshBackward0_copy_properties);
csrc/autograd/generated/python_functions_1.cpp:  addClass<ViewAsRealBackward0_copy>(module, ViewAsRealBackward0_copyClass, "ViewAsRealBackward0_copy", ViewAsRealBackward0_copy_properties);
csrc/autograd/generated/python_functions_1.cpp:  addClass<UnbindBackward0_copy>(module, UnbindBackward0_copyClass, "UnbindBackward0_copy", UnbindBackward0_copy_properties);
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & squeeze_copy_out_dim_out_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::squeeze_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with squeeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & squeeze_copy_out_dims_out_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::squeeze_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with squeeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:at::Tensor values_copy_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self) {
csrc/autograd/generated/VariableType_2.cpp:at::Tensor view_copy_AutogradNestedTensor(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size) {
csrc/autograd/generated/VariableType_2.cpp:    return at::redispatch::view_copy_symint(ks & c10::after_autograd_keyset, self_, size);
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(handle_r_to_c(self_p.scalar_type(), original_self_t.conj() * original_self_p.sgn())) : handle_r_to_c(self_p.scalar_type(), original_self_t.conj() * original_self_p.sgn());
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * -((-original_self_p * original_self_p + 1).rsqrt()).conj()).conj()) : (original_self_t.conj() * -((-original_self_p * original_self_p + 1).rsqrt()).conj()).conj();
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(maybe_multiply(self_t, beta) + maybe_multiply(batch1_t.bmm(batch2_p).sum(0), alpha) + maybe_multiply(batch1_p.bmm(batch2_t).sum(0), alpha)) : maybe_multiply(self_t, beta) + maybe_multiply(batch1_t.bmm(batch2_p).sum(0), alpha) + maybe_multiply(batch1_p.bmm(batch2_t).sum(0), alpha);
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t + maybe_multiply(tensor1_t / tensor2_p, value) - maybe_multiply(tensor2_t * (tensor1_p / tensor2_p) / tensor2_p, value)) : self_t + maybe_multiply(tensor1_t / tensor2_p, value) - maybe_multiply(tensor2_t * (tensor1_p / tensor2_p) / tensor2_p, value);
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((-original_self_p * other_t + other_p * original_self_t) / (original_self_p.pow(2) + other_p.pow(2))) : (-original_self_p * other_t + other_p * original_self_t) / (original_self_p.pow(2) + other_p.pow(2));
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() / (original_self_p * original_self_p + 1).conj()).conj()) : (original_self_t.conj() / (original_self_p * original_self_p + 1).conj()).conj();
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(maybe_multiply(self_t, beta) + maybe_multiply(batch1_t.bmm(batch2_p), alpha) + maybe_multiply(batch1_p.bmm(batch2_t), alpha)) : maybe_multiply(self_t, beta) + maybe_multiply(batch1_t.bmm(batch2_p), alpha) + maybe_multiply(batch1_p.bmm(batch2_t), alpha);
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((where(original_self_p <= max, original_self_t.conj(), at::scalar_tensor(0., original_self_t.conj().options()))).conj()) : (where(original_self_p <= max, original_self_t.conj(), at::scalar_tensor(0., original_self_t.conj().options()))).conj();
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(where(original_self_p <= max_p, original_self_t, max_t)) : where(original_self_p <= max_p, original_self_t, max_t);
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * -original_self_p.sin().conj()).conj()) : (original_self_t.conj() * -original_self_p.sin().conj()).conj();
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(cumprod_jvp(original_self_t, original_self_p, self_p, dim).to(dtype.has_value() ? *dtype : original_self_p.scalar_type())) : cumprod_jvp(original_self_t, original_self_p, self_p, dim).to(dtype.has_value() ? *dtype : original_self_p.scalar_type());
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(at::cumsum(self_t, dim, dtype)) : at::cumsum(self_t, dim, dtype);
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & diagonal_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::diagonal_copy_outf(ks & c10::after_autograd_keyset, self_, offset, dim1, dim2, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with diagonal_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & expand_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::expand_copy_symint_outf(ks & c10::after_autograd_keyset, self_, size, implicit, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with expand_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj() * (self_p + 1)).conj()) : (self_t.conj() * (self_p + 1)).conj();
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((self_t.conj()).conj()) : (self_t.conj()).conj();
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(original_self_t - other_t * original_self_p.div(other_p, /*rounding_mode=*/"trunc")) : original_self_t - other_t * original_self_p.div(other_p, /*rounding_mode=*/"trunc");
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((gelu_backward(original_self_t.conj(), original_self_p, approximate)).conj()) : (gelu_backward(original_self_t.conj(), original_self_p, approximate)).conj();
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & index_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::index_copy_outf(ks & c10::after_autograd_keyset, self_, dim, index_, source_, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(source) || isFwGradDefined(out))), "Trying to use forward AD with index_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((threshold_backward(self_t.conj(), self_p, 0)).conj()) : (threshold_backward(self_t.conj(), self_p, 0)).conj();
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(scatter_reduce_jvp(original_self_p, original_self_t, dim, index, src_p, src_t, reduce, include_self, self_p)) : scatter_reduce_jvp(original_self_p, original_self_t, dim, index, src_p, src_t, reduce, include_self, self_p);
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(sgn_backward(original_self_p, original_self_t, self_p)) : sgn_backward(original_self_p, original_self_t, self_p);
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((original_self_t.conj() * original_self_p.cos().conj()).conj()) : (original_self_t.conj() * original_self_p.cos().conj()).conj();
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & squeeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::squeeze_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with squeeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & squeeze_copy_out_dim_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::squeeze_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with squeeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & squeeze_copy_out_dims_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::squeeze_copy_outf(ks & c10::after_autograd_keyset, self_, dim, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with squeeze_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_(self_t - maybe_multiply(other_t, alpha)) : self_t - maybe_multiply(other_t, alpha);
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((handle_r_to_c(original_self_p.scalar_type(), original_self_t.conj())).conj()) : (handle_r_to_c(original_self_p.scalar_type(), original_self_t.conj())).conj();
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & t_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::t_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with t_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t.copy_(threshold_backward(self_t.conj(), original_self_p, threshold).conj());
csrc/autograd/generated/VariableType_2.cpp:at::Tensor transpose_copy_int(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim0, int64_t dim1) {
csrc/autograd/generated/VariableType_2.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: transpose_copy_int");
csrc/autograd/generated/VariableType_2.cpp:    AT_ASSERT(result.use_count() <= 1, "function: transpose_copy_int");
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & transpose_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::transpose_copy_outf(ks & c10::after_autograd_keyset, self_, dim0, dim1, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with transpose_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:      self_new_fw_grad_opt = self_t_raw.defined() ? self_t_raw.copy_((zeros_like(self_t.conj())).conj()) : (zeros_like(self_t.conj())).conj();
csrc/autograd/generated/VariableType_2.cpp:at::Tensor & view_as_real_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/VariableType_2.cpp:    at::redispatch::view_as_real_copy_outf(ks & c10::after_autograd_keyset, self_, out_);
csrc/autograd/generated/VariableType_2.cpp:  TORCH_CHECK_NOT_IMPLEMENTED(!((isFwGradDefined(self) || isFwGradDefined(out))), "Trying to use forward AD with view_as_real_copy_out that does not support it because it is an out= function");
csrc/autograd/generated/VariableType_2.cpp:    return at::redispatch::view_copy_symint(ks & c10::after_autograd_keyset, self_, size);
csrc/autograd/generated/VariableType_2.cpp:at::Tensor view_copy_dtype(c10::DispatchKeySet ks, const at::Tensor & self, at::ScalarType dtype) {
csrc/autograd/generated/VariableType_2.cpp:    AT_ASSERT(result.storage().use_count() == 1, "function: view_copy_dtype");
csrc/autograd/generated/VariableType_2.cpp:    AT_ASSERT(result.use_count() <= 1, "function: view_copy_dtype");
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::squeeze_copy_out_dim_out_AutogradNestedTensor)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::squeeze_copy_out_dims_out_AutogradNestedTensor)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::values_copy_AutogradNestedTensor)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::view_copy_AutogradNestedTensor)
csrc/autograd/generated/VariableType_2.cpp:m.impl("_copy_from_and_resize.out", torch::autograd::autogradNotImplementedFallback());
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::diagonal_copy_out_out)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::expand_copy_out_out)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::index_copy_out_out)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::squeeze_copy_out_out)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::squeeze_copy_out_dim_out)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::squeeze_copy_out_dims_out)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::t_copy_out_out)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::transpose_copy_int)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::transpose_copy_out_int_out)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::view_as_real_copy_out_out)
csrc/autograd/generated/VariableType_2.cpp:       TORCH_FN(VariableType::view_copy_dtype)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_conj_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_copy_from_and_resize_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_copy_from_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_fw_primal_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_make_dual_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_neg_view_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_nested_view_from_buffer_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_reshape_alias_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_sparse_broadcast_to_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_to_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/_values_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/alias_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/as_strided_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/ccol_indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/col_indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/crow_indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/detach_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/diagonal_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/expand_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/index_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/lift_fresh_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/narrow_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/permute_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/row_indices_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/select_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/slice_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/squeeze_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/t_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/transpose_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/unfold_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/unsqueeze_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/values_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/view_as_complex_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/view_as_real_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:#include <ATen/ops/view_copy_ops.h>
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _conj_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_conj_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _copy_from_and_resize_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_copy_from_and_resize_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dst, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _copy_from_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & dst, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_copy_from_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dst, non_blocking, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _fw_primal_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t level, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_fw_primal_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, level, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _make_dual_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & primal, const at::Tensor & tangent, int64_t level, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_make_dual_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, primal, tangent, level, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _neg_view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_neg_view_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _nested_view_from_buffer_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_nested_view_from_buffer_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, nested_size, nested_strides, offsets, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _reshape_alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_reshape_alias_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, size, stride, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _sparse_broadcast_to_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_sparse_broadcast_to_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, size, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _test_autograd_multiple_dispatch_view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_test_autograd_multiple_dispatch_view_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _to_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, bool non_blocking, c10::optional<at::MemoryFormat> memory_format, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_to_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, non_blocking, memory_format, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & _values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::_values_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & alias_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::alias_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & as_strided_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::as_strided_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, size, stride, storage_offset, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & ccol_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::ccol_indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & col_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::col_indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, src, non_blocking, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & copy_sparse_to_sparse_(c10::DispatchKeySet ks, at::Tensor & self, const at::Tensor & src, bool non_blocking) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::copy_sparse_to_sparse_::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, src, non_blocking);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & copy_sparse_to_sparse_out_out(c10::DispatchKeySet ks, const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::copy_sparse_to_sparse_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, src, non_blocking, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & crow_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::crow_indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & detach_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::detach_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & diagonal_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::diagonal_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, offset, dim1, dim2, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & expand_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::expand_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, size, implicit, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & index_copy_(c10::DispatchKeySet ks, at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::index_copy_::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, index, source);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & index_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::index_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, index, source, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & lift_fresh_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::lift_fresh_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & narrow_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::narrow_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, start, length, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & permute_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::permute_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dims, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & row_indices_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::row_indices_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & select_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::select_copy_int_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, index, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & slice_copy_out_Tensor_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::slice_copy_Tensor_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, start, end, step, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & squeeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::squeeze_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & squeeze_copy_out_dim_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::squeeze_copy_dim_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & squeeze_copy_out_dims_out(c10::DispatchKeySet ks, const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::squeeze_copy_dims_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & t_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::t_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & transpose_copy_out_int_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::transpose_copy_int_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim0, dim1, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & unfold_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::unfold_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dimension, size, step, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & unsqueeze_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::unsqueeze_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dim, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & values_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::values_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & view_as_complex_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::view_as_complex_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & view_as_real_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::view_as_real_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & view_copy_out_out(c10::DispatchKeySet ks, const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::view_copy_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, size, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:at::Tensor & view_copy_out_dtype_out(c10::DispatchKeySet ks, const at::Tensor & self, at::ScalarType dtype, at::Tensor & out) {
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:    at::_ops::view_copy_dtype_out::redispatch(ks & c10::after_ADInplaceOrView_keyset, self, dtype, out);
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_conj_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:  m.impl("_copy_from_and_resize.out",
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_copy_from_and_resize_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:  m.impl("_copy_from.out",
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_copy_from_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_fw_primal_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_make_dual_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_neg_view_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_nested_view_from_buffer_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_reshape_alias_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_sparse_broadcast_to_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_test_autograd_multiple_dispatch_view_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_to_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::_values_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::alias_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::as_strided_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::ccol_indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::col_indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:  m.impl("copy_sparse_to_sparse_",
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::copy_sparse_to_sparse_)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:  m.impl("copy_sparse_to_sparse.out",
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::copy_sparse_to_sparse_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::crow_indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::detach_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::diagonal_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::expand_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:  m.impl("index_copy_",
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::index_copy_)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::index_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::lift_fresh_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::narrow_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::permute_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::row_indices_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::select_copy_out_int_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::slice_copy_out_Tensor_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::squeeze_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::squeeze_copy_out_dim_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::squeeze_copy_out_dims_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::t_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::transpose_copy_out_int_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::unfold_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::unsqueeze_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::values_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::view_as_complex_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::view_as_real_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::view_copy_out_out)
csrc/autograd/generated/ADInplaceOrViewTypeEverything.cpp:         TORCH_FN(ADInplaceOrView::view_copy_out_dtype_out)
csrc/autograd/generated/python_torch_functions_2.cpp:    auto dispatch_view_as_real_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_2.cpp:      return at::view_as_real_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_2.cpp:    return wrap(dispatch_view_as_real_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_2.cpp:    auto dispatch_permute_copy_out = [](at::Tensor out, const at::Tensor & self, at::IntArrayRef dims) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_2.cpp:      return at::permute_copy_out(out, self, dims);
csrc/autograd/generated/python_torch_functions_2.cpp:    return wrap(dispatch_permute_copy_out(_r.tensor(2), _r.tensor(0), _r.intlist(1)));
csrc/autograd/generated/python_torch_functions_2.cpp:    auto dispatch_detach_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_2.cpp:      return at::detach_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_2.cpp:    return wrap(dispatch_detach_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_2.cpp:      return at::split_copy_symint(self, split_size, dim);
csrc/autograd/generated/python_torch_functions_2.cpp:    auto dispatch_split_copy_out = [](at::TensorList out, const at::Tensor & self, c10::SymInt split_size, int64_t dim) -> void {
csrc/autograd/generated/python_torch_functions_2.cpp:      at::split_copy_symint_out(out, self, split_size, dim);
csrc/autograd/generated/python_torch_functions_2.cpp:    dispatch_split_copy_out(_r.tensorlist(3), _r.tensor(0), _r.toSymInt(1), _r.toInt64(2));
csrc/autograd/generated/python_torch_functions_2.cpp:    auto dispatch_unsqueeze_copy_out = [](at::Tensor out, const at::Tensor & self, int64_t dim) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_2.cpp:      return at::unsqueeze_copy_out(out, self, dim);
csrc/autograd/generated/python_torch_functions_2.cpp:    return wrap(dispatch_unsqueeze_copy_out(_r.tensor(2), _r.tensor(0), _r.toInt64(1)));
csrc/autograd/generated/python_torch_functions_2.cpp:    auto dispatch__indices_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_2.cpp:      return at::_indices_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_2.cpp:    return wrap(dispatch__indices_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_2.cpp:    auto dispatch__values_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_2.cpp:      return at::_values_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_2.cpp:    return wrap(dispatch__values_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/generated/python_torch_functions_2.cpp:    auto dispatch_unbind_copy_out = [](at::TensorList out, const at::Tensor & self, int64_t dim) -> void {
csrc/autograd/generated/python_torch_functions_2.cpp:      at::unbind_copy_out(out, self, dim);
csrc/autograd/generated/python_torch_functions_2.cpp:    dispatch_unbind_copy_out(_r.tensorlist(2), _r.tensor(0), _r.toInt64(1));
csrc/autograd/generated/python_torch_functions_2.cpp:    auto dispatch_alias_copy_out = [](at::Tensor out, const at::Tensor & self) -> at::Tensor {
csrc/autograd/generated/python_torch_functions_2.cpp:      return at::alias_copy_out(out, self);
csrc/autograd/generated/python_torch_functions_2.cpp:    return wrap(dispatch_alias_copy_out(_r.tensor(1), _r.tensor(0)));
csrc/autograd/VariableTypeUtils.h:// a.copy_(b)
csrc/autograd/utils/grad_layout_contract.h:                         .copy_(new_grad));
csrc/autograd/autograd_meta.cpp://     foo.copy_(bar)
csrc/autograd/autograd_meta.cpp://     view.copy_(bar)
csrc/autograd/autograd_meta.cpp://     foo.copy_(bar)
csrc/autograd/autograd_meta.cpp://     view.copy_(bar)
csrc/autograd/autograd_meta.cpp://     base.copy_(bar)
csrc/autograd/autograd_meta.cpp:            new_fw_grad_value.copy_(new_grad);
csrc/autograd/autograd_meta.cpp:      res.copy_(new_grad);
csrc/autograd/TraceTypeManual.cpp:Tensor& copy_(Tensor& self, const Tensor& src, bool non_blocking) {
csrc/autograd/TraceTypeManual.cpp:          jit::aten::copy_,
csrc/autograd/TraceTypeManual.cpp:        "copy_ (possibly due to an assignment)", self);
csrc/autograd/TraceTypeManual.cpp:    self.copy_(src, non_blocking);
csrc/autograd/TraceTypeManual.cpp:  m.impl("copy_", copy_);
csrc/functorch/init.cpp:    unwrapped.copy_(wrapped_inner);
csrc/cuda/comm.cpp:      out_tensor.copy_(tensor, /*non_blocking=*/true);
csrc/cuda/comm.cpp:    out_tensors[i].copy_(chunks[i], /*non_blocking=*/true);
csrc/cuda/comm.cpp:    chunks[i].copy_(tensors[i], /*non_blocking=*/out_tensor.is_cuda());
csrc/cuda/nccl.cpp:        outputs[r].copy_(inputs);
csrc/cuda/nccl.cpp:        outputs.copy_(inputs[r]);
csrc/cuda/Tensor.cpp:#include <torch/csrc/copy_utils.h>
csrc/utils.cpp:  dst_t.copy_(src_t, non_blocking);
csrc/StorageMethods.cpp:#include <torch/csrc/copy_utils.h>
csrc/StorageMethods.cpp:static PyObject* THPStorage_copy_(
csrc/StorageMethods.cpp:      "copy_(Storage src, bool? non_blocking=None)",
csrc/StorageMethods.cpp:    {"copy_",
csrc/StorageMethods.cpp:     castPyCFunctionWithKeywords(THPStorage_copy_),
csrc/serialization.cpp:    // Here we use a tensor.copy_() to impl H2D for all non-CPU device.
csrc/serialization.cpp:    device_tensor.copy_(cpu_tensor);
csrc/distributed/autograd/utils.cpp:  std::copy_if(
csrc/distributed/c10d/ProcessGroupUCC.cpp:    auto copy_from_flat = [&] {
csrc/distributed/c10d/ProcessGroupUCC.cpp:          outputTensors[i][j].copy_(flat_output[i][j], asyncCopy);
csrc/distributed/c10d/ProcessGroupUCC.cpp:        copy_from_flat,
csrc/distributed/c10d/ProcessGroupUCC.cpp:  auto copy_to_flat = [&] {
csrc/distributed/c10d/ProcessGroupUCC.cpp:        flat_input[i][j].copy_(inputTensors[i][j], asyncCopy);
csrc/distributed/c10d/ProcessGroupUCC.cpp:      copy_to_flat,
csrc/distributed/c10d/ProcessGroupGloo.cpp:      inputs[i].copy_(inputs[rootTensor]);
csrc/distributed/c10d/ProcessGroupGloo.cpp:      tmp.copy_(inputs[rootTensor], /* non_blocking */ true);
csrc/distributed/c10d/ProcessGroupGloo.cpp:      inputs[i].copy_(tmp, /* non_blocking */ true);
csrc/distributed/c10d/ProcessGroupGloo.cpp:      tensor.copy_(coalescedTensor.slice(0, offset, offset + tensorNumel)
csrc/distributed/c10d/ProcessGroupGloo.cpp:      inputs[i].copy_(output);
csrc/distributed/c10d/ProcessGroupGloo.cpp:      tmp.push_back(pinnedLike(inputs[i]).copy_(inputs[i], true));
csrc/distributed/c10d/ProcessGroupGloo.cpp:      inputs[i].copy_(tmp[i], /* non_blocking */ true);
csrc/distributed/c10d/ProcessGroupGloo.cpp:      inputs[i].copy_(output, /*non_blocking=*/true);
csrc/distributed/c10d/ProcessGroupGloo.cpp:      tmp.push_back(pinnedLike(inputs[i]).copy_(inputs[i], true));
csrc/distributed/c10d/ProcessGroupGloo.cpp:      inputs[i].copy_(tmp[i], /* non_blocking */ true);
csrc/distributed/c10d/ProcessGroupGloo.cpp:        outputgroup[j].copy_(flatOutputTensor[j]);
csrc/distributed/c10d/ProcessGroupGloo.cpp:      tmpInputs.push_back(pinnedLike(inputs[i]).copy_(inputs[i], true));
csrc/distributed/c10d/ProcessGroupGloo.cpp:        outputs[i][j].copy_(tmpOutputs[i][j], /* non_blocking */ true);
csrc/distributed/c10d/ProcessGroupGloo.cpp:        output_tensor.copy_(
csrc/distributed/c10d/ProcessGroupGloo.cpp:        outputs[0][i].copy_(flatOutputTensor[i]);
csrc/distributed/c10d/ProcessGroupGloo.cpp:      tmpInputs.push_back(pinnedLike(inputs[i]).copy_(inputs[i], true));
csrc/distributed/c10d/ProcessGroupGloo.cpp:        outputs[i][j].copy_(tmpOutputs[i][j], /* non_blocking */ true);
csrc/distributed/c10d/ProcessGroupGloo.cpp:            pinnedLike(inputs[i][j]).copy_(inputs[i][j], true));
csrc/distributed/c10d/ProcessGroupGloo.cpp:      outputs[i].copy_(tmpOutputs[i], /* non_blocking */ true);
csrc/distributed/c10d/ProcessGroupGloo.cpp:    cpuInput = pinnedLike(inputTensor).copy_(inputTensor, true);
csrc/distributed/c10d/ProcessGroupGloo.cpp:    outputTensor.copy_(cpuOutput, /* non_blocking */ true);
csrc/distributed/c10d/comm.cpp:        bucket_tensors_[i].copy_(output_tensors[i], /*non_blocking=*/true);
csrc/distributed/c10d/init.cpp:          "__copy__",
csrc/distributed/c10d/init.cpp:          "__deepcopy__",
csrc/distributed/c10d/reducer.cpp:            bucket_view.copy_(div_result);
csrc/distributed/c10d/reducer.cpp:          bucket_view.copy_(grad);
csrc/distributed/c10d/reducer.cpp:    // essential. The H2D copy_ is stream ordered, while the host's
csrc/distributed/c10d/reducer.cpp:    // cuda-stream work pushes the copy_ far into the future, and if no
csrc/distributed/c10d/reducer.cpp:    // before the stream executes the copy_, copy_ will read those zeros
csrc/distributed/c10d/reducer.cpp:    local_used_map_tmp.copy_(local_used_map_);
csrc/distributed/c10d/reducer.cpp:    local_used_map_dev_.copy_(local_used_map_tmp, true);
csrc/distributed/c10d/reducer.cpp:    local_used_map_dev_.copy_(local_used_map_, true);
csrc/distributed/c10d/reducer.cpp:      // grad. Views serve as entry points to `copy_()` each grad's data in/out
csrc/distributed/c10d/reducer.cpp:      // during copy_s, it's beneficial for each view's layout to match its
csrc/distributed/c10d/reducer.cpp:      // patterns when copy_ing grad data in and out of its bucket view.
csrc/distributed/c10d/reducer.cpp:      // then grad.copy_(bucket_view_out) transposes it back to grad's layout.
csrc/distributed/c10d/reducer.cpp:          bucket_view.copy_(grad);
csrc/distributed/c10d/reducer.cpp:void Reducer::copy_bucket_to_grad(
csrc/distributed/c10d/reducer.cpp:        grad.copy_(bucket_view);
csrc/distributed/c10d/reducer.cpp:        local_used_map_.copy_(local_used_map_dev_);
csrc/distributed/c10d/reducer.cpp:            "torch.distributed.ddp.reducer::copy_bucket_to_grad",
csrc/distributed/c10d/reducer.cpp:        copy_bucket_to_grad(
csrc/distributed/c10d/reducer.cpp:        bucket_view_in.copy_(bucket_view_out);
csrc/distributed/c10d/reducer.cpp:      bucket.gradients.copy_(future_result);
csrc/distributed/c10d/reducer.cpp:  indices_tensor_device.copy_(indices_tensor, /*non_blocking=*/true);
csrc/distributed/c10d/reducer.cpp:  indices_tensor.copy_(indices_tensor_list.front(), /*non_blocking=*/false);
csrc/distributed/c10d/reducer.cpp:  bucket_sizes_tensor_device.copy_(bucket_sizes_tensor, /*non_blocking=*/true);
csrc/distributed/c10d/reducer.cpp:  bucket_sizes_tensor.copy_(
csrc/distributed/c10d/reducer.cpp:  control.copy_(metadata_dev, /*non_blocking=*/false);
csrc/distributed/c10d/default_comm_hooks.cpp:    decompressed_tensor.copy_(reduce_tensor);
csrc/distributed/c10d/reducer.hpp:  // entry points to `copy_()` each grad's data in/out of the flattened
csrc/distributed/c10d/reducer.hpp:  void copy_bucket_to_grad(
csrc/distributed/c10d/reducer.hpp:    // `bucket_views_in[i].copy_(grad)` and `grad.copy_(bucket_views_out[i])`
csrc/distributed/c10d/ProcessGroupNCCL.cpp:              outputTensors[i][j].copy_(outputFlattened[i][j], true);
csrc/distributed/c10d/ProcessGroupNCCL.cpp:              inputFlattened[i][j].copy_(inputTensors[i][j], true);
csrc/distributed/c10d/ProcessGroupMPI.cpp:          outputDataVec[i].copy_(flatOutputTensor[i]);
csrc/distributed/c10d/ProcessGroupMPI.cpp:            outputDataVec.at(i).copy_(flatOutputTensor[i]);
csrc/distributed/c10d/ProcessGroupMPI.cpp:            flatInputTensor[i].copy_(inputDataVec.at(i));
csrc/distributed/c10d/ProcessGroupMPI.cpp:          srcFlatDataSplits[i].copy_(srcdata[i].view({-1}));
csrc/distributed/c10d/ProcessGroupMPI.cpp:          dstdata[i].view({-1}).copy_(dstFlatDataSplits[i]);
csrc/jit/ir/ir.cpp:    bool copy_blocks) {
csrc/jit/ir/ir.cpp:  if (copy_blocks) {
csrc/jit/ir/ir.h:  // if copy_blocks is false, it will not recursively clone the nested blocks
csrc/jit/ir/ir.h:      bool copy_blocks = true);
csrc/jit/python/python_ir.cpp:              size_t copy_bytes = t.element_size() * t.numel();
csrc/jit/python/python_ir.cpp:                  py::bytes(static_cast<const char*>(t.data_ptr()), copy_bytes);
csrc/jit/python/script_init.cpp:          .def("__copy__", &Object::copy)
csrc/jit/python/script_init.cpp:      "__deepcopy__", [](const Object& self, const py::dict& memo) {
csrc/jit/python/script_init.cpp:      .def("__copy__", &Module::copy)
csrc/jit/python/script_init.cpp:          "__deepcopy__",
csrc/jit/runtime/register_prim_ops.cpp:      TORCH_SELECTIVE_SCHEMA("aten::copy_." #other_type                  \
csrc/jit/runtime/symbolic_script.cpp:            grad_input.select(dim, index).copy_(grad)
csrc/jit/runtime/symbolic_script.cpp:            grad_input.slice(dim, start, end, step).copy_(grad)
csrc/jit/runtime/static/memory_planner.cpp:  static const auto to_maybe_copy_out_symbol =
csrc/jit/runtime/static/memory_planner.cpp:      c10::Symbol::fromQualString("static_runtime::to_maybe_copy_out");
csrc/jit/runtime/static/memory_planner.cpp:  // If to_maybe_copy_out did not actually do anything in the
csrc/jit/runtime/static/memory_planner.cpp:  return pnode.node()->kind() == to_maybe_copy_out_symbol &&
csrc/jit/runtime/static/memory_planner.cpp:      // ival is allowed to be None in special cases, e.g. to_maybe_copy_out
csrc/jit/runtime/static/memory_planner.cpp:        // to_maybe_copy_out. We don't know if the tensor value is managed until
csrc/jit/runtime/static/impl.cpp:    if (opts.use_copy_variants && !opts.enable_tensorexpr_fusion) {
csrc/jit/runtime/static/impl.cpp:    if (opts.use_maybe_copy_variants && !opts.enable_tensorexpr_fusion) {
csrc/jit/runtime/static/impl.cpp:            << opts.manage_output_tensors << ", use_copy_variants "
csrc/jit/runtime/static/impl.cpp:            << opts.use_copy_variants << ", use_maybe_copy_variants "
csrc/jit/runtime/static/impl.cpp:            << opts.use_maybe_copy_variants << ", enable_tensorexpr_fusion "
csrc/jit/runtime/static/impl.cpp:  std::copy_if(
csrc/jit/runtime/static/impl.cpp:        // to_maybe_copy_out; see ReplaceWithMaybeCopy for details.
csrc/jit/runtime/static/impl.h:  bool use_copy_variants{true};
csrc/jit/runtime/static/impl.h:  // For the same reason as `use_copy_variants`, the ReplaceWithMaybeCopy pass
csrc/jit/runtime/static/impl.h:  bool use_maybe_copy_variants{true};
csrc/jit/runtime/static/ops.cpp:  at::native::copy_(urtensor, xtensor.expand_as(urtensor));
csrc/jit/runtime/static/ops.cpp:at::Tensor& reshape_copy_out(
csrc/jit/runtime/static/ops.cpp:at::Tensor& flatten_copy_out(
csrc/jit/runtime/static/ops.cpp:    return reshape_copy_out(out, self, at::DimVector{1}, false);
csrc/jit/runtime/static/ops.cpp:    return reshape_copy_out(out, self, shape, false);
csrc/jit/runtime/static/ops.cpp:  return reshape_copy_out(out, self, shape, false);
csrc/jit/runtime/static/ops.cpp:        "to_copy_out_inner_loop",                                  \
csrc/jit/runtime/static/ops.cpp:void to_copy_out_fast_path(Tensor& out, const Tensor& self) {
csrc/jit/runtime/static/ops.cpp:  to_copy_out_fast_path<scalar_t>(out, self)
csrc/jit/runtime/static/ops.cpp:at::Tensor& to_copy_out(
csrc/jit/runtime/static/ops.cpp:    bool copy_strides,
csrc/jit/runtime/static/ops.cpp:  if (copy_strides) {
csrc/jit/runtime/static/ops.cpp:  // TensorIterator in at::native::copy_, which is relatively
csrc/jit/runtime/static/ops.cpp:        kHalf, kBFloat16, kBool, kFloat8, self.scalar_type(), "to_copy_out", [&]() {
csrc/jit/runtime/static/ops.cpp:  at::native::copy_(out, self, non_blocking);
csrc/jit/runtime/static/ops.cpp:at::Tensor& dequantize_copy_out(Tensor& out, const Tensor& self) {
csrc/jit/runtime/static/ops.cpp:    return at::native::to_copy_out(out, self, false, false, c10::nullopt);
csrc/jit/runtime/static/ops.cpp:    at::native::copy_(out_t, src, false);
csrc/jit/runtime/static/ops.cpp:          at::native::narrow_copy_dense_cpu(self, dim, start, length);
csrc/jit/runtime/static/ops.cpp:    at::native::narrow_copy_dense_cpu_out(self, dim, start, length, output);
csrc/jit/runtime/static/ops.cpp:    // The to_maybe_copy_out operator functor should have detected a
csrc/jit/runtime/static/ops.cpp:C10_ALWAYS_INLINE void to_copy_functor_impl(
csrc/jit/runtime/static/ops.cpp:  bool copy_strides = false;
csrc/jit/runtime/static/ops.cpp:      copy_strides = true;
csrc/jit/runtime/static/ops.cpp:  copy_strides = copy_strides ||
csrc/jit/runtime/static/ops.cpp:  at::native::to_copy_out(
csrc/jit/runtime/static/ops.cpp:      out_t, self, non_blocking, copy_strides, memory_format);
csrc/jit/runtime/static/ops.cpp:void to_copy_functor(ProcessedNode* p_node) {
csrc/jit/runtime/static/ops.cpp:  to_copy_functor_impl<
csrc/jit/runtime/static/ops.cpp:void to_maybe_copy_out_functor(ProcessedNode* p_node) {
csrc/jit/runtime/static/ops.cpp:    to_copy_functor_impl<
csrc/jit/runtime/static/ops.cpp:void to_maybe_copy_out_functor<true, false>(ProcessedNode* p_node) {
csrc/jit/runtime/static/ops.cpp:    to_copy_functor_impl<true, false>(p_node, &args);
csrc/jit/runtime/static/ops.cpp:auto get_to_copy_functor(
csrc/jit/runtime/static/ops.cpp:      return to_copy_functor<true, true>;
csrc/jit/runtime/static/ops.cpp:      return to_copy_functor<true, false>;
csrc/jit/runtime/static/ops.cpp:      return to_copy_functor<false, true>;
csrc/jit/runtime/static/ops.cpp:      return to_copy_functor<false, false>;
csrc/jit/runtime/static/ops.cpp:    static_runtime::to_maybe_copy_out,
csrc/jit/runtime/static/ops.cpp:              "static_runtime::to_maybe_copy_out.prim_dtype(Tensor self, int? dtype=None, bool non_blocking=False, bool copy=False) -> (Tensor, bool)",
csrc/jit/runtime/static/ops.cpp:              "static_runtime::to_maybe_copy_out.dtype(Tensor self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> (Tensor, bool)",
csrc/jit/runtime/static/ops.cpp:              "static_runtime::to_maybe_copy_out.other(Tensor self, Tensor other, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> (Tensor, bool)")) {
csrc/jit/runtime/static/ops.cpp:          return get_to_copy_functor(
csrc/jit/runtime/static/ops.cpp:          return to_maybe_copy_out_functor<true, true>;
csrc/jit/runtime/static/ops.cpp:          return to_maybe_copy_out_functor<true, false>;
csrc/jit/runtime/static/ops.cpp:          return to_maybe_copy_out_functor<false, true>;
csrc/jit/runtime/static/ops.cpp:          return to_maybe_copy_out_functor<false, false>;
csrc/jit/runtime/static/ops.cpp:      return get_to_copy_functor(
csrc/jit/runtime/static/ops.cpp:        at::native::dequantize_copy_out(out_t, self);
csrc/jit/runtime/static/ops.cpp:        at::native::reshape_copy_out(out, self, proposed_shape, true);
csrc/jit/runtime/static/ops.cpp:        at::native::flatten_copy_out(out, self, start_dim, end_dim);
csrc/jit/runtime/static/passes.cpp:      "static_runtime::to_maybe_copy_out.prim_dtype(Tensor self, int? dtype=None, bool non_blocking=False, bool copy=False) -> (Tensor, bool)",
csrc/jit/runtime/static/passes.cpp:      "static_runtime::to_maybe_copy_out.dtype(Tensor self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> (Tensor, bool)",
csrc/jit/runtime/static/passes.cpp:      "static_runtime::to_maybe_copy_out.other(Tensor self, Tensor other, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> (Tensor, bool)",
csrc/jit/runtime/static/passes.cpp:// `static_runtime::$OP_maybe_copy_out` variant of the op. This op
csrc/jit/runtime/static/passes.cpp:// |    | static_runtime::$OP_maybe_copy_out |
csrc/jit/runtime/static/passes.cpp:         fromQualString("static_runtime::to_maybe_copy_out")},
csrc/jit/runtime/static/passes.cpp:         fromQualString("static_runtime::to_maybe_copy_out")},
csrc/jit/runtime/static/passes.cpp:         fromQualString("static_runtime::to_maybe_copy_out")}}};
csrc/jit/runtime/static/ops.h:at::Tensor& reshape_copy_out(
csrc/jit/runtime/static/ops.h:at::Tensor& to_copy_out(
csrc/jit/runtime/static/ops.h:    bool copy_strides,
csrc/jit/runtime/static/generated_ops.cpp:      at::cpu::index_copy_out(out, self, dim, index, source);
csrc/jit/runtime/register_prim_ops_fulljit.cpp:template <bool has_reverse_arg, bool copy_return_list>
csrc/jit/runtime/register_prim_ops_fulljit.cpp:  if (copy_return_list) {
csrc/jit/runtime/register_prim_ops_fulljit.cpp:  if (copy_return_list) {
csrc/jit/runtime/register_prim_ops_fulljit.cpp:        sort_op</*has_reverse_arg*/ false, /*copy_return_list*/ true>,
csrc/jit/runtime/register_prim_ops_fulljit.cpp:        sort_op</*has_reverse_arg*/ true, /*copy_return_list*/ false>,
csrc/jit/mobile/flatbuffer_loader.h:// If should_copy_tensor_memory is true, then the returned module will NOT have
csrc/jit/mobile/flatbuffer_loader.h:// If should_copy_tensor_memory is false, then returned module will have tensors
csrc/jit/mobile/flatbuffer_loader.h:    bool should_copy_tensor_memory = false);
csrc/jit/mobile/flatbuffer_loader.h:    bool should_copy_tensor_memory);
csrc/jit/mobile/import_data.cpp:            copy.copy_(source);
csrc/jit/mobile/flatbuffer_loader.cpp:  void setShouldCopyTensorMemory(bool should_copy_tensor_memory) {
csrc/jit/mobile/flatbuffer_loader.cpp:    should_copy_tensor_memory_ = should_copy_tensor_memory;
csrc/jit/mobile/flatbuffer_loader.cpp:  bool should_copy_tensor_memory_ = false;
csrc/jit/mobile/flatbuffer_loader.cpp:    if (should_copy_tensor_memory_) {
csrc/jit/mobile/flatbuffer_loader.cpp:    bool should_copy_tensor_memory) {
csrc/jit/mobile/flatbuffer_loader.cpp:  loader.setShouldCopyTensorMemory(should_copy_tensor_memory);
csrc/jit/mobile/flatbuffer_loader.cpp:      /*should_copy_tensor_memory=*/false);
csrc/jit/mobile/model_tracer/TracerRunner.cpp:  zb.copy_(zf);
csrc/jit/mobile/model_tracer/TracerRunner.cpp:    tensor1.copy_(at::zeros({10}, at::kBool));
csrc/jit/mobile/model_tracer/TracerRunner.cpp:    tensor1.copy_(at::zeros({10}, at::kFloat));
csrc/jit/mobile/model_tracer/TracerRunner.cpp:    tensor1.copy_(at::zeros({10}, at::kInt));
csrc/jit/mobile/model_tracer/TracerRunner.cpp:  c.copy_(t.cpu());
csrc/jit/mobile/model_tracer/TracerRunner.cpp:    // When we encounter a GPU model, we should call .cpu().copy_() on the
csrc/jit/mobile/model_tracer/TracerRunner.cpp:    // When we encounter a CPU model, we should call .cpu().copy_() on the
csrc/jit/codegen/cuda/executor_kernel_arg.h:  virtual std::unique_ptr<ArgAbstract> copy_unique_ptr() const = 0;
csrc/jit/codegen/cuda/executor_kernel_arg.h:  std::unique_ptr<ArgAbstract> copy_unique_ptr() const override { \
csrc/jit/codegen/cuda/lower_utils.cpp:  std::copy_if(
csrc/jit/codegen/cuda/lower_utils.cpp:  std::copy_if(
csrc/jit/codegen/cuda/predicate_compute.cpp:  std::copy_if(
csrc/jit/codegen/cuda/predicate_compute.cpp:  std::copy_if(
csrc/jit/codegen/cuda/executor_kernel_arg.cpp:  arguments_.emplace_back(arg->copy_unique_ptr());
csrc/jit/codegen/cuda/executor_kernel_arg.cpp:  auto holder = arg->copy_unique_ptr();
csrc/jit/codegen/cuda/fusion_segmenter.cpp:  std::copy_if(
csrc/jit/codegen/cuda/fusion_segmenter.cpp:  std::copy_if(
csrc/jit/codegen/cuda/fusion_segmenter.cpp:    std::copy_if(
csrc/jit/codegen/cuda/lower_predicate_elimination.cpp:      std::copy_if(
csrc/jit/codegen/cuda/compute_at.cpp:  std::copy_if(
csrc/jit/codegen/cuda/parser.cpp:  static auto reshape_copy_schema =
csrc/jit/codegen/cuda/parser.cpp:  static auto view_copy_schema =
csrc/jit/codegen/cuda/parser.cpp:  if (node->matches(reshape_schema) || node->matches(reshape_copy_schema) ||
csrc/jit/codegen/cuda/parser.cpp:      node->matches(view_schema) || node->matches(view_copy_schema)) {
csrc/jit/codegen/cuda/parser.cpp:  static auto permute_copy_schema =
csrc/jit/codegen/cuda/parser.cpp:  if (node->matches(permute_schema) || node->matches(permute_copy_schema)) {
csrc/jit/codegen/cuda/parser.cpp:  static auto transpose_int_copy_schema =
csrc/jit/codegen/cuda/parser.cpp:  if (node->matches(transpose_int_copy_schema) ||
csrc/jit/codegen/cuda/parser.cpp:  static auto to_copy_schema =
csrc/jit/codegen/cuda/parser.cpp:  if (node->matches(to_copy_schema)) {
csrc/jit/codegen/cuda/manager.cpp:  static std::unordered_set<Symbol> alias_copy_op(
csrc/jit/codegen/cuda/manager.cpp:    if (alias_copy_op.find(n->kind()) != alias_copy_op.end()) {
csrc/jit/codegen/cuda/scheduler/utils.cpp:    std::copy_if(
csrc/jit/codegen/cuda/graph_fuser.cpp:  static std::unordered_map<Symbol, Symbol> alias_to_copy_mapping(
csrc/jit/codegen/cuda/graph_fuser.cpp:    if (alias_to_copy_mapping.find(n->kind()) != alias_to_copy_mapping.end()) {
csrc/jit/codegen/cuda/graph_fuser.cpp:    auto copy_op = graph->insertNode(
csrc/jit/codegen/cuda/graph_fuser.cpp:        graph->create(alias_to_copy_mapping[n->kind()], n->inputs(), 1));
csrc/jit/codegen/cuda/graph_fuser.cpp:    copy_op->output()->setType(n->output(0)->type());
csrc/jit/codegen/cuda/graph_fuser.cpp:    alias_db->createValue(copy_op->output());
csrc/jit/codegen/cuda/graph_fuser.cpp:    n->output()->replaceAllUsesWith(copy_op->output());
csrc/jit/codegen/cuda/graph_fuser.cpp:  static std::unordered_map<Symbol, Symbol> copy_to_alias_mapping(
csrc/jit/codegen/cuda/graph_fuser.cpp:  std::vector<Node*> alias_copy_ops;
csrc/jit/codegen/cuda/graph_fuser.cpp:    if (copy_to_alias_mapping.find(n->kind()) != copy_to_alias_mapping.end()) {
csrc/jit/codegen/cuda/graph_fuser.cpp:      alias_copy_ops.push_back(n);
csrc/jit/codegen/cuda/graph_fuser.cpp:        graph->create(copy_to_alias_mapping[n->kind()], n->inputs(), 1));
csrc/jit/codegen/cuda/graph_fuser.cpp:  for (Node* n : alias_copy_ops) {
csrc/jit/codegen/cuda/compute_at_map.cpp:  std::copy_if(
csrc/jit/codegen/cuda/compute_at_map.cpp:      std::copy_if(
csrc/jit/codegen/cuda/lower_validation.cpp:    std::copy_if(
csrc/jit/codegen/cuda/ir_utils.cpp:  std::copy_if(
csrc/jit/frontend/ir_emitter.cpp:      std::copy_if(
csrc/jit/frontend/ir_emitter.cpp:      // TODO: the Python equivalent code has special-cased copy_to
csrc/jit/frontend/ir_emitter.cpp:        graph->insert(aten::copy_, {slicedArg, convertedRhs}, {}, stmtRange);
csrc/jit/serialization/import_source.cpp:        non_holding_object_cache[obj] = obj->copy_to_weak_compilation_ref();
csrc/jit/tensorexpr/kernel.cpp:  std::copy_if(
csrc/jit/tensorexpr/kernel.cpp:  std::copy_if(
csrc/jit/passes/mkldnn_rewrite.cpp:            outputs[0].toObject()->copy_to_weak_compilation_ref();
csrc/jit/passes/freeze_module.cpp:                    attr.toObject()->copy_to_weak_compilation_ref();
csrc/jit/passes/concat_opt.cpp:  //     %22 = aten::copy_(%21, %2)      // copy %2
csrc/jit/passes/concat_opt.cpp:  //     %24 = aten::copy_(%23, %3)      // copy %3
csrc/jit/passes/concat_opt.cpp:      auto copy = graph_->create(aten::copy_, {slice->output(), cat_inp});
csrc/jit/passes/concat_opt.cpp:  //     %22 = aten::copy_(%21, %2)
csrc/jit/passes/concat_opt.cpp:  //     %24 = aten::copy_(%23, %3)
csrc/jit/passes/concat_opt.cpp:  //     %32 = aten::copy_(%31, %20)     // src of copy is aten::empty
csrc/jit/passes/concat_opt.cpp:  //     %34 = aten::copy_(%33, %4)
csrc/jit/passes/concat_opt.cpp:  //     %22 = aten::copy_(%21, %2)
csrc/jit/passes/concat_opt.cpp:  //     %24 = aten::copy_(%23, %3)
csrc/jit/passes/concat_opt.cpp:  //     %34 = aten::copy_(%33, %4)
csrc/jit/passes/metal_rewrite.cpp:          Symbol::fromQualString("metal::copy_to_host"), {namedValue});
csrc/jit/passes/bailout_graph.cpp:      : graph_(std::move(graph)), copy_graph_(std::move(target)) {}
csrc/jit/passes/bailout_graph.cpp:      auto new_const = copy_graph_->createClone(node, {nullptr});
csrc/jit/passes/bailout_graph.cpp:      copy_graph_->block()->prependNode(new_const);
csrc/jit/passes/bailout_graph.cpp:    auto new_value = copy_graph_->block()->addInput();
csrc/jit/passes/bailout_graph.cpp:    auto* block = copy_graph_->block();
csrc/jit/passes/bailout_graph.cpp:    auto new_node = block->appendNode(copy_graph_->createClone(node, env));
csrc/jit/passes/bailout_graph.cpp:    auto* block = copy_graph_->block();
csrc/jit/passes/bailout_graph.cpp:        copy_graph_->insert(aten::sub, {old_max_count, cur_iter});
csrc/jit/passes/bailout_graph.cpp:    auto one = copy_graph_->insertConstant({1});
csrc/jit/passes/bailout_graph.cpp:        copy_graph_->insert(aten::sub, {updated_max_trip_count, one});
csrc/jit/passes/bailout_graph.cpp:    auto cur_plus_one = copy_graph_->insert(aten::add, {one, cur_iter});
csrc/jit/passes/bailout_graph.cpp:        copy_graph_->insertNode(copy_graph_->create(prim::Loop, {}, 0))
csrc/jit/passes/bailout_graph.cpp:      auto adj_iter_ctr = copy_graph_->insert(aten::add, {cur_plus_one, one});
csrc/jit/passes/bailout_graph.cpp:      copy_graph_->registerOutput(getOrAddInputForValue(ov));
csrc/jit/passes/bailout_graph.cpp:    return copy_graph_;
csrc/jit/passes/bailout_graph.cpp:  std::shared_ptr<Graph> copy_graph_;
csrc/jit/passes/shape_analysis.cpp:        aten::copy_,
csrc/jit/passes/onnx/unpack_quantized_weights.cpp:  const_bias_copy.copy_(const_bias);
csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:  TORCH_INTERNAL_ASSERT(node->kind() == aten::copy_);
csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:  // aten::copy_ can be viewed as a special case of index_put, where the
csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:  // Remove aten::copy_, and replace it with index_put.
csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:  // Tracing aten::copy_ broadcasts the rhs values.
csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:    // Cases from a[i] = x. Convert to copy_ and eventually index_put_.
csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:    auto new_copy = graph->create(aten::copy_, 1);
csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:      if (nkind == aten::copy_) {
csrc/jit/passes/onnx/function_extraction.cpp:    std::copy_if(
csrc/jit/passes/onnx/function_extraction.cpp:    std::copy_if(
csrc/jit/passes/onnx/function_extraction.cpp:  auto copy_attr =
csrc/jit/passes/onnx/function_extraction.cpp:      copy_attr(ref_n, func_n, attr, attr_name);
csrc/jit/passes/onnx/function_extraction.cpp:          copy_attr(n, func_n, attr, attr_name);
csrc/jit/passes/onnx/function_extraction.cpp:      copy_attr(node, func_n, attr, attr.toUnqualString());
csrc/jit/passes/onnx/shape_type_inference.cpp:      const_val_copy.copy_(const_val);
csrc/jit/passes/onnx/shape_type_inference.cpp:    const_fold_val_copy.copy_(const_fold_val.value());
csrc/jit/passes/onnx/shape_type_inference.cpp:        f_copy.copy_(f);
csrc/jit/passes/onnx/shape_type_inference.cpp:        f_copy.copy_(f);
csrc/jit/passes/onnx/shape_type_inference.cpp:      const_val_copy.copy_(const_val);
csrc/jit/passes/onnx/constant_fold.cpp:  f_copy.copy_(f);
csrc/jit/passes/symbolic_shape_runtime_fusion.cpp:  auto copy_node = graph->create(
csrc/jit/passes/symbolic_shape_runtime_fusion.cpp:  false_block->appendNode(copy_node);
csrc/jit/passes/symbolic_shape_runtime_fusion.cpp:    false_block->replaceOutput(i, copy_node->outputs().at(i));
csrc/jit/passes/symbolic_shape_runtime_fusion.cpp:        out_t.copy_(inputs[i].toTensor());
csrc/api/src/optim/lbfgs.cpp:    _params.at(i).copy_(params_data.at(i));
csrc/api/src/optim/lbfgs.cpp:      prev_flat_grad.copy_(flat_grad);
csrc/api/src/nn/init.cpp:  tensor.view_as(q).copy_(q);
csrc/api/src/nn/modules/adaptive.cpp:      gather_inds.index_copy_(0, row_indices, target.index({target_mask}));
csrc/api/src/nn/modules/adaptive.cpp:      output.index_copy_(0, row_indices, local_logprob.squeeze(1));
csrc/api/src/nn/modules/_functions.cpp:    scale_current.copy_(scale_previous);
csrc/utils/tensor_new.cpp:    bool copy_variables,
csrc/utils/tensor_new.cpp:    bool copy_numpy,
csrc/utils/tensor_new.cpp:    if (copy_variables) {
csrc/utils/tensor_new.cpp:        /*copy=*/copy_variables);
csrc/utils/tensor_new.cpp:        /*copy=*/copy_numpy);
csrc/utils/tensor_new.cpp:        tensor_from_numpy(data, /*warn_if_not_writeable=*/!copy_numpy);
csrc/utils/tensor_new.cpp:        /*copy=*/copy_numpy);
csrc/utils/tensor_new.cpp:      /*copy_variables=*/true,
csrc/utils/tensor_new.cpp:      /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:      /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:      /*copy_numpy=*/false,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/false,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/false,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:      /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:      /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:      /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:      /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:      /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:      /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:      /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:      /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:      /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:      /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:      /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:      /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:      /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:      /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:      /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:      /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/true,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/true,
csrc/utils/tensor_new.cpp:        /*copy_variables=*/false,
csrc/utils/tensor_new.cpp:        /*copy_numpy=*/false,
csrc/utils/tensor_new.cpp:        /* copy_variables = */ false,
csrc/utils/tensor_new.cpp:        /* copy_numpy = */ false,
csrc/utils/python_arg_parser.cpp:      "to",           "_to_copy",      "copy_",
csrc/Storage.cpp:#include <torch/csrc/copy_utils.h>
csrc/lazy/core/tensor_impl.cpp:c10::intrusive_ptr<c10::TensorImpl> LTCTensorImpl::shallow_copy_and_detach(
csrc/lazy/core/tensor_impl.cpp:  copy_tensor_metadata(
csrc/lazy/core/tensor_impl.cpp:c10::intrusive_ptr<c10::TensorImpl> LTCTensorImpl::shallow_copy_and_detach(
csrc/lazy/core/tensor_impl.cpp:  copy_tensor_metadata(
csrc/lazy/core/tensor_impl.cpp:void LTCTensorImpl::shallow_copy_from(
csrc/lazy/core/tensor_impl.cpp:  copy_tensor_metadata(
csrc/lazy/core/shape_inference.h:TORCH_API std::vector<torch::lazy::Shape> compute_shape_narrow_copy_symint(const at::Tensor & self, int64_t dim, int64_t start, c10::SymInt length);
csrc/lazy/core/tensor_impl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
csrc/lazy/core/tensor_impl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
csrc/lazy/core/tensor_impl.h:  void shallow_copy_from(const c10::intrusive_ptr<TensorImpl>& impl) override;
csrc/lazy/core/shape_inference.cpp:std::vector<Shape> compute_shape_narrow_copy_symint(
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector _reshape_alias_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(_reshape_alias_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return _reshape_alias_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector alias_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(alias_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return alias_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector as_strided_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(as_strided_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return as_strided_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector detach_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(detach_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return detach_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector diagonal_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(diagonal_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return diagonal_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector expand_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(expand_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return expand_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector permute_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(permute_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return permute_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector select_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(select_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return select_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector slice_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(slice_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return slice_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector squeeze_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(squeeze_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return squeeze_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector squeeze_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(squeeze_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return squeeze_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector squeeze_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(squeeze_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return squeeze_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector t_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(t_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return t_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector transpose_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(transpose_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return transpose_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector unfold_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(unfold_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return unfold_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector unsqueeze_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(unsqueeze_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return unsqueeze_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector view_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(view_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return view_copy_out;
csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector view_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(view_copy_out.size(), 1);
csrc/lazy/generated/LazyIr.h:    return view_copy_out;
csrc/lazy/generated/LazyNativeFunctions.cpp:    at::Tensor LazyNativeFunctions::_reshape_alias_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) {
csrc/lazy/generated/LazyNativeFunctions.cpp:        auto out_meta = at::compositeexplicitautogradnonfunctional::_reshape_alias_copy_symint(self_meta, size, stride);
csrc/lazy/generated/LazyNativeFunctions.cpp:    at::Tensor LazyNativeFunctions::as_strided_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset) {
csrc/lazy/generated/LazyNativeFunctions.cpp:        auto out_meta = at::compositeexplicitautogradnonfunctional::as_strided_copy_symint(self_meta, size, stride, storage_offset);
csrc/lazy/generated/LazyNativeFunctions.cpp:    at::Tensor LazyNativeFunctions::expand_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit) {
csrc/lazy/generated/LazyNativeFunctions.cpp:        auto out_meta = at::compositeexplicitautogradnonfunctional::expand_copy_symint(self_meta, size, implicit);
csrc/lazy/generated/LazyNativeFunctions.cpp:    at::Tensor LazyNativeFunctions::slice_copy_symint(const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step) {
csrc/lazy/generated/LazyNativeFunctions.cpp:        auto out_meta = at::compositeexplicitautogradnonfunctional::slice_copy_symint(self_meta, dim, start, end, step);
csrc/lazy/generated/LazyNativeFunctions.cpp:    at::Tensor LazyNativeFunctions::view_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size) {
csrc/lazy/generated/LazyNativeFunctions.cpp:        auto out_meta = at::compositeexplicitautogradnonfunctional::view_copy_symint(self_meta, size);
csrc/lazy/generated/RegisterAutogradLazy.cpp:#include <ATen/ops/_copy_from_and_resize.h>
csrc/lazy/generated/RegisterAutogradLazy.cpp:#include <ATen/ops/_copy_from.h>
csrc/lazy/generated/RegisterAutogradLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_AutogradLazy_out_native_group_norm_out_tmp), out0);
csrc/lazy/generated/RegisterAutogradLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_AutogradLazy_out_native_group_norm_out_tmp), out1);
csrc/lazy/generated/RegisterAutogradLazy.cpp:  at::_copy_from_and_resize(std::get<2>(wrapper_AutogradLazy_out_native_group_norm_out_tmp), out2);
csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor _copy_from(const at::Tensor & self, const at::Tensor & dst, bool non_blocking);
csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor _copy_from_and_resize(const at::Tensor & self, const at::Tensor & dst);
csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor _reshape_alias_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride);
csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor as_strided_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset);
csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor expand_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit);
csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor narrow_copy_symint(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length);
csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor slice_copy_symint(const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step);
csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor view_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size);
csrc/lazy/generated/RegisterLazy.cpp:#include <ATen/ops/_copy_from_and_resize.h>
csrc/lazy/generated/RegisterLazy.cpp:#include <ATen/ops/_copy_from.h>
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__adaptive_avg_pool2d_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__adaptive_avg_pool2d_backward_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor wrapper_Lazy___copy_from(const at::Tensor & self, const at::Tensor & dst, bool non_blocking) {
csrc/lazy/generated/RegisterLazy.cpp:  return torch::lazy::LazyNativeFunctions::_copy_from(self, dst, non_blocking);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out__copy_from_out(const at::Tensor & self, const at::Tensor & dst, bool non_blocking, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out__copy_from_out_tmp = wrapper_Lazy___copy_from(self, dst, non_blocking);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__copy_from_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor wrapper_Lazy___copy_from_and_resize(const at::Tensor & self, const at::Tensor & dst) {
csrc/lazy/generated/RegisterLazy.cpp:  return torch::lazy::LazyNativeFunctions::_copy_from_and_resize(self, dst);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out__copy_from_and_resize_out(const at::Tensor & self, const at::Tensor & dst, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out__copy_from_and_resize_out_tmp = wrapper_Lazy___copy_from_and_resize(self, dst);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__copy_from_and_resize_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__log_softmax_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__log_softmax_backward_data_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  return torch::lazy::LazyNativeFunctions::_reshape_alias_copy_symint(self, size, stride);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out__reshape_alias_copy_out(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out__reshape_alias_copy_out_tmp = wrapper_Lazy___reshape_alias_copy(self, size, stride);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__reshape_alias_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__softmax_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__softmax_backward_data_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out__to_copy_out(const at::Tensor & self, bool non_blocking, c10::optional<at::MemoryFormat> memory_format, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out__to_copy_out_tmp = wrapper_Lazy___to_copy(self, out.scalar_type(), out.layout(), out.device(), c10::nullopt, non_blocking, memory_format);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__to_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__trilinear_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out__unsafe_view_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_abs_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__abs__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_add_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_add__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_addcdiv_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__addcdiv__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_addcmul_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__addcmul__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_addmm_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__addmm__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_alias_copy_out(const at::Tensor & self, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_alias_copy_out_tmp = wrapper_Lazy__alias_copy(self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_alias_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_all_out_all_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_all_out_any_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  return torch::lazy::LazyNativeFunctions::as_strided_copy_symint(self, size, stride, storage_offset);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_as_strided_copy_out(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_as_strided_copy_out_tmp = wrapper_Lazy__as_strided_copy(self, size, stride, storage_offset);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_as_strided_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_as_strided_scatter_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_avg_pool2d_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_avg_pool2d_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_baddbmm_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__baddbmm__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_bernoulli_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_float_out_bernoulli_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_float_bernoulli__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_binary_cross_entropy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_binary_cross_entropy_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_bitwise_and_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_bitwise_and__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_bitwise_or_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_bitwise_or__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_block_diag_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_bmm_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_cat_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_clamp_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__clamp__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_clamp_min_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__clamp_min__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_clone_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_constant_pad_nd_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_convolution_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_out_convolution_backward_out_tmp), out0);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_out_convolution_backward_out_tmp), out1);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<2>(wrapper_Lazy_out_convolution_backward_out_tmp), out2);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_cos_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__cos__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_cumsum_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__cumsum__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_detach_copy_out(const at::Tensor & self, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_detach_copy_out_tmp = wrapper_Lazy__detach_copy(self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_detach_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_diag_embed_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_diagonal_backward_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_diagonal_copy_out(const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_diagonal_copy_out_tmp = wrapper_Lazy__diagonal_copy(self, offset, dim1, dim2);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_diagonal_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_diagonal_scatter_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_div_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_div__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_mode_div_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_mode_div__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_elu_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__elu__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_elu_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_embedding_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_embedding_dense_backward_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_empty_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_empty_strided_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Scalar_out_eq_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Scalar_eq__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_eq_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_eq__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_exp_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__exp__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  return torch::lazy::LazyNativeFunctions::expand_copy_symint(self, size, implicit);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_expand_copy_out(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_expand_copy_out_tmp = wrapper_Lazy__expand_copy(self, size, implicit);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_expand_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_flip_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_floor_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__floor__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_frac_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__frac__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_gather_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Scalar_out_ge_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Scalar_ge__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_ge_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_ge__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_gelu_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__gelu__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_gelu_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_glu_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_glu_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_glu_jvp_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_grid_sampler_2d_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_out_grid_sampler_2d_backward_out_tmp), out0);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_out_grid_sampler_2d_backward_out_tmp), out1);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Scalar_out_gt_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Scalar_gt__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_gt_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_gt__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_hardsigmoid_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__hardsigmoid__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_index_select_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Scalar_out_le_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Scalar_le__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_le_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_le__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_leaky_relu_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__leaky_relu__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_leaky_relu_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_lift_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_atol_rtol_tensor_out_linalg_pinv_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_log_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__log__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_log2_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__log2__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_log_sigmoid_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_output_log_sigmoid_forward_out_tmp), output);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_output_log_sigmoid_forward_out_tmp), buffer);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Scalar_out_lt_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Scalar_lt__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_lt_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_lt__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Scalar_out_masked_fill_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Scalar_masked_fill__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_masked_fill_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_masked_fill__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_dim_max_max_out_tmp), max);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_dim_max_max_out_tmp), max_values);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_unary_out_max_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_out_max_pool2d_with_indices_out_tmp), out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_out_max_pool2d_with_indices_out_tmp), indices);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_max_pool2d_with_indices_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_out_max_pool3d_with_indices_out_tmp), out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_out_max_pool3d_with_indices_out_tmp), indices);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_max_pool3d_with_indices_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_maximum_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_mean_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_minimum_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_mm_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_mul_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_mul__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_mv_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  return torch::lazy::LazyNativeFunctions::narrow_copy_symint(self, dim, start, length);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_narrow_copy_out(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_narrow_copy_out_tmp = wrapper_Lazy__narrow_copy(self, dim, start, length);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_narrow_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_out_native_batch_norm_out_tmp), out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_out_native_batch_norm_out_tmp), save_mean);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<2>(wrapper_Lazy_out_native_batch_norm_out_tmp), save_invstd);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_out_native_batch_norm_backward_out_tmp), out0);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_out_native_batch_norm_backward_out_tmp), out1);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<2>(wrapper_Lazy_out_native_batch_norm_backward_out_tmp), out2);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_out_native_dropout_out_tmp), out0);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_out_native_dropout_out_tmp), out1);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_native_dropout_backward_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_out_native_layer_norm_out_tmp), out0);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_out_native_layer_norm_out_tmp), out1);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<2>(wrapper_Lazy_out_native_layer_norm_out_tmp), out2);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_out_native_layer_norm_backward_out_tmp), out0);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_out_native_layer_norm_backward_out_tmp), out1);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<2>(wrapper_Lazy_out_native_layer_norm_backward_out_tmp), out2);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Scalar_out_ne_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Scalar_ne__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_ne_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_ne__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_neg_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__neg__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_new_empty_strided_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_nll_loss2d_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_output_nll_loss2d_forward_out_tmp), output);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_output_nll_loss2d_forward_out_tmp), total_weight);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_nll_loss_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_output_nll_loss_forward_out_tmp), output);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_output_nll_loss_forward_out_tmp), total_weight);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_nonzero_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_norm_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_permute_copy_out(const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_permute_copy_out_tmp = wrapper_Lazy__permute_copy(self, dims);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_permute_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_pixel_shuffle_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_pixel_unshuffle_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_Tensor_out_pow_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_pow__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_Scalar_out_pow_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Scalar_pow__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_from_out_random_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_from_random__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_to_out_random_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_to_random__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_random_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__random__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_reciprocal_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__reciprocal__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_relu_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__relu__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_remainder_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_remainder__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_repeat_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_rsqrt_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__rsqrt__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_scatter_add_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__scatter_add__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_select_backward_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_int_out_select_copy_out(const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_int_out_select_copy_out_tmp = wrapper_Lazy_int_select_copy(self, dim, index);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_int_out_select_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_select_scatter_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_sgn_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__sgn__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_sigmoid_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__sigmoid__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_sigmoid_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_silu_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__silu__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_slice_backward_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  return torch::lazy::LazyNativeFunctions::slice_copy_symint(self, dim, start, end, step);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_Tensor_out_slice_copy_out(const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_Tensor_out_slice_copy_out_tmp = wrapper_Lazy_Tensor_slice_copy(self, dim, start, end, step);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_Tensor_out_slice_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_slice_scatter_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_smooth_l1_loss_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_smooth_l1_loss_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_softplus_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_softplus_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_values_sort_out_tmp), values);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_values_sort_out_tmp), indices);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_sqrt_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__sqrt__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_squeeze_copy_out(const at::Tensor & self, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_squeeze_copy_out_tmp = wrapper_Lazy__squeeze_copy(self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_squeeze_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_dim_out_squeeze_copy_out(const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_dim_out_squeeze_copy_out_tmp = wrapper_Lazy_dim_squeeze_copy(self, dim);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_dim_out_squeeze_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_dims_out_squeeze_copy_out(const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_dims_out_squeeze_copy_out_tmp = wrapper_Lazy_dims_squeeze_copy(self, dim);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_dims_out_squeeze_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_stack_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_std_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_correction_out_std_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_sub_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy_Tensor_sub__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_sum_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_IntList_out_sum_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_t_copy_out(const at::Tensor & self, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_t_copy_out_tmp = wrapper_Lazy__t_copy(self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_t_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_tanh_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__tanh__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_tanh_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_threshold_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__threshold__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_threshold_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<0>(wrapper_Lazy_values_topk_out_tmp), values);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(std::get<1>(wrapper_Lazy_values_topk_out_tmp), indices);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_trace_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_int_out_transpose_copy_out(const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_int_out_transpose_copy_out_tmp = wrapper_Lazy_int_transpose_copy(self, dim0, dim1);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_int_out_transpose_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_tril_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__tril__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_triu_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__triu__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_trunc_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__trunc__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_unfold_copy_out(const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_unfold_copy_out_tmp = wrapper_Lazy__unfold_copy(self, dimension, size, step);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_unfold_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_unsqueeze_copy_out(const at::Tensor & self, int64_t dim, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_unsqueeze_copy_out_tmp = wrapper_Lazy__unsqueeze_copy(self, dim);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_unsqueeze_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_upsample_bilinear2d_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_upsample_bilinear2d_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_upsample_nearest2d_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_grad_input_upsample_nearest2d_backward_out_tmp, grad_input);
csrc/lazy/generated/RegisterLazy.cpp:  return torch::lazy::LazyNativeFunctions::view_copy_symint(self, size);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_out_view_copy_out(const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_out_view_copy_out_tmp = wrapper_Lazy__view_copy(self, size);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_view_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:at::Tensor & wrapper_Lazy_dtype_out_view_copy_out(const at::Tensor & self, at::ScalarType dtype, at::Tensor & out) {
csrc/lazy/generated/RegisterLazy.cpp:  auto wrapper_Lazy_dtype_out_view_copy_out_tmp = wrapper_Lazy_dtype_view_copy(self, dtype);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_dtype_out_view_copy_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from_and_resize(wrapper_Lazy_out_zero_out_tmp, out);
csrc/lazy/generated/RegisterLazy.cpp:  at::_copy_from(wrapper_Lazy__zero__tmp, self);
csrc/lazy/generated/RegisterLazy.cpp:    m.impl("_copy_from",
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy___copy_from));
csrc/lazy/generated/RegisterLazy.cpp:    m.impl("_copy_from.out",
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out__copy_from_out));
csrc/lazy/generated/RegisterLazy.cpp:    m.impl("_copy_from_and_resize",
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy___copy_from_and_resize));
csrc/lazy/generated/RegisterLazy.cpp:    m.impl("_copy_from_and_resize.out",
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out__copy_from_and_resize_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out__reshape_alias_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out__to_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_alias_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_as_strided_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_detach_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_diagonal_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_expand_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_narrow_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_permute_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_int_out_select_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_Tensor_out_slice_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_squeeze_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_dim_out_squeeze_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_dims_out_squeeze_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_t_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_int_out_transpose_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_unfold_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_unsqueeze_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_out_view_copy_out));
csrc/lazy/generated/RegisterLazy.cpp:    TORCH_FN(wrapper_Lazy_dtype_out_view_copy_out));
csrc/lazy/ts_backend/ts_eager_fallback.cpp:      at::_copy_from_and_resize(eager_tensors[i], tensor_args[i]);
csrc/lazy/ts_backend/config.cpp:    "Use synchronous copy inside _copy_from op");
csrc/lazy/ts_backend/ts_native_functions.cpp:at::Tensor LazyNativeFunctions::_copy_from(
csrc/lazy/ts_backend/ts_native_functions.cpp:    // dst.copy_()
csrc/lazy/ts_backend/ts_native_functions.cpp:    dst.resize_as_(typed_tensor).copy_(typed_tensor);
csrc/lazy/ts_backend/ts_native_functions.cpp:        dst_tensor_data->copy_(*src_tensor_data);
csrc/lazy/ts_backend/ts_native_functions.cpp:        dst_tensor_data->copy_(self_tensor->ToTensor(/*detached=*/false));
csrc/lazy/ts_backend/ts_native_functions.cpp:      copy_(dst_tensor, self_tensor);
csrc/lazy/ts_backend/ts_native_functions.cpp:at::Tensor LazyNativeFunctions::_copy_from_and_resize(
csrc/lazy/ts_backend/ts_native_functions.cpp:    dst.resize_as_(typed_tensor).copy_(typed_tensor);
csrc/lazy/ts_backend/ts_native_functions.cpp:  return LazyNativeFunctions::view_copy_symint(
csrc/lazy/ts_backend/ts_native_functions.cpp:at::Tensor LazyNativeFunctions::narrow_copy_symint(
csrc/lazy/ts_backend/ts_native_functions.cpp:  out.copy_(out_unwrapped);
csrc/lazy/ts_backend/tensor_aten_ops.h:void copy_(torch::lazy::LazyTensorPtr& input, torch::lazy::LazyTensorPtr& src);
csrc/lazy/ts_backend/ops/to_copy.h:    torch::lazy::TSOpVector _to_copy_out =
csrc/lazy/ts_backend/ops/to_copy.h:    TORCH_CHECK_EQ(_to_copy_out.size(), 1);
csrc/lazy/ts_backend/ops/to_copy.h:    return _to_copy_out;
csrc/lazy/ts_backend/tensor_aten_ops.cpp:void copy_(torch::lazy::LazyTensorPtr& input, torch::lazy::LazyTensorPtr& src) {
csrc/lazy/ts_backend/tensor_aten_ops.cpp:    torch::lazy::Value copy_value;
csrc/lazy/ts_backend/tensor_aten_ops.cpp:      copy_value = src->GetIrValue();
csrc/lazy/ts_backend/tensor_aten_ops.cpp:      copy_value = torch::lazy::MakeCast(
csrc/lazy/ts_backend/tensor_aten_ops.cpp:    input->SetIrValue(MaybeExpand(copy_value, input->shape()));
csrc/lazy/ts_backend/ts_node_lowering.cpp:  LowerBuiltin(at::aten::copy_, function, arguments);
Binary file cuda/amp/__pycache__/grad_scaler.cpython-310.pyc matches
cuda/amp/grad_scaler.py:                self._scale.copy_(new_scale)  # type: ignore[union-attr]
Binary file cuda/__pycache__/graphs.cpython-310.pyc matches
cuda/graphs.py:                        static_input_surface[i].copy_(inputs[i])
cuda/graphs.py:                            g.copy_(grad)
_decomp/decompositions.py:    _safe_copy_out,
_decomp/decompositions.py:    return _safe_copy_out(copy_from=result, copy_to=grad_input, exact_dtype=True)
_decomp/decompositions.py:                running_mean.copy_(new_running_mean)
_decomp/decompositions.py:                running_var.copy_(new_running_var)
_decomp/decompositions.py:@register_decomposition(aten.index_copy_)
_decomp/decompositions.py:def index_copy_(x: TensorLike, dim: int, index: TensorLike, tensor: TensorLike):
_decomp/decompositions.py:    return self.copy_((high - low) * torch.rand_like(self) + low)
_decomp/decompositions.py:        return args[0].copy_(out)
Binary file _decomp/__pycache__/decompositions.cpython-310.pyc matches
distributed/optim/named_optimizer.py:                        shard.tensor.detach().copy_(src_shard.tensor)
distributed/optim/named_optimizer.py:                    state_val.detach().copy_(src_state_val)
distributed/optim/zero_redundancy_optimizer.py:def _recursive_copy_to_device(
distributed/optim/zero_redundancy_optimizer.py:            _recursive_copy_to_device(val, non_blocking=non_blocking, device=device)
distributed/optim/zero_redundancy_optimizer.py:            key: _recursive_copy_to_device(
distributed/optim/zero_redundancy_optimizer.py:                        _recursive_copy_to_device(
distributed/optim/zero_redundancy_optimizer.py:                        _recursive_copy_to_device(
distributed/optim/zero_redundancy_optimizer.py:                self.optim.state[param] = _recursive_copy_to_device(
distributed/optim/zero_redundancy_optimizer.py:                        bucket[offset:offset_next].copy_(param.data.flatten())
distributed/optim/zero_redundancy_optimizer.py:                    tensor[offset:offset_next].copy_(param.data.flatten())
distributed/_tensor/ops/tensor_ops.py:    "aten.copy_.default",
distributed/_tensor/ops/pointwise_ops.py:    "aten.copy_sign.Scalar",
distributed/_tensor/ops/pointwise_ops.py:    "aten.copy_sign.Scalar_out",
distributed/_tensor/ops/pointwise_ops.py:    "aten.copy_sign.Tensor",
distributed/_tensor/ops/pointwise_ops.py:    "aten.copy_sign.out",
distributed/_tensor/ops/pointwise_ops.py:    "aten.copy_sign_.Scalar",
distributed/_tensor/ops/pointwise_ops.py:    "aten.copy_sign_.Tensor",
distributed/_tensor/device_mesh.py:            output.copy_(
distributed/pipeline/sync/pipe.py:        self._copy_streams: List[List[AbstractStream]] = []
distributed/pipeline/sync/pipe.py:        copy_streams = self._ensure_copy_streams()
distributed/pipeline/sync/pipe.py:        self.pipeline = Pipeline(self.partitions, self.devices, copy_streams, self._skip_layout, checkpoint_stop)
distributed/pipeline/sync/pipe.py:    def _ensure_copy_streams(self) -> List[List[AbstractStream]]:
distributed/pipeline/sync/pipe.py:        if not self._copy_streams:
distributed/pipeline/sync/pipe.py:                self._copy_streams.append([new_stream(device) for _ in range(self.chunks)])
distributed/pipeline/sync/pipe.py:        return self._copy_streams
distributed/pipeline/sync/pipeline.py:        copy_streams: List[List[AbstractStream]],
distributed/pipeline/sync/pipeline.py:        self.copy_streams = copy_streams
distributed/pipeline/sync/pipeline.py:        copy_streams = self.copy_streams
distributed/pipeline/sync/pipeline.py:            next_stream = copy_streams[j][i]
distributed/pipeline/sync/pipeline.py:            for prev_j, ns, name in skip_layout.copy_policy(j):
distributed/pipeline/sync/pipeline.py:                prev_stream = copy_streams[prev_j][i]
distributed/pipeline/sync/pipeline.py:                prev_stream = copy_streams[j - 1][i]
distributed/pipeline/sync/pipeline.py:        copy_streams = self.copy_streams
distributed/pipeline/sync/pipeline.py:                _wait(batch, copy_streams[j][i], streams[j])
distributed/pipeline/sync/pipeline.py:                _wait(batch, streams[j], copy_streams[j][i])
distributed/pipeline/sync/skip/layout.py:    def copy_policy(self, next_j: int) -> Iterable[Tuple[int, Namespace, str]]:
distributed/algorithms/ddp_comm_hooks/default_hooks.py:        decompressed_tensor.copy_(fut.value()[0])
distributed/algorithms/ddp_comm_hooks/default_hooks.py:        decompressed_tensor.copy_(fut.value()[0])
distributed/algorithms/ddp_comm_hooks/default_hooks.py:            decompressed_tensor.copy_(fut.value())
distributed/algorithms/ddp_comm_hooks/default_hooks.py:            decompressed_tensor.copy_(fut.value())
distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:                q.copy_(
distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:            tensor.copy_(
distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:                    original_tensor.copy_(tensor[i])
distributed/fsdp/_unshard_param_utils.py:        handle.flat_param._local_shard[: param_shard.numel()].copy_(param_shard)  # type: ignore[attr-defined]
distributed/fsdp/_unshard_param_utils.py:                existing_grad[: grad_shard.numel()].copy_(grad_shard)
distributed/fsdp/sharded_grad_scaler.py:                v.copy_(v_on_cuda.cpu())
distributed/fsdp/sharded_grad_scaler.py:                self._scale.copy_(new_scale)  # type: ignore[union-attr]
distributed/fsdp/_runtime_utils.py:                flat_param._cpu_grad.copy_(  # type: ignore[attr-defined]
distributed/fsdp/flat_param.py:        Since :meth:`load_state_dict` is implemented via :meth:`copy_`, the
distributed/fsdp/flat_param.py:        # `copy_()` implicitly casts to the low precision
distributed/fsdp/flat_param.py:        flat_param._mp_shard.copy_(  # type: ignore[attr-defined]
distributed/fsdp/flat_param.py:            padded_unsharded_flat_param[: self.flat_param.numel()].copy_(
distributed/fsdp/flat_param.py:            dst_tensor[offset : offset + expected_shape.numel()].copy_(src_tensor)
distributed/_shard/sharded_tensor/api.py:                data[shard_offset: shard_offset + src.numel()].copy_(src)
distributed/_shard/sharded_tensor/api.py:            out_narrow_view.copy_(tensor)
distributed/_shard/sharded_tensor/api.py:        copy_tensor = kwargs.get("copy", False)
distributed/_shard/sharded_tensor/api.py:        if not copy_tensor and dtype_to == current_dtype and device_to == current_device:
distributed/_shard/sharded_tensor/api.py:                copy=copy_tensor,
distributed/_shard/sharded_tensor/_ops/misc_ops.py:@_sharded_op_impl(torch._has_compatible_shallow_copy_type)
distributed/_shard/sharded_tensor/_ops/misc_ops.py:def tensor_has_compatible_shallow_copy_type(types, args=(), kwargs=None, pg=None):
distributed/_shard/sharded_tensor/_ops/tensor_ops.py:    # instead of using the default tensor.__deepcopy__
distributed/_shard/sharded_tensor/_ops/tensor_ops.py:    torch.Tensor.__deepcopy__,
distributed/_shard/sharded_tensor/_ops/tensor_ops.py:@_sharded_op_impl(torch.Tensor.copy_)
distributed/_shard/sharded_tensor/_ops/tensor_ops.py:        local_shard.tensor.copy_(new_shard.tensor, nonblocking)
distributed/_shard/replicated_tensor.py:    def __deepcopy__(self, memo):
distributed/checkpoint/filesystem.py:        per_thread_copy_ahead: int = 10_000_000,
distributed/checkpoint/filesystem.py:            per_thread_copy_ahead: How many bytes to copy from the GPU ahead of saving then. Default 10Mb.
distributed/checkpoint/filesystem.py:        self.per_thread_copy_ahead = per_thread_copy_ahead
distributed/checkpoint/filesystem.py:                    self.per_thread_copy_ahead,
distributed/checkpoint/filesystem.py:            inflight_threshhold=self.per_thread_copy_ahead,
distributed/checkpoint/filesystem.py:                        target_tensor.copy_(tensor)
_dynamo/symbolic_convert.py:            state = self.copy_graphstate()
_dynamo/symbolic_convert.py:        state = self.copy_graphstate()
_dynamo/symbolic_convert.py:            self.checkpoint = inst, self.copy_graphstate()
_dynamo/symbolic_convert.py:        prior = self.copy_graphstate()
_dynamo/symbolic_convert.py:    def copy_graphstate(self) -> InstructionTranslatorGraphState:
_dynamo/symbolic_convert.py:            self.output.copy_graphstate(),
_dynamo/symbolic_convert.py:        """Restore a checkpoint created by self.copy_graphstate()"""
_dynamo/symbolic_convert.py:        # Mutable state checkpointed by copy_graphstate()
_dynamo/variables/torch.py:            graph_checkpoint, checkpoint = tx.output.graph, tx.copy_graphstate()
_dynamo/variables/torch.py:                state = tx.copy_graphstate()
_dynamo/utils.py:            result.copy_(x.clone())
_dynamo/utils.py:                    param.copy_(original_value)
_dynamo/utils.py:def deepcopy_to_fake_tensor(obj, fake_mode):
_dynamo/utils.py:            nnmodule = deepcopy_to_fake_tensor(nnmodule, tx.fake_mode)
_dynamo/debug_utils.py:            copy_tensor_attrs = [fake_mode.from_tensor(x) for x in real_inputs]
_dynamo/debug_utils.py:                        copy_tensor_attrs,
_dynamo/debug_utils.py:                        copy_tensor_attrs,
_dynamo/debug_utils.py:                            copy_tensor_attrs,
_dynamo/debug_utils.py:                            copy_tensor_attrs,
_dynamo/output_graph.py:        copy_gm = copy.deepcopy(self.gm)
_dynamo/output_graph.py:        self.candidate = self.backend(copy_gm, self.original_example_inputs)
_dynamo/output_graph.py:        # used to track nodes that are added between calls of copy_graphstate
_dynamo/output_graph.py:    def copy_graphstate(self) -> OutputGraphState:
_dynamo/output_graph.py:        guards_graph_state = self.tracing_context.guards_context.copy_graphstate()
_dynamo/output_graph.py:        """Restore a checkpoint created by self.copy_graphstate()"""
_dynamo/optimizations/backends.py:            binding.copy_outputs_to_cpu()
_dynamo/optimizations/backends.py:def cudagraphs_inner(model, inputs, copy_outputs=True):
_dynamo/optimizations/backends.py:            dst.copy_(src)
_dynamo/optimizations/backends.py:        if copy_outputs:
_dynamo/optimizations/torchxla_integration.py:            args[arg_index].copy_(res[res_index])
_dynamo/optimizations/distributed.py:from ..utils import deepcopy_to_fake_tensor, fake_mode_from_tensors
_dynamo/optimizations/distributed.py:                            curr_submod = deepcopy_to_fake_tensor(real_mod, fake_mode)
_dynamo/optimizations/training.py:                dst.copy_(src)
_dynamo/optimizations/training.py:                args[i].copy_(self.static_inputs[i])
_dynamo/optimizations/training.py:                args[i].copy_(self.static_inputs[i])
functional.py:            out[i].resize_as_(result[i]).copy_(result[i])
functional.py:            out[i].resize_as_(result[i]).copy_(result[i])
_functorch/eager_transforms.py:                    sr[idx * chunk_size: (idx + 1) * chunk_size].copy_(r)
_functorch/eager_transforms.py:            view_copy_1 = torch.ops.aten.view_copy(add_1, [2]);  add_1 = None
_functorch/eager_transforms.py:            return view_copy_1
_functorch/eager_transforms.py:        >>> # but there is an extra copy_ in the graph to correctly apply the mutation to the input
_functorch/eager_transforms.py:            view_copy_1 = torch.ops.aten.view_copy(add, [2]);  add = None
_functorch/eager_transforms.py:            copy_ = torch.ops.aten.copy_(a_1, view_copy_1);  a_1 = None
_functorch/eager_transforms.py:            return view_copy_1
Binary file _functorch/__pycache__/eager_transforms.cpython-310.pyc matches
_functorch/aot_autograd.py:#     x.copy_(x_updated)
_functorch/aot_autograd.py:# That way, during the x.copy_(x_updated) bit in the epilogue, gradients will flow from the updated input
_functorch/aot_autograd.py:#     x.copy_(x_updated)
_functorch/aot_autograd.py:#     a.copy_(a_updated)
_functorch/aot_autograd.py:                    original_inpt.copy_(updated_inpt)
_functorch/fx_minifier.py:    def deepcopy_fx_graph(fx_graph):
_functorch/fx_minifier.py:            new_state = strategy(deepcopy_fx_graph(old_state.graph), list(old_state.inps), granularity)
_functorch/fx_minifier.py:            new_graph = deepcopy_fx_graph(cur_graph)
fx/graph.py:    def __deepcopy__(self, memo=None) -> 'Graph':
fx/graph.py:        Explicitly implement __deepcopy__ to prevent excessive recursion depth
fx/graph_module.py:def _copy_attr(from_module: torch.nn.Module, to_module: torch.nn.Module, target: str):
fx/graph_module.py:                    _copy_attr(root, self, node.target)
fx/graph_module.py:    def __deepcopy__(self, memo):
fx/graph_module.py:    def __copy__(self):
fx/graph_module.py:        new_gm = self.__copy__()
fx/experimental/rewriter.py:        return ast.copy_location(expr_wrapper, node)
Binary file fx/__pycache__/graph_module.cpython-310.pyc matches
Binary file fx/__pycache__/_symbolic_trace.cpython-310.pyc matches
Binary file fx/__pycache__/graph.cpython-310.pyc matches
fx/passes/reinplace.py:        # copy_() doesn't read from its first argument; it writes to it, overwriting previous data.
fx/passes/reinplace.py:        if node.target is torch.ops.aten.copy_.default:
fx/passes/reinplace.py:          there is a node that looks like "a.copy_(...)",
fx/passes/reinplace.py:          which will later be overwritten by the copy_() call.
fx/passes/reinplace.py:          a_slice.copy_(b)
fx/passes/reinplace.py:            slice.copy_(mutated_slice)
fx/passes/reinplace.py:                # TODO: later, add the optimization for handling `copy_()` calls in the graph.
fx/passes/reinplace.py:            # and instead copy_() the slice directly into the larger tensor.
fx/passes/reinplace.py:                #   slice.copy_(mutated_slice)
fx/passes/reinplace.py:                    copy_node = gm.graph.create_node(
fx/passes/reinplace.py:                        'call_function', torch.ops.aten.copy_.default, (slice_node, mutated_slice_node,), {})
fx/passes/utils/matcher_utils.py:    def __copy__(self):
fx/passes/shape_prop.py:            from torch._dynamo.utils import deepcopy_to_fake_tensor
fx/passes/shape_prop.py:            self.fake_module = deepcopy_to_fake_tensor(self.module, fake_mode)
fx/_symbolic_trace.py:    def __deepcopy__(self, memo):
_guards.py:copy_graphstate() -> T, a somewhat legacy name, is expected to emit a snapshot of any type that
_guards.py:    def copy_graphstate(self) -> T:
_guards.py:prefer to extract them with copy_graphstate to produce a GuardsCheckpointState.
_guards.py:    def copy_graphstate(self):
halfintorch.txt:include/caffe2/mobile/contrib/ios/mpscnn/mpscnn_kernels.h:kernel void copy_metal_to_nchw(texture2d_array<half, access::read> in[[texture(0)]],
halfintorch.txt:include/caffe2/mobile/contrib/ios/mpscnn/mpscnn_kernels.h:kernel void copy_metal_to_nchw_nonarray(texture2d<half, access::read> in[[texture(0)]],
include/google/protobuf/message.h:class ZeroCopyInputStream;   // zero_copy_stream.h
include/google/protobuf/message.h:class ZeroCopyOutputStream;  // zero_copy_stream.h
include/google/protobuf/util/delimited_message_util.h:#include <google/protobuf/io/zero_copy_stream_impl.h>
include/google/protobuf/io/gzip_stream.h:#include <google/protobuf/io/zero_copy_stream.h>
include/google/protobuf/io/printer.h:class ZeroCopyOutputStream;  // zero_copy_stream.h
include/google/protobuf/io/zero_copy_stream.h:// implementations of these interfaces, see zero_copy_stream_impl.h.
include/google/protobuf/io/coded_stream.h:class ZeroCopyInputStream;   // zero_copy_stream.h
include/google/protobuf/io/coded_stream.h:class ZeroCopyOutputStream;  // zero_copy_stream.h
include/google/protobuf/io/zero_copy_stream_impl.h:// zero_copy_stream.h which are only included in the full (non-lite)
include/google/protobuf/io/zero_copy_stream_impl.h:// and C++ iostreams.  See also:  zero_copy_stream_impl_lite.h
include/google/protobuf/io/zero_copy_stream_impl.h:#include <google/protobuf/io/zero_copy_stream.h>
include/google/protobuf/io/zero_copy_stream_impl.h:#include <google/protobuf/io/zero_copy_stream_impl_lite.h>
include/google/protobuf/io/tokenizer.h:class ZeroCopyInputStream;  // zero_copy_stream.h
include/google/protobuf/io/zero_copy_stream_impl_lite.h:// zero_copy_stream.h which are included in the "lite" protobuf library.
include/google/protobuf/io/zero_copy_stream_impl_lite.h:#include <google/protobuf/io/zero_copy_stream.h>
include/google/protobuf/parse_context.h:#include <google/protobuf/io/zero_copy_stream.h>
include/google/protobuf/unknown_field_set.h:#include <google/protobuf/io/zero_copy_stream_impl_lite.h>
include/google/protobuf/compiler/python/python_generator.h:  void CopyPublicDependenciesAliases(const std::string& copy_from,
include/xnnpack.h:enum xnn_status xnn_create_copy_nc_x32(
include/xnnpack.h:  xnn_operator_t* copy_op_out);
include/xnnpack.h:enum xnn_status xnn_setup_copy_nc_x32(
include/xnnpack.h:  xnn_operator_t copy_op,
include/xnnpack.h:enum xnn_status xnn_create_copy_nc_x16(
include/xnnpack.h:  xnn_operator_t* copy_op_out);
include/xnnpack.h:enum xnn_status xnn_setup_copy_nc_x16(
include/xnnpack.h:  xnn_operator_t copy_op,
include/xnnpack.h:enum xnn_status xnn_create_copy_nc_x8(
include/xnnpack.h:  xnn_operator_t* copy_op_out);
include/xnnpack.h:enum xnn_status xnn_setup_copy_nc_x8(
include/xnnpack.h:  xnn_operator_t copy_op,
include/ATen/core/ivalue_inl.h:  c10::intrusive_ptr<Object> copy_to_weak_compilation_ref() const;
include/ATen/core/aten_interned_strings.h:_(aten, _copy_from) \
include/ATen/core/aten_interned_strings.h:_(aten, _copy_from_and_resize) \
include/ATen/core/aten_interned_strings.h:_(aten, _has_compatible_shallow_copy_type) \
include/ATen/core/aten_interned_strings.h:_(aten, copy_) \
include/ATen/core/aten_interned_strings.h:_(aten, copy_sparse_to_sparse) \
include/ATen/core/aten_interned_strings.h:_(aten, copy_sparse_to_sparse_) \
include/ATen/core/aten_interned_strings.h:_(aten, index_copy_) \
include/ATen/core/TensorBody.h:    return copy_(rhs);
include/ATen/core/TensorBody.h:    return copy_(rhs);
include/ATen/core/TensorBody.h:  at::Tensor & copy_(const at::Tensor & src, bool non_blocking=false) const;
include/ATen/core/TensorBody.h:  at::Tensor & index_copy_(int64_t dim, const at::Tensor & index, const at::Tensor & source) const;
include/ATen/core/TensorBody.h:  at::Tensor & index_copy_(at::Dimname dim, const at::Tensor & index, const at::Tensor & source) const;
include/ATen/core/TensorBody.h:  at::Tensor narrow_copy_symint(int64_t dim, c10::SymInt start, c10::SymInt length) const;
include/ATen/core/TensorBody.h:// aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)
include/ATen/core/TensorBody.h:inline at::Tensor & Tensor::copy_(const at::Tensor & src, bool non_blocking) const {
include/ATen/core/TensorBody.h:    return at::_ops::copy_::call(const_cast<Tensor&>(*this), src, non_blocking);
include/ATen/core/TensorBody.h:// aten::index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -> Tensor(a!)
include/ATen/core/TensorBody.h:inline at::Tensor & Tensor::index_copy_(int64_t dim, const at::Tensor & index, const at::Tensor & source) const {
include/ATen/core/TensorBody.h:    return at::_ops::index_copy_::call(const_cast<Tensor&>(*this), dim, index, source);
include/ATen/core/TensorBody.h:// aten::index_copy_.dimname(Tensor(a!) self, Dimname dim, Tensor index, Tensor source) -> Tensor(a!)
include/ATen/core/TensorBody.h:inline at::Tensor & Tensor::index_copy_(at::Dimname dim, const at::Tensor & index, const at::Tensor & source) const {
include/ATen/core/TensorBody.h:    return at::_ops::index_copy__dimname::call(const_cast<Tensor&>(*this), dim, index, source);
include/ATen/core/TensorBody.h:    return at::_ops::index_copy_dimname::call(const_cast<Tensor&>(*this), dim, index, source);
include/ATen/core/TensorBody.h:inline at::Tensor Tensor::narrow_copy_symint(int64_t dim, c10::SymInt start, c10::SymInt length) const {
include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:      copy_(output, stack, std::make_index_sequence<sizeof...(OutputTypes)>());
include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:    static void copy_(const std::tuple<OutputTypes...>& output, Stack* stack, std::index_sequence<indices...>) {
include/ATen/Functions.h:#include <ATen/ops/_copy_from.h>
include/ATen/Functions.h:#include <ATen/ops/_copy_from_and_resize.h>
include/ATen/Functions.h:#include <ATen/ops/_has_compatible_shallow_copy_type.h>
include/ATen/Functions.h:#include <ATen/ops/copy_sparse_to_sparse.h>
include/ATen/functorch/TensorWrapper.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/functorch/TensorWrapper.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/functorch/TensorWrapper.h:  void shallow_copy_from(const c10::intrusive_ptr<TensorImpl>& impl) override;
include/ATen/cuda/CachingHostAllocator.h:// allocation. This is currently invoked by at::native::copy_kernel_cuda.
include/ATen/cuda/CUDAApplyUtils.cuh:    at::native::copy_ignoring_overlaps(oldA, a);
include/ATen/cuda/CUDAApplyUtils.cuh:    at::native::copy_ignoring_overlaps(oldB, b);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor copy_generated_plumbing(const at::Tensor & self, const at::Tensor & src, bool non_blocking) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor & copy__generated_plumbing(at::Tensor & self, const at::Tensor & src, bool non_blocking) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::copy_::call(self, src, non_blocking);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _copy_from_generated_plumbing(const at::Tensor & self, const at::Tensor & dst, bool non_blocking) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::_copy_from::call(self, dst, non_blocking);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _copy_from_and_resize_generated_plumbing(const at::Tensor & self, const at::Tensor & dst) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::_copy_from_and_resize::call(self, dst);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor & index_copy__generated_plumbing(at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::index_copy_::call(self, dim, index, source);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor index_copy_generated_plumbing(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor & index_copy__dimname_generated_plumbing(at::Tensor & self, at::Dimname dim, const at::Tensor & index, const at::Tensor & source) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::index_copy__dimname::call(self, dim, index, source);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor index_copy_dimname_generated_plumbing(const at::Tensor & self, at::Dimname dim, const at::Tensor & index, const at::Tensor & source) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::index_copy_dimname::call(self, dim, index, source);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor narrow_copy_generated_plumbing(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _reshape_copy_generated_plumbing(const at::Tensor & self, c10::SymIntArrayRef size) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _nested_view_from_buffer_copy_generated_plumbing(const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor & copy_sparse_to_sparse__generated_plumbing(at::Tensor & self, const at::Tensor & src, bool non_blocking) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::copy_sparse_to_sparse_::call(self, src, non_blocking);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _to_copy_generated_plumbing(const at::Tensor & self, c10::optional<at::ScalarType> dtype, c10::optional<at::Layout> layout, c10::optional<at::Device> device, c10::optional<bool> pin_memory, bool non_blocking, c10::optional<at::MemoryFormat> memory_format) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor lift_fresh_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _test_autograd_multiple_dispatch_view_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _fw_primal_copy_generated_plumbing(const at::Tensor & self, int64_t level) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _make_dual_copy_generated_plumbing(const at::Tensor & primal, const at::Tensor & tangent, int64_t level) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor view_as_real_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor view_as_complex_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _conj_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _neg_view_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor as_strided_copy_generated_plumbing(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _sparse_broadcast_to_copy_generated_plumbing(const at::Tensor & self, at::IntArrayRef size) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor diagonal_copy_generated_plumbing(const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor expand_copy_generated_plumbing(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor permute_copy_generated_plumbing(const at::Tensor & self, at::IntArrayRef dims) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _reshape_alias_copy_generated_plumbing(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor select_copy_int_generated_plumbing(const at::Tensor & self, int64_t dim, c10::SymInt index) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::select_copy_int::call(self, dim, index);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor detach_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor slice_copy_Tensor_generated_plumbing(const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::slice_copy_Tensor::call(self, dim, start, end, step);
include/ATen/VmapGeneratedPlumbing.h:::std::vector<at::Tensor> split_copy_Tensor_generated_plumbing(const at::Tensor & self, c10::SymInt split_size, int64_t dim) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::split_copy_Tensor::call(self, split_size, dim);
include/ATen/VmapGeneratedPlumbing.h:::std::vector<at::Tensor> split_with_sizes_copy_generated_plumbing(const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor squeeze_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor squeeze_copy_dim_generated_plumbing(const at::Tensor & self, int64_t dim) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::squeeze_copy_dim::call(self, dim);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor squeeze_copy_dims_generated_plumbing(const at::Tensor & self, at::IntArrayRef dim) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::squeeze_copy_dims::call(self, dim);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor t_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor transpose_copy_int_generated_plumbing(const at::Tensor & self, int64_t dim0, int64_t dim1) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::transpose_copy_int::call(self, dim0, dim1);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor unsqueeze_copy_generated_plumbing(const at::Tensor & self, int64_t dim) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _indices_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor _values_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor indices_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor values_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor crow_indices_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor col_indices_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor ccol_indices_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor row_indices_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:::std::vector<at::Tensor> unbind_copy_int_generated_plumbing(const at::Tensor & self, int64_t dim) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::unbind_copy_int::call(self, dim);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor view_copy_generated_plumbing(const at::Tensor & self, c10::SymIntArrayRef size) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor view_copy_dtype_generated_plumbing(const at::Tensor & self, at::ScalarType dtype) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::view_copy_dtype::call(self, dtype);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor unfold_copy_generated_plumbing(const at::Tensor & self, int64_t dimension, int64_t size, int64_t step) {
include/ATen/VmapGeneratedPlumbing.h:at::Tensor alias_copy_generated_plumbing(const at::Tensor & self) {
include/ATen/VmapGeneratedPlumbing.h:void split_copy_Tensor_out_generated_plumbing(const at::Tensor & self, c10::SymInt split_size, int64_t dim, at::TensorList out) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::split_copy_Tensor_out::call(self, split_size, dim, out);
include/ATen/VmapGeneratedPlumbing.h:void split_with_sizes_copy_out_generated_plumbing(const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim, at::TensorList out) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::split_with_sizes_copy_out::call(self, split_sizes, dim, out);
include/ATen/VmapGeneratedPlumbing.h:void unbind_copy_int_out_generated_plumbing(const at::Tensor & self, int64_t dim, at::TensorList out) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::unbind_copy_int_out::call(self, dim, out);
include/ATen/VmapGeneratedPlumbing.h:at::Tensor copy_sparse_to_sparse_generated_plumbing(const at::Tensor & self, const at::Tensor & src, bool non_blocking) {
include/ATen/VmapGeneratedPlumbing.h:    return at::_ops::copy_sparse_to_sparse::call(self, src, non_blocking);
include/ATen/NestedTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/NestedTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/NestedTensorImpl.h:  void shallow_copy_from(const c10::intrusive_ptr<TensorImpl>& impl) override {
include/ATen/NestedTensorImpl.h:    copy_tensor_metadata(
include/ATen/NestedTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach_core(
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_conj_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_copy_from_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_copy_from_and_resize_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_fw_primal_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_indices_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_make_dual_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_neg_view_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_nested_view_from_buffer_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_reshape_alias_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_reshape_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_sparse_broadcast_to_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_to_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/_values_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/alias_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/as_strided_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/ccol_indices_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/col_indices_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/copy_sparse_to_sparse_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/crow_indices_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/detach_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/diagonal_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/expand_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/indices_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/lift_fresh_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/permute_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/row_indices_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/select_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/slice_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/split_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/split_with_sizes_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/squeeze_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/t_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/transpose_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/unbind_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/unfold_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/unsqueeze_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/values_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/view_as_complex_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/view_as_real_copy_compositeexplicitautograd_dispatch.h>
include/ATen/CompositeExplicitAutogradFunctions_inl.h:#include <ATen/ops/view_copy_compositeexplicitautograd_dispatch.h>
include/ATen/SparseCsrTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/SparseCsrTensorImpl.h:    copy_tensor_metadata(
include/ATen/SparseCsrTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/SparseCsrTensorImpl.h:    copy_tensor_metadata(
include/ATen/SparseCsrTensorImpl.h:  static void copy_tensor_metadata(
include/ATen/SparseCsrTensorImpl.h:    TensorImpl::copy_tensor_metadata(
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_conj_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_copy_from_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_copy_from_and_resize_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_fw_primal_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_has_compatible_shallow_copy_type_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_indices_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_make_dual_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_neg_view_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_nested_view_from_buffer_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_reshape_alias_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_reshape_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_sparse_broadcast_to_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_to_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/_values_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/alias_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/as_strided_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/ccol_indices_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/col_indices_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/copy_sparse_to_sparse_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/crow_indices_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/detach_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/diagonal_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/expand_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/index_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/indices_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/lift_fresh_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/narrow_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/permute_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/row_indices_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/select_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/slice_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/split_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/split_with_sizes_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/squeeze_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/t_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/transpose_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/unbind_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/unfold_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/unsqueeze_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/values_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/view_as_complex_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/view_as_real_copy_meta.h>
include/ATen/NativeMetaFunctions.h:#include <ATen/ops/view_copy_meta.h>
include/ATen/CompositeImplicitAutogradFunctions_inl.h:#include <ATen/ops/_has_compatible_shallow_copy_type_compositeimplicitautograd_dispatch.h>
include/ATen/CompositeImplicitAutogradFunctions_inl.h:#include <ATen/ops/index_copy_compositeimplicitautograd_dispatch.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_conj_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_copy_from_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_copy_from_and_resize_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_fw_primal_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_has_compatible_shallow_copy_type_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_indices_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_make_dual_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_neg_view_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_nested_view_from_buffer_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_reshape_alias_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_reshape_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_sparse_broadcast_to_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_to_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/_values_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/alias_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/as_strided_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/ccol_indices_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/col_indices_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/copy_sparse_to_sparse_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/crow_indices_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/detach_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/diagonal_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/expand_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/index_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/indices_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/lift_fresh_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/narrow_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/permute_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/row_indices_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/select_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/slice_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/split_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/split_with_sizes_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/squeeze_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/t_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/transpose_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/unbind_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/unfold_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/unsqueeze_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/values_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/view_as_complex_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/view_as_real_copy_native.h>
include/ATen/NativeFunctions.h:#include <ATen/ops/view_copy_native.h>
include/ATen/FunctionalTensorWrapper.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/FunctionalTensorWrapper.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/FunctionalTensorWrapper.h:  // This is used to re-implement shallow_copy_and_detach for
include/ATen/FunctionalTensorWrapper.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach_core(
include/ATen/OpaqueTensorImpl.h:// of `shallow_copy_and_detach`. We would need to define an interface to
include/ATen/OpaqueTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/OpaqueTensorImpl.h:    copy_tensor_metadata(
include/ATen/OpaqueTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/OpaqueTensorImpl.h:    copy_tensor_metadata(
include/ATen/OpaqueTensorImpl.h:  void shallow_copy_from(const c10::intrusive_ptr<TensorImpl>& impl) override {
include/ATen/OpaqueTensorImpl.h:    AT_ASSERT(has_compatible_shallow_copy_type(impl->key_set()));
include/ATen/OpaqueTensorImpl.h:    copy_tensor_metadata(
include/ATen/OpaqueTensorImpl.h:  static void copy_tensor_metadata(
include/ATen/OpaqueTensorImpl.h:    TensorImpl::copy_tensor_metadata(
include/ATen/OpaqueTensorImpl.h:  static void copy_tensor_metadata(
include/ATen/OpaqueTensorImpl.h:    TensorImpl::copy_tensor_metadata(
include/ATen/Operators.h:#include <ATen/ops/_conj_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_copy_from_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_copy_from_and_resize_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_fw_primal_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_has_compatible_shallow_copy_type_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_indices_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_make_dual_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_neg_view_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_nested_view_from_buffer_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_reshape_alias_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_reshape_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_sparse_broadcast_to_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_to_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/_values_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/alias_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/as_strided_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/ccol_indices_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/col_indices_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
include/ATen/Operators.h:#include <ATen/ops/crow_indices_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/detach_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/diagonal_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/expand_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/index_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/indices_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/lift_fresh_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/narrow_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/permute_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/row_indices_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/select_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/slice_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/split_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/split_with_sizes_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/squeeze_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/t_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/transpose_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/unbind_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/unfold_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/unsqueeze_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/values_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/view_as_complex_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/view_as_real_copy_ops.h>
include/ATen/Operators.h:#include <ATen/ops/view_copy_ops.h>
include/ATen/native/LinearAlgebraUtils.h:  auto copy_sizes = desired_batch_sizes.has_value()
include/ATen/native/LinearAlgebraUtils.h:  copy_sizes.insert(copy_sizes.end(), {nrows, src.size(-1)});
include/ATen/native/LinearAlgebraUtils.h:  const auto copy_strides = batched_matrix_contiguous_strides(copy_sizes, /*f-contig*/true);
include/ATen/native/LinearAlgebraUtils.h:  auto copy = at::empty_strided(copy_sizes, copy_strides, src.options());
include/ATen/native/LinearAlgebraUtils.h:  copy.narrow(-2, 0, src.size(-2)).copy_(src);
include/ATen/native/LinearAlgebraUtils.h:  std::function<void(int64_t)> check_if_copy_needed_for_a
include/ATen/native/LinearAlgebraUtils.h:      .copy_(a);
include/ATen/native/LinearAlgebraUtils.h:    check_if_copy_needed_for_a = [&](int64_t a_curr_linear_batch_idx) {
include/ATen/native/LinearAlgebraUtils.h:          .copy_(a_buffer_3d.select(0, a_curr_linear_batch_idx));
include/ATen/native/LinearAlgebraUtils.h:      check_if_copy_needed_for_a(a_curr_linear_batch_idx);
include/ATen/native/LinearAlgebraUtils.h:  strided_to.copy_(original_tensor);
include/ATen/native/cuda/Copy.h:void direct_copy_kernel_cuda(TensorIteratorBase &iter);
include/ATen/native/cpu/Loops.h:    std::copy_n(base, ntensors, data.data());
include/ATen/native/cpu/CopyKernel.h:void direct_copy_kernel(TensorIteratorBase &iter);
include/ATen/native/cpu/CopyKernel.h:void copy_kernel(TensorIterator& iter, bool /*non_blocking*/);
include/ATen/native/CPUBlas.h:using copy_fn = void(*)(at::ScalarType type, int64_t n, const void *x, int64_t incx, void *y, int64_t incy);
include/ATen/native/CPUBlas.h:DECLARE_DISPATCH(copy_fn, copy_stub);
include/ATen/native/CPUBlas.h:  copy_stub(
include/ATen/native/Copy.h:using copy_fn = void (*)(TensorIterator&, bool non_blocking);
include/ATen/native/Copy.h:DECLARE_DISPATCH(copy_fn, copy_stub);
include/ATen/native/Copy.h:TORCH_API void copy_ignoring_overlaps(const TensorBase &dst, const TensorBase &src);
include/ATen/native/Unfold2d.h:DECLARE_DISPATCH(unfold2d_fn, unfolded2d_copy_stub);
include/ATen/native/IndexKernel.h:using index_copy_fn = void(*)(TensorIterator & iter, int64_t dim, int64_t self_dim_size, int64_t self_dim_stride);
include/ATen/native/IndexKernel.h:DECLARE_DISPATCH(index_copy_fn, index_copy_stub);
include/ATen/native/im2col.h:              std::copy_n(slice_im, channels, slice_col);
include/ATen/native/MathBitsFallback.h:// NOTE: To use this fallback, `clone` and `copy_` should fully understand and be able to correctly handle the semantic of your math bit.
include/ATen/native/MathBitsFallback.h:        3. out= operation.  Desugar add(x, 2, out=y) into y.copy_(add(x, 2))
include/ATen/native/MathBitsFallback.h:      mutable_input.copy_(returned_output);
include/ATen/native/quantized/cpu/XnnpackUtils.h:void q8_copy_int8_weight_and_add_offset(const at::Tensor& in, at::Tensor& out);
include/ATen/native/quantized/Copy.h:Tensor& quantized_copy_from_float_(Tensor& self, const Tensor& src);
include/ATen/CPUFunctions_inl.h:#include <ATen/ops/index_copy_cpu_dispatch.h>
include/ATen/CPUFunctions_inl.h:#include <ATen/ops/narrow_copy_cpu_dispatch.h>
include/ATen/Utils.h:  std::copy_n(list.begin(), N, res.begin());
include/ATen/MethodOperators.h:#include <ATen/ops/copy_ops.h>
include/ATen/MethodOperators.h:#include <ATen/ops/index_copy_ops.h>
include/ATen/MethodOperators.h:#include <ATen/ops/narrow_copy_ops.h>
include/ATen/ops/_sparse_broadcast_to_copy.h:#include <ATen/ops/_sparse_broadcast_to_copy_ops.h>
include/ATen/ops/_sparse_broadcast_to_copy.h:inline at::Tensor & _sparse_broadcast_to_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size) {
include/ATen/ops/_sparse_broadcast_to_copy.h:    return at::_ops::_sparse_broadcast_to_copy_out::call(self, size, out);
include/ATen/ops/_sparse_broadcast_to_copy.h:inline at::Tensor & _sparse_broadcast_to_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::Tensor & out) {
include/ATen/ops/_sparse_broadcast_to_copy.h:    return at::_ops::_sparse_broadcast_to_copy_out::call(self, size, out);
include/ATen/ops/expand_copy_native.h:TORCH_API at::Tensor & expand_copy_out_symint(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out);
include/ATen/ops/expand_copy_native.h:TORCH_API at::Tensor expand_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit=false);
include/ATen/ops/_values_copy.h:#include <ATen/ops/_values_copy_ops.h>
include/ATen/ops/_values_copy.h:inline at::Tensor & _values_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/_values_copy.h:    return at::_ops::_values_copy_out::call(self, out);
include/ATen/ops/_values_copy.h:inline at::Tensor & _values_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/_values_copy.h:    return at::_ops::_values_copy_out::call(self, out);
include/ATen/ops/copy_sparse_to_sparse_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor copy_sparse_to_sparse(const at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/copy_sparse_to_sparse_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & copy_sparse_to_sparse_out(at::Tensor & out, const at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/copy_sparse_to_sparse_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & copy_sparse_to_sparse_outf(const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out);
include/ATen/ops/permute_copy_ops.h:struct TORCH_API permute_copy_out {
include/ATen/ops/view_as_complex_copy_native.h:TORCH_API at::Tensor & view_as_complex_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_reshape_alias_copy_ops.h:struct TORCH_API _reshape_alias_copy_out {
include/ATen/ops/_has_compatible_shallow_copy_type_ops.h:struct TORCH_API _has_compatible_shallow_copy_type {
include/ATen/ops/_has_compatible_shallow_copy_type_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::_has_compatible_shallow_copy_type")
include/ATen/ops/_has_compatible_shallow_copy_type_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool")
include/ATen/ops/expand_copy_compositeexplicitautogradnonfunctional_dispatch.h:TORCH_API at::Tensor expand_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit=false);
include/ATen/ops/_test_autograd_multiple_dispatch_view_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _test_autograd_multiple_dispatch_view_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/_test_autograd_multiple_dispatch_view_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _test_autograd_multiple_dispatch_view_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/view_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & view_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size);
include/ATen/ops/view_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & view_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::Tensor & out);
include/ATen/ops/view_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & view_copy_symint_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size);
include/ATen/ops/view_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & view_copy_symint_outf(const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out);
include/ATen/ops/view_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & view_copy_out(at::Tensor & out, const at::Tensor & self, at::ScalarType dtype);
include/ATen/ops/view_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & view_copy_outf(const at::Tensor & self, at::ScalarType dtype, at::Tensor & out);
include/ATen/ops/index_copy.h:#include <ATen/ops/index_copy_ops.h>
include/ATen/ops/index_copy.h:inline at::Tensor & index_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
include/ATen/ops/index_copy.h:    return at::_ops::index_copy_out::call(self, dim, index, source, out);
include/ATen/ops/index_copy.h:inline at::Tensor & index_copy_outf(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out) {
include/ATen/ops/index_copy.h:    return at::_ops::index_copy_out::call(self, dim, index, source, out);
include/ATen/ops/index_copy.h:    return at::_ops::index_copy_dimname::call(self, dim, index, source);
include/ATen/ops/expand_copy.h:#include <ATen/ops/expand_copy_ops.h>
include/ATen/ops/expand_copy.h:inline at::Tensor expand_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit=false) {
include/ATen/ops/expand_copy.h:inline at::Tensor & expand_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, bool implicit=false) {
include/ATen/ops/expand_copy.h:    return at::_ops::expand_copy_out::call(self, c10::fromIntArrayRefSlow(size), implicit, out);
include/ATen/ops/expand_copy.h:  at::Tensor & expand_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, bool implicit=false) {
include/ATen/ops/expand_copy.h:    return at::_ops::expand_copy_out::call(self, c10::fromIntArrayRefSlow(size), implicit, out);
include/ATen/ops/expand_copy.h:inline at::Tensor & expand_copy_outf(const at::Tensor & self, at::IntArrayRef size, bool implicit, at::Tensor & out) {
include/ATen/ops/expand_copy.h:    return at::_ops::expand_copy_out::call(self, c10::fromIntArrayRefSlow(size), implicit, out);
include/ATen/ops/expand_copy.h:  at::Tensor & expand_copy_outf(const at::Tensor & self, at::IntArrayRef size, bool implicit, at::Tensor & out) {
include/ATen/ops/expand_copy.h:    return at::_ops::expand_copy_out::call(self, c10::fromIntArrayRefSlow(size), implicit, out);
include/ATen/ops/expand_copy.h:inline at::Tensor & expand_copy_symint_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit=false) {
include/ATen/ops/expand_copy.h:    return at::_ops::expand_copy_out::call(self, size, implicit, out);
include/ATen/ops/expand_copy.h:  at::Tensor & expand_copy_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit=false) {
include/ATen/ops/expand_copy.h:    return at::_ops::expand_copy_out::call(self, size, implicit, out);
include/ATen/ops/expand_copy.h:inline at::Tensor & expand_copy_symint_outf(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out) {
include/ATen/ops/expand_copy.h:    return at::_ops::expand_copy_out::call(self, size, implicit, out);
include/ATen/ops/expand_copy.h:  at::Tensor & expand_copy_outf(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out) {
include/ATen/ops/expand_copy.h:    return at::_ops::expand_copy_out::call(self, size, implicit, out);
include/ATen/ops/copy_sparse_to_sparse_meta_dispatch.h:TORCH_API at::Tensor & copy_sparse_to_sparse_(at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/lift_fresh_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & lift_fresh_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/lift_fresh_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & lift_fresh_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/t_copy_native.h:TORCH_API at::Tensor & t_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/crow_indices_copy_ops.h:struct TORCH_API crow_indices_copy_out {
include/ATen/ops/_values_copy_native.h:TORCH_API at::Tensor & _values_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/diagonal_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & diagonal_copy_out(at::Tensor & out, const at::Tensor & self, int64_t offset=0, int64_t dim1=0, int64_t dim2=1);
include/ATen/ops/diagonal_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & diagonal_copy_outf(const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out);
include/ATen/ops/unsqueeze_copy.h:#include <ATen/ops/unsqueeze_copy_ops.h>
include/ATen/ops/unsqueeze_copy.h:inline at::Tensor & unsqueeze_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim) {
include/ATen/ops/unsqueeze_copy.h:    return at::_ops::unsqueeze_copy_out::call(self, dim, out);
include/ATen/ops/unsqueeze_copy.h:inline at::Tensor & unsqueeze_copy_outf(const at::Tensor & self, int64_t dim, at::Tensor & out) {
include/ATen/ops/unsqueeze_copy.h:    return at::_ops::unsqueeze_copy_out::call(self, dim, out);
include/ATen/ops/index_copy_meta_dispatch.h:TORCH_API at::Tensor & index_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source);
include/ATen/ops/index_copy_meta_dispatch.h:TORCH_API at::Tensor & index_copy_outf(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out);
include/ATen/ops/index_copy_meta_dispatch.h:TORCH_API at::Tensor & index_copy_(at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source);
include/ATen/ops/split_with_sizes_copy_ops.h:struct TORCH_API split_with_sizes_copy_out {
include/ATen/ops/_indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _indices_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/_indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _indices_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/narrow_copy_compositeexplicitautogradnonfunctional_dispatch.h:TORCH_API at::Tensor narrow_copy_symint(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length);
include/ATen/ops/_reshape_alias_copy_native.h:TORCH_API at::Tensor & _reshape_alias_copy_out(const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, at::Tensor & out);
include/ATen/ops/_reshape_alias_copy_native.h:TORCH_API at::Tensor _reshape_alias_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride);
include/ATen/ops/_to_copy.h:#include <ATen/ops/_to_copy_ops.h>
include/ATen/ops/_to_copy.h:inline at::Tensor & _to_copy_out(at::Tensor & out, const at::Tensor & self, bool non_blocking=false, c10::optional<at::MemoryFormat> memory_format=c10::nullopt) {
include/ATen/ops/_to_copy.h:    return at::_ops::_to_copy_out::call(self, non_blocking, memory_format, out);
include/ATen/ops/_to_copy.h:inline at::Tensor & _to_copy_outf(const at::Tensor & self, bool non_blocking, c10::optional<at::MemoryFormat> memory_format, at::Tensor & out) {
include/ATen/ops/_to_copy.h:    return at::_ops::_to_copy_out::call(self, non_blocking, memory_format, out);
include/ATen/ops/index_copy_cpu_dispatch.h:TORCH_API at::Tensor & index_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source);
include/ATen/ops/index_copy_cpu_dispatch.h:TORCH_API at::Tensor & index_copy_outf(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out);
include/ATen/ops/index_copy_cpu_dispatch.h:TORCH_API at::Tensor & index_copy_(at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source);
include/ATen/ops/split_copy_native.h:TORCH_API void split_copy_Tensor_out(const at::Tensor & self, int64_t split_size, int64_t dim, at::TensorList out);
include/ATen/ops/split_copy_native.h:TORCH_API ::std::vector<at::Tensor> split_copy_Tensor_symint(const at::Tensor & self, c10::SymInt split_size, int64_t dim=0);
include/ATen/ops/detach_copy.h:#include <ATen/ops/detach_copy_ops.h>
include/ATen/ops/detach_copy.h:inline at::Tensor & detach_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/detach_copy.h:    return at::_ops::detach_copy_out::call(self, out);
include/ATen/ops/detach_copy.h:inline at::Tensor & detach_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/detach_copy.h:    return at::_ops::detach_copy_out::call(self, out);
include/ATen/ops/select_copy_native.h:TORCH_API at::Tensor & select_copy_symint_out(const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out);
include/ATen/ops/select_copy_native.h:TORCH_API at::Tensor select_copy_sparse_csr(const at::Tensor & self, int64_t dim, int64_t index);
include/ATen/ops/select_copy_native.h:TORCH_API at::Tensor select_copy_symint(const at::Tensor & self, int64_t dim, c10::SymInt index);
include/ATen/ops/squeeze_copy_ops.h:struct TORCH_API squeeze_copy_dim {
include/ATen/ops/squeeze_copy_ops.h:struct TORCH_API squeeze_copy_dims {
include/ATen/ops/squeeze_copy_ops.h:struct TORCH_API squeeze_copy_out {
include/ATen/ops/squeeze_copy_ops.h:struct TORCH_API squeeze_copy_dim_out {
include/ATen/ops/squeeze_copy_ops.h:struct TORCH_API squeeze_copy_dims_out {
include/ATen/ops/values_copy_ops.h:struct TORCH_API values_copy_out {
include/ATen/ops/indices_copy_ops.h:struct TORCH_API indices_copy_out {
include/ATen/ops/split_copy_compositeexplicitautogradnonfunctional_dispatch.h:TORCH_API ::std::vector<at::Tensor> split_copy_symint(const at::Tensor & self, c10::SymInt split_size, int64_t dim=0);
include/ATen/ops/squeeze_copy_native.h:TORCH_API at::Tensor & squeeze_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/squeeze_copy_native.h:TORCH_API at::Tensor & squeeze_copy_dim_out(const at::Tensor & self, int64_t dim, at::Tensor & out);
include/ATen/ops/squeeze_copy_native.h:TORCH_API at::Tensor squeeze_copy_dim(const at::Tensor & self, int64_t dim);
include/ATen/ops/squeeze_copy_native.h:TORCH_API at::Tensor & squeeze_copy_dims_out(const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out);
include/ATen/ops/squeeze_copy_native.h:TORCH_API at::Tensor squeeze_copy_dims(const at::Tensor & self, at::IntArrayRef dim);
include/ATen/ops/transpose_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & transpose_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim0, int64_t dim1);
include/ATen/ops/transpose_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & transpose_copy_outf(const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out);
include/ATen/ops/slice_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & slice_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim=0, c10::optional<int64_t> start=c10::nullopt, c10::optional<int64_t> end=c10::nullopt, int64_t step=1);
include/ATen/ops/slice_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & slice_copy_outf(const at::Tensor & self, int64_t dim, c10::optional<int64_t> start, c10::optional<int64_t> end, int64_t step, at::Tensor & out);
include/ATen/ops/slice_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & slice_copy_symint_out(at::Tensor & out, const at::Tensor & self, int64_t dim=0, c10::optional<c10::SymInt> start=c10::nullopt, c10::optional<c10::SymInt> end=c10::nullopt, c10::SymInt step=1);
include/ATen/ops/slice_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & slice_copy_symint_outf(const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out);
include/ATen/ops/index_copy_compositeimplicitautograd_dispatch.h:TORCH_API at::Tensor & index_copy_(at::Tensor & self, at::Dimname dim, const at::Tensor & index, const at::Tensor & source);
include/ATen/ops/_fw_primal_copy.h:#include <ATen/ops/_fw_primal_copy_ops.h>
include/ATen/ops/_fw_primal_copy.h:inline at::Tensor & _fw_primal_copy_out(at::Tensor & out, const at::Tensor & self, int64_t level) {
include/ATen/ops/_fw_primal_copy.h:    return at::_ops::_fw_primal_copy_out::call(self, level, out);
include/ATen/ops/_fw_primal_copy.h:inline at::Tensor & _fw_primal_copy_outf(const at::Tensor & self, int64_t level, at::Tensor & out) {
include/ATen/ops/_fw_primal_copy.h:    return at::_ops::_fw_primal_copy_out::call(self, level, out);
include/ATen/ops/diagonal_copy.h:#include <ATen/ops/diagonal_copy_ops.h>
include/ATen/ops/diagonal_copy.h:inline at::Tensor & diagonal_copy_out(at::Tensor & out, const at::Tensor & self, int64_t offset=0, int64_t dim1=0, int64_t dim2=1) {
include/ATen/ops/diagonal_copy.h:    return at::_ops::diagonal_copy_out::call(self, offset, dim1, dim2, out);
include/ATen/ops/diagonal_copy.h:inline at::Tensor & diagonal_copy_outf(const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out) {
include/ATen/ops/diagonal_copy.h:    return at::_ops::diagonal_copy_out::call(self, offset, dim1, dim2, out);
include/ATen/ops/expand_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & expand_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, bool implicit=false);
include/ATen/ops/expand_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & expand_copy_outf(const at::Tensor & self, at::IntArrayRef size, bool implicit, at::Tensor & out);
include/ATen/ops/expand_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & expand_copy_symint_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit=false);
include/ATen/ops/expand_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & expand_copy_symint_outf(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out);
include/ATen/ops/_copy_from_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _copy_from_out(at::Tensor & out, const at::Tensor & self, const at::Tensor & dst, bool non_blocking=false);
include/ATen/ops/_copy_from_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _copy_from_outf(const at::Tensor & self, const at::Tensor & dst, bool non_blocking, at::Tensor & out);
include/ATen/ops/select_copy_ops.h:struct TORCH_API select_copy_int {
include/ATen/ops/select_copy_ops.h:struct TORCH_API select_copy_int_out {
include/ATen/ops/permute_copy_native.h:TORCH_API at::Tensor & permute_copy_out(const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out);
include/ATen/ops/unsqueeze_copy_ops.h:struct TORCH_API unsqueeze_copy_out {
include/ATen/ops/copy_sparse_to_sparse_ops.h:struct TORCH_API copy_sparse_to_sparse_ {
include/ATen/ops/copy_sparse_to_sparse_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::copy_sparse_to_sparse_")
include/ATen/ops/copy_sparse_to_sparse_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "copy_sparse_to_sparse_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)")
include/ATen/ops/copy_sparse_to_sparse_ops.h:struct TORCH_API copy_sparse_to_sparse_out {
include/ATen/ops/copy_sparse_to_sparse_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::copy_sparse_to_sparse")
include/ATen/ops/copy_sparse_to_sparse_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "copy_sparse_to_sparse.out(Tensor self, Tensor src, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)")
include/ATen/ops/copy_sparse_to_sparse_ops.h:struct TORCH_API copy_sparse_to_sparse {
include/ATen/ops/copy_sparse_to_sparse_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::copy_sparse_to_sparse")
include/ATen/ops/copy_sparse_to_sparse_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "copy_sparse_to_sparse(Tensor self, Tensor src, bool non_blocking=False) -> Tensor")
include/ATen/ops/row_indices_copy.h:#include <ATen/ops/row_indices_copy_ops.h>
include/ATen/ops/row_indices_copy.h:inline at::Tensor & row_indices_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/row_indices_copy.h:    return at::_ops::row_indices_copy_out::call(self, out);
include/ATen/ops/row_indices_copy.h:inline at::Tensor & row_indices_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/row_indices_copy.h:    return at::_ops::row_indices_copy_out::call(self, out);
include/ATen/ops/alias_copy_ops.h:struct TORCH_API alias_copy_out {
include/ATen/ops/alias_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & alias_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/alias_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & alias_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/index_copy_cuda_dispatch.h:TORCH_API at::Tensor & index_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source);
include/ATen/ops/index_copy_cuda_dispatch.h:TORCH_API at::Tensor & index_copy_outf(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out);
include/ATen/ops/index_copy_cuda_dispatch.h:TORCH_API at::Tensor & index_copy_(at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source);
include/ATen/ops/unbind_copy_ops.h:struct TORCH_API unbind_copy_int {
include/ATen/ops/unbind_copy_ops.h:struct TORCH_API unbind_copy_int_out {
include/ATen/ops/view_as_real_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & view_as_real_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/view_as_real_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & view_as_real_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/copy_sparse_to_sparse_native.h:TORCH_API at::Tensor copy_sparse_to_sparse(const at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/copy_sparse_to_sparse_native.h:TORCH_API at::Tensor & copy_sparse_to_sparse_out(const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out);
include/ATen/ops/copy_sparse_to_sparse_native.h:TORCH_API at::Tensor & copy_sparse_(at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/_has_compatible_shallow_copy_type_compositeimplicitautograd_dispatch.h:TORCH_API bool _has_compatible_shallow_copy_type(const at::Tensor & self, const at::Tensor & from);
include/ATen/ops/alias_copy.h:#include <ATen/ops/alias_copy_ops.h>
include/ATen/ops/alias_copy.h:inline at::Tensor & alias_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/alias_copy.h:    return at::_ops::alias_copy_out::call(self, out);
include/ATen/ops/alias_copy.h:inline at::Tensor & alias_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/alias_copy.h:    return at::_ops::alias_copy_out::call(self, out);
include/ATen/ops/ccol_indices_copy_ops.h:struct TORCH_API ccol_indices_copy_out {
include/ATen/ops/view_as_real_copy_ops.h:struct TORCH_API view_as_real_copy_out {
include/ATen/ops/alias_copy_native.h:TORCH_API at::Tensor & alias_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_sparse_broadcast_to_copy_native.h:TORCH_API at::Tensor & _sparse_broadcast_to_copy_out(const at::Tensor & self, at::IntArrayRef size, at::Tensor & out);
include/ATen/ops/squeeze_copy.h:#include <ATen/ops/squeeze_copy_ops.h>
include/ATen/ops/squeeze_copy.h:    return at::_ops::squeeze_copy_dim::call(self, dim);
include/ATen/ops/squeeze_copy.h:    return at::_ops::squeeze_copy_dims::call(self, dim);
include/ATen/ops/squeeze_copy.h:inline at::Tensor & squeeze_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/squeeze_copy.h:    return at::_ops::squeeze_copy_out::call(self, out);
include/ATen/ops/squeeze_copy.h:inline at::Tensor & squeeze_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/squeeze_copy.h:    return at::_ops::squeeze_copy_out::call(self, out);
include/ATen/ops/squeeze_copy.h:inline at::Tensor & squeeze_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim) {
include/ATen/ops/squeeze_copy.h:    return at::_ops::squeeze_copy_dim_out::call(self, dim, out);
include/ATen/ops/squeeze_copy.h:inline at::Tensor & squeeze_copy_outf(const at::Tensor & self, int64_t dim, at::Tensor & out) {
include/ATen/ops/squeeze_copy.h:    return at::_ops::squeeze_copy_dim_out::call(self, dim, out);
include/ATen/ops/squeeze_copy.h:inline at::Tensor & squeeze_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef dim) {
include/ATen/ops/squeeze_copy.h:    return at::_ops::squeeze_copy_dims_out::call(self, dim, out);
include/ATen/ops/squeeze_copy.h:inline at::Tensor & squeeze_copy_outf(const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
include/ATen/ops/squeeze_copy.h:    return at::_ops::squeeze_copy_dims_out::call(self, dim, out);
include/ATen/ops/_has_compatible_shallow_copy_type_native.h:TORCH_API bool _has_compatible_shallow_copy_type(const at::Tensor & self, const at::Tensor & from);
include/ATen/ops/_copy_from_and_resize.h:#include <ATen/ops/_copy_from_and_resize_ops.h>
include/ATen/ops/_copy_from_and_resize.h:// aten::_copy_from_and_resize(Tensor self, Tensor dst) -> Tensor
include/ATen/ops/_copy_from_and_resize.h:inline at::Tensor _copy_from_and_resize(const at::Tensor & self, const at::Tensor & dst) {
include/ATen/ops/_copy_from_and_resize.h:    return at::_ops::_copy_from_and_resize::call(self, dst);
include/ATen/ops/_copy_from_and_resize.h:// aten::_copy_from_and_resize.out(Tensor self, Tensor dst, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/ops/_copy_from_and_resize.h:inline at::Tensor & _copy_from_and_resize_out(at::Tensor & out, const at::Tensor & self, const at::Tensor & dst) {
include/ATen/ops/_copy_from_and_resize.h:    return at::_ops::_copy_from_and_resize_out::call(self, dst, out);
include/ATen/ops/_copy_from_and_resize.h:// aten::_copy_from_and_resize.out(Tensor self, Tensor dst, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/ops/_copy_from_and_resize.h:inline at::Tensor & _copy_from_and_resize_outf(const at::Tensor & self, const at::Tensor & dst, at::Tensor & out) {
include/ATen/ops/_copy_from_and_resize.h:    return at::_ops::_copy_from_and_resize_out::call(self, dst, out);
include/ATen/ops/_fw_primal_copy_native.h:TORCH_API at::Tensor & _fw_primal_copy_out(const at::Tensor & self, int64_t level, at::Tensor & out);
include/ATen/ops/_make_dual_copy.h:#include <ATen/ops/_make_dual_copy_ops.h>
include/ATen/ops/_make_dual_copy.h:inline at::Tensor & _make_dual_copy_out(at::Tensor & out, const at::Tensor & primal, const at::Tensor & tangent, int64_t level) {
include/ATen/ops/_make_dual_copy.h:    return at::_ops::_make_dual_copy_out::call(primal, tangent, level, out);
include/ATen/ops/_make_dual_copy.h:inline at::Tensor & _make_dual_copy_outf(const at::Tensor & primal, const at::Tensor & tangent, int64_t level, at::Tensor & out) {
include/ATen/ops/_make_dual_copy.h:    return at::_ops::_make_dual_copy_out::call(primal, tangent, level, out);
include/ATen/ops/select_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & select_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, int64_t index);
include/ATen/ops/select_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & select_copy_outf(const at::Tensor & self, int64_t dim, int64_t index, at::Tensor & out);
include/ATen/ops/select_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & select_copy_symint_out(at::Tensor & out, const at::Tensor & self, int64_t dim, c10::SymInt index);
include/ATen/ops/select_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & select_copy_symint_outf(const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out);
include/ATen/ops/_reshape_copy.h:#include <ATen/ops/_reshape_copy_ops.h>
include/ATen/ops/_reshape_copy.h:inline at::Tensor _reshape_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size) {
include/ATen/ops/detach_copy_native.h:TORCH_API at::Tensor & detach_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/indices_copy_native.h:TORCH_API at::Tensor & indices_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_copy_from.h:#include <ATen/ops/_copy_from_ops.h>
include/ATen/ops/_copy_from.h:// aten::_copy_from(Tensor self, Tensor dst, bool non_blocking=False) -> Tensor
include/ATen/ops/_copy_from.h:inline at::Tensor _copy_from(const at::Tensor & self, const at::Tensor & dst, bool non_blocking=false) {
include/ATen/ops/_copy_from.h:    return at::_ops::_copy_from::call(self, dst, non_blocking);
include/ATen/ops/_copy_from.h:// aten::_copy_from.out(Tensor self, Tensor dst, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/ops/_copy_from.h:inline at::Tensor & _copy_from_out(at::Tensor & out, const at::Tensor & self, const at::Tensor & dst, bool non_blocking=false) {
include/ATen/ops/_copy_from.h:    return at::_ops::_copy_from_out::call(self, dst, non_blocking, out);
include/ATen/ops/_copy_from.h:// aten::_copy_from.out(Tensor self, Tensor dst, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/ops/_copy_from.h:inline at::Tensor & _copy_from_outf(const at::Tensor & self, const at::Tensor & dst, bool non_blocking, at::Tensor & out) {
include/ATen/ops/_copy_from.h:    return at::_ops::_copy_from_out::call(self, dst, non_blocking, out);
include/ATen/ops/unfold_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & unfold_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step);
include/ATen/ops/unfold_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & unfold_copy_outf(const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out);
include/ATen/ops/_copy_from_ops.h:struct TORCH_API _copy_from {
include/ATen/ops/_copy_from_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::_copy_from")
include/ATen/ops/_copy_from_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "_copy_from(Tensor self, Tensor dst, bool non_blocking=False) -> Tensor")
include/ATen/ops/_copy_from_ops.h:struct TORCH_API _copy_from_out {
include/ATen/ops/_copy_from_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::_copy_from")
include/ATen/ops/_copy_from_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "_copy_from.out(Tensor self, Tensor dst, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)")
include/ATen/ops/_has_compatible_shallow_copy_type.h:#include <ATen/ops/_has_compatible_shallow_copy_type_ops.h>
include/ATen/ops/_has_compatible_shallow_copy_type.h:// aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool
include/ATen/ops/_has_compatible_shallow_copy_type.h:inline bool _has_compatible_shallow_copy_type(const at::Tensor & self, const at::Tensor & from) {
include/ATen/ops/_has_compatible_shallow_copy_type.h:    return at::_ops::_has_compatible_shallow_copy_type::call(self, from);
include/ATen/ops/view_copy.h:#include <ATen/ops/view_copy_ops.h>
include/ATen/ops/view_copy.h:inline at::Tensor view_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_dtype::call(self, dtype);
include/ATen/ops/view_copy.h:inline at::Tensor & view_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_out::call(self, c10::fromIntArrayRefSlow(size), out);
include/ATen/ops/view_copy.h:  at::Tensor & view_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_out::call(self, c10::fromIntArrayRefSlow(size), out);
include/ATen/ops/view_copy.h:inline at::Tensor & view_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::Tensor & out) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_out::call(self, c10::fromIntArrayRefSlow(size), out);
include/ATen/ops/view_copy.h:  at::Tensor & view_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::Tensor & out) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_out::call(self, c10::fromIntArrayRefSlow(size), out);
include/ATen/ops/view_copy.h:inline at::Tensor & view_copy_symint_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_out::call(self, size, out);
include/ATen/ops/view_copy.h:  at::Tensor & view_copy_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_out::call(self, size, out);
include/ATen/ops/view_copy.h:inline at::Tensor & view_copy_symint_outf(const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_out::call(self, size, out);
include/ATen/ops/view_copy.h:  at::Tensor & view_copy_outf(const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_out::call(self, size, out);
include/ATen/ops/view_copy.h:inline at::Tensor & view_copy_out(at::Tensor & out, const at::Tensor & self, at::ScalarType dtype) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_dtype_out::call(self, dtype, out);
include/ATen/ops/view_copy.h:inline at::Tensor & view_copy_outf(const at::Tensor & self, at::ScalarType dtype, at::Tensor & out) {
include/ATen/ops/view_copy.h:    return at::_ops::view_copy_dtype_out::call(self, dtype, out);
include/ATen/ops/view_as_real_copy.h:#include <ATen/ops/view_as_real_copy_ops.h>
include/ATen/ops/view_as_real_copy.h:inline at::Tensor & view_as_real_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/view_as_real_copy.h:    return at::_ops::view_as_real_copy_out::call(self, out);
include/ATen/ops/view_as_real_copy.h:inline at::Tensor & view_as_real_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/view_as_real_copy.h:    return at::_ops::view_as_real_copy_out::call(self, out);
include/ATen/ops/unfold_copy_native.h:TORCH_API at::Tensor & unfold_copy_out(const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out);
include/ATen/ops/_reshape_alias_copy_compositeexplicitautogradnonfunctional_dispatch.h:TORCH_API at::Tensor _reshape_alias_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride);
include/ATen/ops/_test_autograd_multiple_dispatch_view_copy_ops.h:struct TORCH_API _test_autograd_multiple_dispatch_view_copy_out {
include/ATen/ops/index_copy_native.h:#include <ATen/ops/index_copy_meta.h>
include/ATen/ops/index_copy_native.h:struct TORCH_API structured_index_copy_out : public at::meta::structured_index_copy {
include/ATen/ops/index_copy_native.h:TORCH_API at::Tensor & index_copy_(at::Tensor & self, at::Dimname dim, const at::Tensor & index, const at::Tensor & source);
include/ATen/ops/ccol_indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & ccol_indices_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/ccol_indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & ccol_indices_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_conj_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _conj_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/_conj_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _conj_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_conj_copy_native.h:TORCH_API at::Tensor & _conj_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/ccol_indices_copy_native.h:TORCH_API at::Tensor & ccol_indices_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/narrow_copy_ops.h:struct TORCH_API narrow_copy_out {
include/ATen/ops/as_strided_copy_native.h:TORCH_API at::Tensor & as_strided_copy_out_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out);
include/ATen/ops/as_strided_copy_native.h:TORCH_API at::Tensor as_strided_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset=c10::nullopt);
include/ATen/ops/as_strided_copy_ops.h:struct TORCH_API as_strided_copy_out {
include/ATen/ops/split_copy.h:#include <ATen/ops/split_copy_ops.h>
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor::call(self, split_size, dim);
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor::call(self, split_size, dim);
include/ATen/ops/split_copy.h:inline ::std::vector<at::Tensor> split_copy_symint(const at::Tensor & self, c10::SymInt split_size, int64_t dim=0) {
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor::call(self, split_size, dim);
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor::call(self, split_size, dim);
include/ATen/ops/split_copy.h:inline void split_copy_out(at::TensorList out, const at::Tensor & self, int64_t split_size, int64_t dim=0) {
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor_out::call(self, split_size, dim, out);
include/ATen/ops/split_copy.h:  void split_copy_out(at::TensorList out, const at::Tensor & self, int64_t split_size, int64_t dim=0) {
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor_out::call(self, split_size, dim, out);
include/ATen/ops/split_copy.h:inline void split_copy_outf(const at::Tensor & self, int64_t split_size, int64_t dim, at::TensorList out) {
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor_out::call(self, split_size, dim, out);
include/ATen/ops/split_copy.h:  void split_copy_outf(const at::Tensor & self, int64_t split_size, int64_t dim, at::TensorList out) {
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor_out::call(self, split_size, dim, out);
include/ATen/ops/split_copy.h:inline void split_copy_symint_out(at::TensorList out, const at::Tensor & self, c10::SymInt split_size, int64_t dim=0) {
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor_out::call(self, split_size, dim, out);
include/ATen/ops/split_copy.h:  void split_copy_out(at::TensorList out, const at::Tensor & self, c10::SymInt split_size, int64_t dim=0) {
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor_out::call(self, split_size, dim, out);
include/ATen/ops/split_copy.h:inline void split_copy_symint_outf(const at::Tensor & self, c10::SymInt split_size, int64_t dim, at::TensorList out) {
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor_out::call(self, split_size, dim, out);
include/ATen/ops/split_copy.h:  void split_copy_outf(const at::Tensor & self, c10::SymInt split_size, int64_t dim, at::TensorList out) {
include/ATen/ops/split_copy.h:    return at::_ops::split_copy_Tensor_out::call(self, split_size, dim, out);
include/ATen/ops/_fw_primal_copy_ops.h:struct TORCH_API _fw_primal_copy_out {
include/ATen/ops/index_copy_ops.h:struct TORCH_API index_copy_out {
include/ATen/ops/index_copy_ops.h:struct TORCH_API index_copy_ {
include/ATen/ops/index_copy_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::index_copy_")
include/ATen/ops/index_copy_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -> Tensor(a!)")
include/ATen/ops/index_copy_ops.h:struct TORCH_API index_copy__dimname {
include/ATen/ops/index_copy_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::index_copy_")
include/ATen/ops/index_copy_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "index_copy_.dimname(Tensor(a!) self, Dimname dim, Tensor index, Tensor source) -> Tensor(a!)")
include/ATen/ops/index_copy_ops.h:struct TORCH_API index_copy_dimname {
include/ATen/ops/as_strided_copy_compositeexplicitautogradnonfunctional_dispatch.h:TORCH_API at::Tensor as_strided_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset=c10::nullopt);
include/ATen/ops/t_copy.h:#include <ATen/ops/t_copy_ops.h>
include/ATen/ops/t_copy.h:inline at::Tensor & t_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/t_copy.h:    return at::_ops::t_copy_out::call(self, out);
include/ATen/ops/t_copy.h:inline at::Tensor & t_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/t_copy.h:    return at::_ops::t_copy_out::call(self, out);
include/ATen/ops/_copy_from_native.h:TORCH_API at::Tensor & _copy_from_out(const at::Tensor & self, const at::Tensor & dst, bool non_blocking, at::Tensor & out);
include/ATen/ops/lift_fresh_copy.h:#include <ATen/ops/lift_fresh_copy_ops.h>
include/ATen/ops/lift_fresh_copy.h:inline at::Tensor & lift_fresh_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/lift_fresh_copy.h:    return at::_ops::lift_fresh_copy_out::call(self, out);
include/ATen/ops/lift_fresh_copy.h:inline at::Tensor & lift_fresh_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/lift_fresh_copy.h:    return at::_ops::lift_fresh_copy_out::call(self, out);
include/ATen/ops/values_copy.h:#include <ATen/ops/values_copy_ops.h>
include/ATen/ops/values_copy.h:inline at::Tensor & values_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/values_copy.h:    return at::_ops::values_copy_out::call(self, out);
include/ATen/ops/values_copy.h:inline at::Tensor & values_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/values_copy.h:    return at::_ops::values_copy_out::call(self, out);
include/ATen/ops/_neg_view_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _neg_view_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/_neg_view_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _neg_view_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/transpose_copy_native.h:TORCH_API at::Tensor & transpose_copy_int_out(const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out);
include/ATen/ops/transpose_copy_native.h:TORCH_API at::Tensor transpose_copy_int(const at::Tensor & self, int64_t dim0, int64_t dim1);
include/ATen/ops/unbind_copy.h:#include <ATen/ops/unbind_copy_ops.h>
include/ATen/ops/unbind_copy.h:    return at::_ops::unbind_copy_int::call(self, dim);
include/ATen/ops/unbind_copy.h:inline void unbind_copy_out(at::TensorList out, const at::Tensor & self, int64_t dim=0) {
include/ATen/ops/unbind_copy.h:    return at::_ops::unbind_copy_int_out::call(self, dim, out);
include/ATen/ops/unbind_copy.h:inline void unbind_copy_outf(const at::Tensor & self, int64_t dim, at::TensorList out) {
include/ATen/ops/unbind_copy.h:    return at::_ops::unbind_copy_int_out::call(self, dim, out);
include/ATen/ops/copy.h:#include <ATen/ops/copy_ops.h>
include/ATen/ops/copy.h:inline at::Tensor & copy_out(at::Tensor & out, const at::Tensor & self, const at::Tensor & src, bool non_blocking=false) {
include/ATen/ops/copy.h:    return at::_ops::copy_out::call(self, src, non_blocking, out);
include/ATen/ops/copy.h:inline at::Tensor & copy_outf(const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
include/ATen/ops/copy.h:    return at::_ops::copy_out::call(self, src, non_blocking, out);
include/ATen/ops/copy_native.h:TORCH_API at::Tensor & copy_out(const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out);
include/ATen/ops/copy_native.h:TORCH_API at::Tensor & copy_(at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/copy_native.h:TORCH_API at::Tensor & copy_nested_(at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/copy_native.h:TORCH_API at::Tensor & copy_sparse_wrapper_(at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/copy_native.h:TORCH_API at::Tensor & copy_sparse_compressed_(at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/copy_native.h:TORCH_API at::Tensor & copy_mkldnn_(at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/view_as_complex_copy_ops.h:struct TORCH_API view_as_complex_copy_out {
include/ATen/ops/_nested_view_from_buffer_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _nested_view_from_buffer_copy_out(at::Tensor & out, const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets);
include/ATen/ops/_nested_view_from_buffer_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _nested_view_from_buffer_copy_outf(const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets, at::Tensor & out);
include/ATen/ops/lift_fresh_copy_native.h:TORCH_API at::Tensor & lift_fresh_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/view_copy_compositeexplicitautogradnonfunctional_dispatch.h:TORCH_API at::Tensor view_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size);
include/ATen/ops/unbind_copy_native.h:TORCH_API void unbind_copy_int_out(const at::Tensor & self, int64_t dim, at::TensorList out);
include/ATen/ops/unbind_copy_native.h:TORCH_API ::std::vector<at::Tensor> unbind_copy_int(const at::Tensor & self, int64_t dim=0);
include/ATen/ops/lift_fresh_copy_ops.h:struct TORCH_API lift_fresh_copy_out {
include/ATen/ops/_nested_view_from_buffer_copy.h:#include <ATen/ops/_nested_view_from_buffer_copy_ops.h>
include/ATen/ops/_nested_view_from_buffer_copy.h:inline at::Tensor & _nested_view_from_buffer_copy_out(at::Tensor & out, const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets) {
include/ATen/ops/_nested_view_from_buffer_copy.h:    return at::_ops::_nested_view_from_buffer_copy_out::call(self, nested_size, nested_strides, offsets, out);
include/ATen/ops/_nested_view_from_buffer_copy.h:inline at::Tensor & _nested_view_from_buffer_copy_outf(const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets, at::Tensor & out) {
include/ATen/ops/_nested_view_from_buffer_copy.h:    return at::_ops::_nested_view_from_buffer_copy_out::call(self, nested_size, nested_strides, offsets, out);
include/ATen/ops/indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & indices_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & indices_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_reshape_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor _reshape_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size);
include/ATen/ops/unfold_copy.h:#include <ATen/ops/unfold_copy_ops.h>
include/ATen/ops/unfold_copy.h:inline at::Tensor & unfold_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step) {
include/ATen/ops/unfold_copy.h:    return at::_ops::unfold_copy_out::call(self, dimension, size, step, out);
include/ATen/ops/unfold_copy.h:inline at::Tensor & unfold_copy_outf(const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out) {
include/ATen/ops/unfold_copy.h:    return at::_ops::unfold_copy_out::call(self, dimension, size, step, out);
include/ATen/ops/select_copy.h:#include <ATen/ops/select_copy_ops.h>
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int::call(self, dim, index);
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int::call(self, dim, index);
include/ATen/ops/select_copy.h:inline at::Tensor select_copy_symint(const at::Tensor & self, int64_t dim, c10::SymInt index) {
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int::call(self, dim, index);
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int::call(self, dim, index);
include/ATen/ops/select_copy.h:inline at::Tensor & select_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, int64_t index) {
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int_out::call(self, dim, index, out);
include/ATen/ops/select_copy.h:  at::Tensor & select_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, int64_t index) {
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int_out::call(self, dim, index, out);
include/ATen/ops/select_copy.h:inline at::Tensor & select_copy_outf(const at::Tensor & self, int64_t dim, int64_t index, at::Tensor & out) {
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int_out::call(self, dim, index, out);
include/ATen/ops/select_copy.h:  at::Tensor & select_copy_outf(const at::Tensor & self, int64_t dim, int64_t index, at::Tensor & out) {
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int_out::call(self, dim, index, out);
include/ATen/ops/select_copy.h:inline at::Tensor & select_copy_symint_out(at::Tensor & out, const at::Tensor & self, int64_t dim, c10::SymInt index) {
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int_out::call(self, dim, index, out);
include/ATen/ops/select_copy.h:  at::Tensor & select_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, c10::SymInt index) {
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int_out::call(self, dim, index, out);
include/ATen/ops/select_copy.h:inline at::Tensor & select_copy_symint_outf(const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int_out::call(self, dim, index, out);
include/ATen/ops/select_copy.h:  at::Tensor & select_copy_outf(const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
include/ATen/ops/select_copy.h:    return at::_ops::select_copy_int_out::call(self, dim, index, out);
include/ATen/ops/select_copy_compositeexplicitautogradnonfunctional_dispatch.h:TORCH_API at::Tensor select_copy_symint(const at::Tensor & self, int64_t dim, c10::SymInt index);
include/ATen/ops/view_as_complex_copy.h:#include <ATen/ops/view_as_complex_copy_ops.h>
include/ATen/ops/view_as_complex_copy.h:inline at::Tensor & view_as_complex_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/view_as_complex_copy.h:    return at::_ops::view_as_complex_copy_out::call(self, out);
include/ATen/ops/view_as_complex_copy.h:inline at::Tensor & view_as_complex_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/view_as_complex_copy.h:    return at::_ops::view_as_complex_copy_out::call(self, out);
include/ATen/ops/as_strided_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & as_strided_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, c10::optional<int64_t> storage_offset=c10::nullopt);
include/ATen/ops/as_strided_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & as_strided_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, c10::optional<int64_t> storage_offset, at::Tensor & out);
include/ATen/ops/as_strided_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & as_strided_copy_symint_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset=c10::nullopt);
include/ATen/ops/as_strided_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & as_strided_copy_symint_outf(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out);
include/ATen/ops/unfold_copy_ops.h:struct TORCH_API unfold_copy_out {
include/ATen/ops/_make_dual_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _make_dual_copy_out(at::Tensor & out, const at::Tensor & primal, const at::Tensor & tangent, int64_t level);
include/ATen/ops/_make_dual_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _make_dual_copy_outf(const at::Tensor & primal, const at::Tensor & tangent, int64_t level, at::Tensor & out);
include/ATen/ops/crow_indices_copy_native.h:TORCH_API at::Tensor & crow_indices_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/slice_copy_native.h:TORCH_API at::Tensor & slice_copy_Tensor_out(const at::Tensor & self, int64_t dim, c10::optional<int64_t> start, c10::optional<int64_t> end, int64_t step, at::Tensor & out);
include/ATen/ops/slice_copy_native.h:TORCH_API at::Tensor slice_copy_Tensor_symint(const at::Tensor & self, int64_t dim=0, c10::optional<c10::SymInt> start=c10::nullopt, c10::optional<c10::SymInt> end=c10::nullopt, c10::SymInt step=1);
include/ATen/ops/col_indices_copy_native.h:TORCH_API at::Tensor & col_indices_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/split_copy_ops.h:struct TORCH_API split_copy_Tensor {
include/ATen/ops/split_copy_ops.h:struct TORCH_API split_copy_Tensor_out {
include/ATen/ops/_nested_view_from_buffer_copy_native.h:TORCH_API at::Tensor & _nested_view_from_buffer_copy_out(const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets, at::Tensor & out);
include/ATen/ops/_neg_view_copy.h:#include <ATen/ops/_neg_view_copy_ops.h>
include/ATen/ops/_neg_view_copy.h:inline at::Tensor & _neg_view_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/_neg_view_copy.h:    return at::_ops::_neg_view_copy_out::call(self, out);
include/ATen/ops/_neg_view_copy.h:inline at::Tensor & _neg_view_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/_neg_view_copy.h:    return at::_ops::_neg_view_copy_out::call(self, out);
include/ATen/ops/view_as_complex_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & view_as_complex_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/view_as_complex_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & view_as_complex_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_indices_copy_native.h:TORCH_API at::Tensor & _indices_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & copy_out(at::Tensor & out, const at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & copy_outf(const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out);
include/ATen/ops/copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & copy_(at::Tensor & self, const at::Tensor & src, bool non_blocking=false);
include/ATen/ops/_test_autograd_multiple_dispatch_view_copy_native.h:TORCH_API at::Tensor & _test_autograd_multiple_dispatch_view_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_to_copy_ops.h:struct TORCH_API _to_copy_out {
include/ATen/ops/_indices_copy_ops.h:struct TORCH_API _indices_copy_out {
include/ATen/ops/_reshape_alias_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _reshape_alias_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride);
include/ATen/ops/_reshape_alias_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _reshape_alias_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, at::Tensor & out);
include/ATen/ops/_reshape_alias_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _reshape_alias_copy_symint_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride);
include/ATen/ops/_reshape_alias_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _reshape_alias_copy_symint_outf(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out);
include/ATen/ops/row_indices_copy_native.h:TORCH_API at::Tensor & row_indices_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/view_copy_native.h:TORCH_API at::Tensor & view_copy_out_symint(const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out);
include/ATen/ops/view_copy_native.h:TORCH_API at::Tensor view_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size);
include/ATen/ops/view_copy_native.h:TORCH_API at::Tensor & view_copy_dtype_out(const at::Tensor & self, at::ScalarType dtype, at::Tensor & out);
include/ATen/ops/view_copy_native.h:TORCH_API at::Tensor view_copy_dtype(const at::Tensor & self, at::ScalarType dtype);
include/ATen/ops/_values_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _values_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/_values_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _values_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/crow_indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & crow_indices_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/crow_indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & crow_indices_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/col_indices_copy_ops.h:struct TORCH_API col_indices_copy_out {
include/ATen/ops/diagonal_copy_ops.h:struct TORCH_API diagonal_copy_out {
include/ATen/ops/col_indices_copy.h:#include <ATen/ops/col_indices_copy_ops.h>
include/ATen/ops/col_indices_copy.h:inline at::Tensor & col_indices_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/col_indices_copy.h:    return at::_ops::col_indices_copy_out::call(self, out);
include/ATen/ops/col_indices_copy.h:inline at::Tensor & col_indices_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/col_indices_copy.h:    return at::_ops::col_indices_copy_out::call(self, out);
include/ATen/ops/_values_copy_ops.h:struct TORCH_API _values_copy_out {
include/ATen/ops/split_with_sizes_copy.h:#include <ATen/ops/split_with_sizes_copy_ops.h>
include/ATen/ops/split_with_sizes_copy.h:inline ::std::vector<at::Tensor> split_with_sizes_copy_symint(const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim=0) {
include/ATen/ops/split_with_sizes_copy.h:inline void split_with_sizes_copy_out(at::TensorList out, const at::Tensor & self, at::IntArrayRef split_sizes, int64_t dim=0) {
include/ATen/ops/split_with_sizes_copy.h:    return at::_ops::split_with_sizes_copy_out::call(self, c10::fromIntArrayRefSlow(split_sizes), dim, out);
include/ATen/ops/split_with_sizes_copy.h:  void split_with_sizes_copy_out(at::TensorList out, const at::Tensor & self, at::IntArrayRef split_sizes, int64_t dim=0) {
include/ATen/ops/split_with_sizes_copy.h:    return at::_ops::split_with_sizes_copy_out::call(self, c10::fromIntArrayRefSlow(split_sizes), dim, out);
include/ATen/ops/split_with_sizes_copy.h:inline void split_with_sizes_copy_outf(const at::Tensor & self, at::IntArrayRef split_sizes, int64_t dim, at::TensorList out) {
include/ATen/ops/split_with_sizes_copy.h:    return at::_ops::split_with_sizes_copy_out::call(self, c10::fromIntArrayRefSlow(split_sizes), dim, out);
include/ATen/ops/split_with_sizes_copy.h:  void split_with_sizes_copy_outf(const at::Tensor & self, at::IntArrayRef split_sizes, int64_t dim, at::TensorList out) {
include/ATen/ops/split_with_sizes_copy.h:    return at::_ops::split_with_sizes_copy_out::call(self, c10::fromIntArrayRefSlow(split_sizes), dim, out);
include/ATen/ops/split_with_sizes_copy.h:inline void split_with_sizes_copy_symint_out(at::TensorList out, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim=0) {
include/ATen/ops/split_with_sizes_copy.h:    return at::_ops::split_with_sizes_copy_out::call(self, split_sizes, dim, out);
include/ATen/ops/split_with_sizes_copy.h:  void split_with_sizes_copy_out(at::TensorList out, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim=0) {
include/ATen/ops/split_with_sizes_copy.h:    return at::_ops::split_with_sizes_copy_out::call(self, split_sizes, dim, out);
include/ATen/ops/split_with_sizes_copy.h:inline void split_with_sizes_copy_symint_outf(const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim, at::TensorList out) {
include/ATen/ops/split_with_sizes_copy.h:    return at::_ops::split_with_sizes_copy_out::call(self, split_sizes, dim, out);
include/ATen/ops/split_with_sizes_copy.h:  void split_with_sizes_copy_outf(const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim, at::TensorList out) {
include/ATen/ops/split_with_sizes_copy.h:    return at::_ops::split_with_sizes_copy_out::call(self, split_sizes, dim, out);
include/ATen/ops/_sparse_broadcast_to_copy_ops.h:struct TORCH_API _sparse_broadcast_to_copy_out {
include/ATen/ops/_indices_copy.h:#include <ATen/ops/_indices_copy_ops.h>
include/ATen/ops/_indices_copy.h:inline at::Tensor & _indices_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/_indices_copy.h:    return at::_ops::_indices_copy_out::call(self, out);
include/ATen/ops/_indices_copy.h:inline at::Tensor & _indices_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/_indices_copy.h:    return at::_ops::_indices_copy_out::call(self, out);
include/ATen/ops/_nested_view_from_buffer_copy_ops.h:struct TORCH_API _nested_view_from_buffer_copy_out {
include/ATen/ops/_conj_copy_ops.h:struct TORCH_API _conj_copy_out {
include/ATen/ops/row_indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & row_indices_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/row_indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & row_indices_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/detach_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & detach_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/detach_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & detach_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/transpose_copy_ops.h:struct TORCH_API transpose_copy_int {
include/ATen/ops/transpose_copy_ops.h:struct TORCH_API transpose_copy_int_out {
include/ATen/ops/_reshape_copy_native.h:TORCH_API at::Tensor _reshape_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size);
include/ATen/ops/_make_dual_copy_ops.h:struct TORCH_API _make_dual_copy_out {
include/ATen/ops/crow_indices_copy.h:#include <ATen/ops/crow_indices_copy_ops.h>
include/ATen/ops/crow_indices_copy.h:inline at::Tensor & crow_indices_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/crow_indices_copy.h:    return at::_ops::crow_indices_copy_out::call(self, out);
include/ATen/ops/crow_indices_copy.h:inline at::Tensor & crow_indices_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/crow_indices_copy.h:    return at::_ops::crow_indices_copy_out::call(self, out);
include/ATen/ops/_copy_from_and_resize_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _copy_from_and_resize_out(at::Tensor & out, const at::Tensor & self, const at::Tensor & dst);
include/ATen/ops/_copy_from_and_resize_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _copy_from_and_resize_outf(const at::Tensor & self, const at::Tensor & dst, at::Tensor & out);
include/ATen/ops/_make_dual_copy_native.h:TORCH_API at::Tensor & _make_dual_copy_out(const at::Tensor & primal, const at::Tensor & tangent, int64_t level, at::Tensor & out);
include/ATen/ops/squeeze_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & squeeze_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/squeeze_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & squeeze_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/squeeze_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & squeeze_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim);
include/ATen/ops/squeeze_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & squeeze_copy_outf(const at::Tensor & self, int64_t dim, at::Tensor & out);
include/ATen/ops/squeeze_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & squeeze_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef dim);
include/ATen/ops/squeeze_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & squeeze_copy_outf(const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out);
include/ATen/ops/col_indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & col_indices_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/col_indices_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & col_indices_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/t_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & t_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/t_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & t_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_reshape_alias_copy.h:#include <ATen/ops/_reshape_alias_copy_ops.h>
include/ATen/ops/_reshape_alias_copy.h:inline at::Tensor _reshape_alias_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) {
include/ATen/ops/_reshape_alias_copy.h:inline at::Tensor & _reshape_alias_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride) {
include/ATen/ops/_reshape_alias_copy.h:    return at::_ops::_reshape_alias_copy_out::call(self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), out);
include/ATen/ops/_reshape_alias_copy.h:  at::Tensor & _reshape_alias_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride) {
include/ATen/ops/_reshape_alias_copy.h:    return at::_ops::_reshape_alias_copy_out::call(self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), out);
include/ATen/ops/_reshape_alias_copy.h:inline at::Tensor & _reshape_alias_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, at::Tensor & out) {
include/ATen/ops/_reshape_alias_copy.h:    return at::_ops::_reshape_alias_copy_out::call(self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), out);
include/ATen/ops/_reshape_alias_copy.h:  at::Tensor & _reshape_alias_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, at::Tensor & out) {
include/ATen/ops/_reshape_alias_copy.h:    return at::_ops::_reshape_alias_copy_out::call(self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), out);
include/ATen/ops/_reshape_alias_copy.h:inline at::Tensor & _reshape_alias_copy_symint_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) {
include/ATen/ops/_reshape_alias_copy.h:    return at::_ops::_reshape_alias_copy_out::call(self, size, stride, out);
include/ATen/ops/_reshape_alias_copy.h:  at::Tensor & _reshape_alias_copy_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) {
include/ATen/ops/_reshape_alias_copy.h:    return at::_ops::_reshape_alias_copy_out::call(self, size, stride, out);
include/ATen/ops/_reshape_alias_copy.h:inline at::Tensor & _reshape_alias_copy_symint_outf(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out) {
include/ATen/ops/_reshape_alias_copy.h:    return at::_ops::_reshape_alias_copy_out::call(self, size, stride, out);
include/ATen/ops/_reshape_alias_copy.h:  at::Tensor & _reshape_alias_copy_outf(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out) {
include/ATen/ops/_reshape_alias_copy.h:    return at::_ops::_reshape_alias_copy_out::call(self, size, stride, out);
include/ATen/ops/diagonal_copy_native.h:TORCH_API at::Tensor & diagonal_copy_out(const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out);
include/ATen/ops/unsqueeze_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & unsqueeze_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim);
include/ATen/ops/unsqueeze_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & unsqueeze_copy_outf(const at::Tensor & self, int64_t dim, at::Tensor & out);
include/ATen/ops/copy_ops.h:struct TORCH_API copy_ {
include/ATen/ops/copy_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::copy_")
include/ATen/ops/copy_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)")
include/ATen/ops/copy_ops.h:struct TORCH_API copy_out {
include/ATen/ops/row_indices_copy_ops.h:struct TORCH_API row_indices_copy_out {
include/ATen/ops/_copy_from_and_resize_native.h:TORCH_API at::Tensor & _copy_from_and_resize_out(const at::Tensor & self, const at::Tensor & dst, at::Tensor & out);
include/ATen/ops/_neg_view_copy_ops.h:struct TORCH_API _neg_view_copy_out {
include/ATen/ops/view_copy_ops.h:struct TORCH_API view_copy_dtype {
include/ATen/ops/view_copy_ops.h:struct TORCH_API view_copy_out {
include/ATen/ops/view_copy_ops.h:struct TORCH_API view_copy_dtype_out {
include/ATen/ops/slice_copy.h:#include <ATen/ops/slice_copy_ops.h>
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor::call(self, dim, start.has_value() ? c10::make_optional(c10::SymInt(*start)) : c10::nullopt, end.has_value() ? c10::make_optional(c10::SymInt(*end)) : c10::nullopt, step);
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor::call(self, dim, start.has_value() ? c10::make_optional(c10::SymInt(*start)) : c10::nullopt, end.has_value() ? c10::make_optional(c10::SymInt(*end)) : c10::nullopt, step);
include/ATen/ops/slice_copy.h:inline at::Tensor slice_copy_symint(const at::Tensor & self, int64_t dim=0, c10::optional<c10::SymInt> start=c10::nullopt, c10::optional<c10::SymInt> end=c10::nullopt, c10::SymInt step=1) {
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor::call(self, dim, start, end, step);
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor::call(self, dim, start, end, step);
include/ATen/ops/slice_copy.h:inline at::Tensor & slice_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim=0, c10::optional<int64_t> start=c10::nullopt, c10::optional<int64_t> end=c10::nullopt, int64_t step=1) {
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor_out::call(self, dim, start.has_value() ? c10::make_optional(c10::SymInt(*start)) : c10::nullopt, end.has_value() ? c10::make_optional(c10::SymInt(*end)) : c10::nullopt, step, out);
include/ATen/ops/slice_copy.h:  at::Tensor & slice_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim=0, c10::optional<int64_t> start=c10::nullopt, c10::optional<int64_t> end=c10::nullopt, int64_t step=1) {
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor_out::call(self, dim, start.has_value() ? c10::make_optional(c10::SymInt(*start)) : c10::nullopt, end.has_value() ? c10::make_optional(c10::SymInt(*end)) : c10::nullopt, step, out);
include/ATen/ops/slice_copy.h:inline at::Tensor & slice_copy_outf(const at::Tensor & self, int64_t dim, c10::optional<int64_t> start, c10::optional<int64_t> end, int64_t step, at::Tensor & out) {
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor_out::call(self, dim, start.has_value() ? c10::make_optional(c10::SymInt(*start)) : c10::nullopt, end.has_value() ? c10::make_optional(c10::SymInt(*end)) : c10::nullopt, step, out);
include/ATen/ops/slice_copy.h:  at::Tensor & slice_copy_outf(const at::Tensor & self, int64_t dim, c10::optional<int64_t> start, c10::optional<int64_t> end, int64_t step, at::Tensor & out) {
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor_out::call(self, dim, start.has_value() ? c10::make_optional(c10::SymInt(*start)) : c10::nullopt, end.has_value() ? c10::make_optional(c10::SymInt(*end)) : c10::nullopt, step, out);
include/ATen/ops/slice_copy.h:inline at::Tensor & slice_copy_symint_out(at::Tensor & out, const at::Tensor & self, int64_t dim=0, c10::optional<c10::SymInt> start=c10::nullopt, c10::optional<c10::SymInt> end=c10::nullopt, c10::SymInt step=1) {
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor_out::call(self, dim, start, end, step, out);
include/ATen/ops/slice_copy.h:  at::Tensor & slice_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim=0, c10::optional<c10::SymInt> start=c10::nullopt, c10::optional<c10::SymInt> end=c10::nullopt, c10::SymInt step=1) {
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor_out::call(self, dim, start, end, step, out);
include/ATen/ops/slice_copy.h:inline at::Tensor & slice_copy_symint_outf(const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out) {
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor_out::call(self, dim, start, end, step, out);
include/ATen/ops/slice_copy.h:  at::Tensor & slice_copy_outf(const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out) {
include/ATen/ops/slice_copy.h:    return at::_ops::slice_copy_Tensor_out::call(self, dim, start, end, step, out);
include/ATen/ops/detach_copy_ops.h:struct TORCH_API detach_copy_out {
include/ATen/ops/_sparse_broadcast_to_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _sparse_broadcast_to_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size);
include/ATen/ops/_sparse_broadcast_to_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _sparse_broadcast_to_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::Tensor & out);
include/ATen/ops/copy_sparse_to_sparse.h:#include <ATen/ops/copy_sparse_to_sparse_ops.h>
include/ATen/ops/copy_sparse_to_sparse.h:// aten::copy_sparse_to_sparse_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)
include/ATen/ops/copy_sparse_to_sparse.h:inline at::Tensor & copy_sparse_to_sparse_(at::Tensor & self, const at::Tensor & src, bool non_blocking=false) {
include/ATen/ops/copy_sparse_to_sparse.h:    return at::_ops::copy_sparse_to_sparse_::call(self, src, non_blocking);
include/ATen/ops/copy_sparse_to_sparse.h:// aten::copy_sparse_to_sparse.out(Tensor self, Tensor src, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/ops/copy_sparse_to_sparse.h:inline at::Tensor & copy_sparse_to_sparse_out(at::Tensor & out, const at::Tensor & self, const at::Tensor & src, bool non_blocking=false) {
include/ATen/ops/copy_sparse_to_sparse.h:    return at::_ops::copy_sparse_to_sparse_out::call(self, src, non_blocking, out);
include/ATen/ops/copy_sparse_to_sparse.h:// aten::copy_sparse_to_sparse.out(Tensor self, Tensor src, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/ops/copy_sparse_to_sparse.h:inline at::Tensor & copy_sparse_to_sparse_outf(const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
include/ATen/ops/copy_sparse_to_sparse.h:    return at::_ops::copy_sparse_to_sparse_out::call(self, src, non_blocking, out);
include/ATen/ops/copy_sparse_to_sparse.h:// aten::copy_sparse_to_sparse(Tensor self, Tensor src, bool non_blocking=False) -> Tensor
include/ATen/ops/copy_sparse_to_sparse.h:inline at::Tensor copy_sparse_to_sparse(const at::Tensor & self, const at::Tensor & src, bool non_blocking=false) {
include/ATen/ops/copy_sparse_to_sparse.h:    return at::_ops::copy_sparse_to_sparse::call(self, src, non_blocking);
include/ATen/ops/permute_copy.h:#include <ATen/ops/permute_copy_ops.h>
include/ATen/ops/permute_copy.h:inline at::Tensor & permute_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef dims) {
include/ATen/ops/permute_copy.h:    return at::_ops::permute_copy_out::call(self, dims, out);
include/ATen/ops/permute_copy.h:inline at::Tensor & permute_copy_outf(const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out) {
include/ATen/ops/permute_copy.h:    return at::_ops::permute_copy_out::call(self, dims, out);
include/ATen/ops/index_copy_compositeexplicitautogradnonfunctional_dispatch.h:TORCH_API at::Tensor & index_copy_(at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source);
include/ATen/ops/as_strided_copy.h:#include <ATen/ops/as_strided_copy_ops.h>
include/ATen/ops/as_strided_copy.h:inline at::Tensor as_strided_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset=c10::nullopt) {
include/ATen/ops/as_strided_copy.h:inline at::Tensor & as_strided_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, c10::optional<int64_t> storage_offset=c10::nullopt) {
include/ATen/ops/as_strided_copy.h:    return at::_ops::as_strided_copy_out::call(self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? c10::make_optional(c10::SymInt(*storage_offset)) : c10::nullopt, out);
include/ATen/ops/as_strided_copy.h:  at::Tensor & as_strided_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, c10::optional<int64_t> storage_offset=c10::nullopt) {
include/ATen/ops/as_strided_copy.h:    return at::_ops::as_strided_copy_out::call(self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? c10::make_optional(c10::SymInt(*storage_offset)) : c10::nullopt, out);
include/ATen/ops/as_strided_copy.h:inline at::Tensor & as_strided_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, c10::optional<int64_t> storage_offset, at::Tensor & out) {
include/ATen/ops/as_strided_copy.h:    return at::_ops::as_strided_copy_out::call(self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? c10::make_optional(c10::SymInt(*storage_offset)) : c10::nullopt, out);
include/ATen/ops/as_strided_copy.h:  at::Tensor & as_strided_copy_outf(const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, c10::optional<int64_t> storage_offset, at::Tensor & out) {
include/ATen/ops/as_strided_copy.h:    return at::_ops::as_strided_copy_out::call(self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? c10::make_optional(c10::SymInt(*storage_offset)) : c10::nullopt, out);
include/ATen/ops/as_strided_copy.h:inline at::Tensor & as_strided_copy_symint_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset=c10::nullopt) {
include/ATen/ops/as_strided_copy.h:    return at::_ops::as_strided_copy_out::call(self, size, stride, storage_offset, out);
include/ATen/ops/as_strided_copy.h:  at::Tensor & as_strided_copy_out(at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset=c10::nullopt) {
include/ATen/ops/as_strided_copy.h:    return at::_ops::as_strided_copy_out::call(self, size, stride, storage_offset, out);
include/ATen/ops/as_strided_copy.h:inline at::Tensor & as_strided_copy_symint_outf(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out) {
include/ATen/ops/as_strided_copy.h:    return at::_ops::as_strided_copy_out::call(self, size, stride, storage_offset, out);
include/ATen/ops/as_strided_copy.h:  at::Tensor & as_strided_copy_outf(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out) {
include/ATen/ops/as_strided_copy.h:    return at::_ops::as_strided_copy_out::call(self, size, stride, storage_offset, out);
include/ATen/ops/_to_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _to_copy_out(at::Tensor & out, const at::Tensor & self, bool non_blocking=false, c10::optional<at::MemoryFormat> memory_format=c10::nullopt);
include/ATen/ops/_to_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _to_copy_outf(const at::Tensor & self, bool non_blocking, c10::optional<at::MemoryFormat> memory_format, at::Tensor & out);
include/ATen/ops/split_with_sizes_copy_native.h:TORCH_API void split_with_sizes_copy_out(const at::Tensor & self, at::IntArrayRef split_sizes, int64_t dim, at::TensorList out);
include/ATen/ops/split_with_sizes_copy_native.h:TORCH_API ::std::vector<at::Tensor> split_with_sizes_copy_symint(const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim=0);
include/ATen/ops/indices_copy.h:#include <ATen/ops/indices_copy_ops.h>
include/ATen/ops/indices_copy.h:inline at::Tensor & indices_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/indices_copy.h:    return at::_ops::indices_copy_out::call(self, out);
include/ATen/ops/indices_copy.h:inline at::Tensor & indices_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/indices_copy.h:    return at::_ops::indices_copy_out::call(self, out);
include/ATen/ops/narrow_copy_cpu_dispatch.h:TORCH_API at::Tensor narrow_copy_symint(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length);
include/ATen/ops/narrow_copy_cpu_dispatch.h:TORCH_API at::Tensor & narrow_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, int64_t start, int64_t length);
include/ATen/ops/narrow_copy_cpu_dispatch.h:TORCH_API at::Tensor & narrow_copy_outf(const at::Tensor & self, int64_t dim, int64_t start, int64_t length, at::Tensor & out);
include/ATen/ops/narrow_copy_cpu_dispatch.h:TORCH_API at::Tensor & narrow_copy_symint_out(at::Tensor & out, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length);
include/ATen/ops/narrow_copy_cpu_dispatch.h:TORCH_API at::Tensor & narrow_copy_symint_outf(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length, at::Tensor & out);
include/ATen/ops/narrow_copy.h:#include <ATen/ops/narrow_copy_ops.h>
include/ATen/ops/narrow_copy.h:inline at::Tensor narrow_copy_symint(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length) {
include/ATen/ops/narrow_copy.h:inline at::Tensor & narrow_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, int64_t start, int64_t length) {
include/ATen/ops/narrow_copy.h:    return at::_ops::narrow_copy_out::call(self, dim, start, length, out);
include/ATen/ops/narrow_copy.h:  at::Tensor & narrow_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, int64_t start, int64_t length) {
include/ATen/ops/narrow_copy.h:    return at::_ops::narrow_copy_out::call(self, dim, start, length, out);
include/ATen/ops/narrow_copy.h:inline at::Tensor & narrow_copy_outf(const at::Tensor & self, int64_t dim, int64_t start, int64_t length, at::Tensor & out) {
include/ATen/ops/narrow_copy.h:    return at::_ops::narrow_copy_out::call(self, dim, start, length, out);
include/ATen/ops/narrow_copy.h:  at::Tensor & narrow_copy_outf(const at::Tensor & self, int64_t dim, int64_t start, int64_t length, at::Tensor & out) {
include/ATen/ops/narrow_copy.h:    return at::_ops::narrow_copy_out::call(self, dim, start, length, out);
include/ATen/ops/narrow_copy.h:inline at::Tensor & narrow_copy_symint_out(at::Tensor & out, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length) {
include/ATen/ops/narrow_copy.h:    return at::_ops::narrow_copy_out::call(self, dim, start, length, out);
include/ATen/ops/narrow_copy.h:  at::Tensor & narrow_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length) {
include/ATen/ops/narrow_copy.h:    return at::_ops::narrow_copy_out::call(self, dim, start, length, out);
include/ATen/ops/narrow_copy.h:inline at::Tensor & narrow_copy_symint_outf(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length, at::Tensor & out) {
include/ATen/ops/narrow_copy.h:    return at::_ops::narrow_copy_out::call(self, dim, start, length, out);
include/ATen/ops/narrow_copy.h:  at::Tensor & narrow_copy_outf(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length, at::Tensor & out) {
include/ATen/ops/narrow_copy.h:    return at::_ops::narrow_copy_out::call(self, dim, start, length, out);
include/ATen/ops/transpose_copy.h:#include <ATen/ops/transpose_copy_ops.h>
include/ATen/ops/transpose_copy.h:    return at::_ops::transpose_copy_int::call(self, dim0, dim1);
include/ATen/ops/transpose_copy.h:inline at::Tensor & transpose_copy_out(at::Tensor & out, const at::Tensor & self, int64_t dim0, int64_t dim1) {
include/ATen/ops/transpose_copy.h:    return at::_ops::transpose_copy_int_out::call(self, dim0, dim1, out);
include/ATen/ops/transpose_copy.h:inline at::Tensor & transpose_copy_outf(const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out) {
include/ATen/ops/transpose_copy.h:    return at::_ops::transpose_copy_int_out::call(self, dim0, dim1, out);
include/ATen/ops/t_copy_ops.h:struct TORCH_API t_copy_out {
include/ATen/ops/_fw_primal_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _fw_primal_copy_out(at::Tensor & out, const at::Tensor & self, int64_t level);
include/ATen/ops/_fw_primal_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & _fw_primal_copy_outf(const at::Tensor & self, int64_t level, at::Tensor & out);
include/ATen/ops/view_as_real_copy_native.h:TORCH_API at::Tensor & view_as_real_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_test_autograd_multiple_dispatch_view_copy.h:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_ops.h>
include/ATen/ops/_test_autograd_multiple_dispatch_view_copy.h:inline at::Tensor & _test_autograd_multiple_dispatch_view_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/_test_autograd_multiple_dispatch_view_copy.h:    return at::_ops::_test_autograd_multiple_dispatch_view_copy_out::call(self, out);
include/ATen/ops/_test_autograd_multiple_dispatch_view_copy.h:inline at::Tensor & _test_autograd_multiple_dispatch_view_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/_test_autograd_multiple_dispatch_view_copy.h:    return at::_ops::_test_autograd_multiple_dispatch_view_copy_out::call(self, out);
include/ATen/ops/split_copy_compositeexplicitautograd_dispatch.h:TORCH_API void split_copy_out(at::TensorList out, const at::Tensor & self, int64_t split_size, int64_t dim=0);
include/ATen/ops/split_copy_compositeexplicitautograd_dispatch.h:TORCH_API void split_copy_outf(const at::Tensor & self, int64_t split_size, int64_t dim, at::TensorList out);
include/ATen/ops/split_copy_compositeexplicitautograd_dispatch.h:TORCH_API void split_copy_symint_out(at::TensorList out, const at::Tensor & self, c10::SymInt split_size, int64_t dim=0);
include/ATen/ops/split_copy_compositeexplicitautograd_dispatch.h:TORCH_API void split_copy_symint_outf(const at::Tensor & self, c10::SymInt split_size, int64_t dim, at::TensorList out);
include/ATen/ops/values_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & values_copy_out(at::Tensor & out, const at::Tensor & self);
include/ATen/ops/values_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & values_copy_outf(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/unsqueeze_copy_native.h:TORCH_API at::Tensor & unsqueeze_copy_out(const at::Tensor & self, int64_t dim, at::Tensor & out);
include/ATen/ops/split_with_sizes_copy_compositeexplicitautogradnonfunctional_dispatch.h:TORCH_API ::std::vector<at::Tensor> split_with_sizes_copy_symint(const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim=0);
include/ATen/ops/_to_copy_native.h:TORCH_API at::Tensor & _to_copy_out(const at::Tensor & self, bool non_blocking, c10::optional<at::MemoryFormat> memory_format, at::Tensor & out);
include/ATen/ops/_to_copy_native.h:TORCH_API at::Tensor _to_copy_nested(const at::Tensor & self, c10::optional<at::ScalarType> dtype={}, c10::optional<at::Layout> layout={}, c10::optional<at::Device> device={}, c10::optional<bool> pin_memory={}, bool non_blocking=false, c10::optional<at::MemoryFormat> memory_format=c10::nullopt);
include/ATen/ops/expand_copy_ops.h:struct TORCH_API expand_copy_out {
include/ATen/ops/unbind_copy_compositeexplicitautograd_dispatch.h:TORCH_API void unbind_copy_out(at::TensorList out, const at::Tensor & self, int64_t dim=0);
include/ATen/ops/unbind_copy_compositeexplicitautograd_dispatch.h:TORCH_API void unbind_copy_outf(const at::Tensor & self, int64_t dim, at::TensorList out);
include/ATen/ops/_copy_from_and_resize_ops.h:struct TORCH_API _copy_from_and_resize {
include/ATen/ops/_copy_from_and_resize_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::_copy_from_and_resize")
include/ATen/ops/_copy_from_and_resize_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "_copy_from_and_resize(Tensor self, Tensor dst) -> Tensor")
include/ATen/ops/_copy_from_and_resize_ops.h:struct TORCH_API _copy_from_and_resize_out {
include/ATen/ops/_copy_from_and_resize_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, "aten::_copy_from_and_resize")
include/ATen/ops/_copy_from_and_resize_ops.h:  STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, "_copy_from_and_resize.out(Tensor self, Tensor dst, *, Tensor(a!) out) -> Tensor(a!)")
include/ATen/ops/values_copy_native.h:TORCH_API at::Tensor & values_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/slice_copy_compositeexplicitautogradnonfunctional_dispatch.h:TORCH_API at::Tensor slice_copy_symint(const at::Tensor & self, int64_t dim=0, c10::optional<c10::SymInt> start=c10::nullopt, c10::optional<c10::SymInt> end=c10::nullopt, c10::SymInt step=1);
include/ATen/ops/permute_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & permute_copy_out(at::Tensor & out, const at::Tensor & self, at::IntArrayRef dims);
include/ATen/ops/permute_copy_compositeexplicitautograd_dispatch.h:TORCH_API at::Tensor & permute_copy_outf(const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out);
include/ATen/ops/narrow_copy_native.h:TORCH_API at::Tensor narrow_copy_dense_cpu(const at::Tensor & self, int64_t dim, int64_t start, int64_t length);
include/ATen/ops/narrow_copy_native.h:TORCH_API at::Tensor & narrow_copy_dense_cpu_out(const at::Tensor & self, int64_t dim, int64_t start, int64_t length, at::Tensor & out);
include/ATen/ops/narrow_copy_native.h:TORCH_API at::Tensor narrow_copy_sparse(const at::Tensor & self, int64_t dim, int64_t start, int64_t length);
include/ATen/ops/narrow_copy_native.h:TORCH_API at::Tensor narrow_copy_dense_symint(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length);
include/ATen/ops/_neg_view_copy_native.h:TORCH_API at::Tensor & _neg_view_copy_out(const at::Tensor & self, at::Tensor & out);
include/ATen/ops/_conj_copy.h:#include <ATen/ops/_conj_copy_ops.h>
include/ATen/ops/_conj_copy.h:inline at::Tensor & _conj_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/_conj_copy.h:    return at::_ops::_conj_copy_out::call(self, out);
include/ATen/ops/_conj_copy.h:inline at::Tensor & _conj_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/_conj_copy.h:    return at::_ops::_conj_copy_out::call(self, out);
include/ATen/ops/slice_copy_ops.h:struct TORCH_API slice_copy_Tensor {
include/ATen/ops/slice_copy_ops.h:struct TORCH_API slice_copy_Tensor_out {
include/ATen/ops/split_with_sizes_copy_compositeexplicitautograd_dispatch.h:TORCH_API void split_with_sizes_copy_out(at::TensorList out, const at::Tensor & self, at::IntArrayRef split_sizes, int64_t dim=0);
include/ATen/ops/split_with_sizes_copy_compositeexplicitautograd_dispatch.h:TORCH_API void split_with_sizes_copy_outf(const at::Tensor & self, at::IntArrayRef split_sizes, int64_t dim, at::TensorList out);
include/ATen/ops/split_with_sizes_copy_compositeexplicitautograd_dispatch.h:TORCH_API void split_with_sizes_copy_symint_out(at::TensorList out, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim=0);
include/ATen/ops/split_with_sizes_copy_compositeexplicitautograd_dispatch.h:TORCH_API void split_with_sizes_copy_symint_outf(const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim, at::TensorList out);
include/ATen/ops/ccol_indices_copy.h:#include <ATen/ops/ccol_indices_copy_ops.h>
include/ATen/ops/ccol_indices_copy.h:inline at::Tensor & ccol_indices_copy_out(at::Tensor & out, const at::Tensor & self) {
include/ATen/ops/ccol_indices_copy.h:    return at::_ops::ccol_indices_copy_out::call(self, out);
include/ATen/ops/ccol_indices_copy.h:inline at::Tensor & ccol_indices_copy_outf(const at::Tensor & self, at::Tensor & out) {
include/ATen/ops/ccol_indices_copy.h:    return at::_ops::ccol_indices_copy_out::call(self, out);
include/ATen/metal/Context.h:  virtual at::Tensor& metal_copy_(at::Tensor& self, const at::Tensor& src)
include/ATen/metal/Context.h:at::Tensor& metal_copy_(at::Tensor& self, const at::Tensor& src);
include/ATen/CUDAFunctions_inl.h:#include <ATen/ops/index_copy_cuda_dispatch.h>
include/ATen/RegistrationDeclarations.h:Tensor & copy_(Tensor & self, const Tensor & src, bool non_blocking); // {"schema": "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor _copy_from(const Tensor & self, const Tensor & dst, bool non_blocking); // {"schema": "aten::_copy_from(Tensor self, Tensor dst, bool non_blocking=False) -> Tensor", "dispatch": "True", "default": "False"}
include/ATen/RegistrationDeclarations.h:Tensor _copy_from_and_resize(const Tensor & self, const Tensor & dst); // {"schema": "aten::_copy_from_and_resize(Tensor self, Tensor dst) -> Tensor", "dispatch": "True", "default": "False"}
include/ATen/RegistrationDeclarations.h:Tensor & index_copy_out(const Tensor & self, int64_t dim, const Tensor & index, const Tensor & source, Tensor & out); // {"schema": "aten::index_copy.out(Tensor self, int dim, Tensor index, Tensor source, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "False"}
include/ATen/RegistrationDeclarations.h:Tensor & index_copy_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & source); // {"schema": "aten::index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & index_copy_(Tensor & self, Dimname dim, const Tensor & index, const Tensor & source); // {"schema": "aten::index_copy_.dimname(Tensor(a!) self, Dimname dim, Tensor index, Tensor source) -> Tensor(a!)", "dispatch": "False", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & narrow_copy_out(const Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length, Tensor & out); // {"schema": "aten::narrow_copy.out(Tensor self, int dim, SymInt start, SymInt length, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "False"}
include/ATen/RegistrationDeclarations.h:bool _has_compatible_shallow_copy_type(const Tensor & self, const Tensor & from); // {"schema": "aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool", "dispatch": "False", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & copy_sparse_to_sparse_(Tensor & self, const Tensor & src, bool non_blocking); // {"schema": "aten::copy_sparse_to_sparse_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)", "dispatch": "True", "default": "False"}
include/ATen/RegistrationDeclarations.h:Tensor & _fw_primal_copy_out(const Tensor & self, int64_t level, Tensor & out); // {"schema": "aten::_fw_primal_copy.out(Tensor self, int level, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _make_dual_copy_out(const Tensor & primal, const Tensor & tangent, int64_t level, Tensor & out); // {"schema": "aten::_make_dual_copy.out(Tensor primal, Tensor tangent, int level, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & view_as_real_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::view_as_real_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & view_as_complex_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::view_as_complex_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _conj_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::_conj_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _neg_view_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::_neg_view_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & as_strided_copy_out(const Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, Tensor & out); // {"schema": "aten::as_strided_copy.out(Tensor self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _sparse_broadcast_to_copy_out(const Tensor & self, IntArrayRef size, Tensor & out); // {"schema": "aten::_sparse_broadcast_to_copy.out(Tensor self, int[] size, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & diagonal_copy_out(const Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, Tensor & out); // {"schema": "aten::diagonal_copy.out(Tensor self, int offset=0, int dim1=0, int dim2=1, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & expand_copy_out(const Tensor & self, c10::SymIntArrayRef size, bool implicit, Tensor & out); // {"schema": "aten::expand_copy.out(Tensor self, SymInt[] size, *, bool implicit=False, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & permute_copy_out(const Tensor & self, IntArrayRef dims, Tensor & out); // {"schema": "aten::permute_copy.out(Tensor self, int[] dims, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _reshape_alias_copy_out(const Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, Tensor & out); // {"schema": "aten::_reshape_alias_copy.out(Tensor self, SymInt[] size, SymInt[] stride, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & select_copy_out(const Tensor & self, int64_t dim, c10::SymInt index, Tensor & out); // {"schema": "aten::select_copy.int_out(Tensor self, int dim, SymInt index, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & detach_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::detach_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & slice_copy_out(const Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, Tensor & out); // {"schema": "aten::slice_copy.Tensor_out(Tensor self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:void split_copy_out(const Tensor & self, c10::SymInt split_size, int64_t dim, TensorList out); // {"schema": "aten::split_copy.Tensor_out(Tensor self, SymInt split_size, int dim=0, *, Tensor(a!)[] out) -> ()", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:void split_with_sizes_copy_out(const Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim, TensorList out); // {"schema": "aten::split_with_sizes_copy.out(Tensor self, SymInt[] split_sizes, int dim=0, *, Tensor(a!)[] out) -> ()", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & squeeze_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::squeeze_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & squeeze_copy_out(const Tensor & self, int64_t dim, Tensor & out); // {"schema": "aten::squeeze_copy.dim_out(Tensor self, int dim, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & squeeze_copy_out(const Tensor & self, IntArrayRef dim, Tensor & out); // {"schema": "aten::squeeze_copy.dims_out(Tensor self, int[] dim, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & t_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::t_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & transpose_copy_out(const Tensor & self, int64_t dim0, int64_t dim1, Tensor & out); // {"schema": "aten::transpose_copy.int_out(Tensor self, int dim0, int dim1, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & unsqueeze_copy_out(const Tensor & self, int64_t dim, Tensor & out); // {"schema": "aten::unsqueeze_copy.out(Tensor self, int dim, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _indices_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::_indices_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _values_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::_values_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & indices_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::indices_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & values_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::values_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & crow_indices_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::crow_indices_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & col_indices_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::col_indices_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:void unbind_copy_out(const Tensor & self, int64_t dim, TensorList out); // {"schema": "aten::unbind_copy.int_out(Tensor self, int dim=0, *, Tensor(a!)[] out) -> ()", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & view_copy_out(const Tensor & self, c10::SymIntArrayRef size, Tensor & out); // {"schema": "aten::view_copy.out(Tensor self, SymInt[] size, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & view_copy_out(const Tensor & self, ScalarType dtype, Tensor & out); // {"schema": "aten::view_copy.dtype_out(Tensor self, ScalarType dtype, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & unfold_copy_out(const Tensor & self, int64_t dimension, int64_t size, int64_t step, Tensor & out); // {"schema": "aten::unfold_copy.out(Tensor self, int dimension, int size, int step, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & alias_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::alias_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & copy_out(const Tensor & self, const Tensor & src, bool non_blocking, Tensor & out); // {"schema": "aten::copy.out(Tensor self, Tensor src, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _copy_from_out(const Tensor & self, const Tensor & dst, bool non_blocking, Tensor & out); // {"schema": "aten::_copy_from.out(Tensor self, Tensor dst, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _copy_from_and_resize_out(const Tensor & self, const Tensor & dst, Tensor & out); // {"schema": "aten::_copy_from_and_resize.out(Tensor self, Tensor dst, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _nested_view_from_buffer_copy_out(const Tensor & self, const Tensor & nested_size, const Tensor & nested_strides, IntArrayRef offsets, Tensor & out); // {"schema": "aten::_nested_view_from_buffer_copy.out(Tensor self, Tensor nested_size, Tensor nested_strides, int[] offsets, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & copy_sparse_to_sparse_out(const Tensor & self, const Tensor & src, bool non_blocking, Tensor & out); // {"schema": "aten::copy_sparse_to_sparse.out(Tensor self, Tensor src, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor copy_sparse_to_sparse(const Tensor & self, const Tensor & src, bool non_blocking); // {"schema": "aten::copy_sparse_to_sparse(Tensor self, Tensor src, bool non_blocking=False) -> Tensor", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _to_copy_out(const Tensor & self, bool non_blocking, c10::optional<MemoryFormat> memory_format, Tensor & out); // {"schema": "aten::_to_copy.out(Tensor self, *, bool non_blocking=False, MemoryFormat? memory_format=None, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & lift_fresh_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::lift_fresh_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & _test_autograd_multiple_dispatch_view_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::_test_autograd_multiple_dispatch_view_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & ccol_indices_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::ccol_indices_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/RegistrationDeclarations.h:Tensor & row_indices_copy_out(const Tensor & self, Tensor & out); // {"schema": "aten::row_indices_copy.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)", "dispatch": "True", "default": "True"}
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/_conj_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/_fw_primal_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/_indices_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/_make_dual_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/_neg_view_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/_nested_view_from_buffer_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/_reshape_alias_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/_sparse_broadcast_to_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/_test_autograd_multiple_dispatch_view_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/_values_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/alias_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/as_strided_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/ccol_indices_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/col_indices_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/crow_indices_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/detach_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/diagonal_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/expand_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/index_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/indices_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/lift_fresh_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/narrow_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/permute_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/row_indices_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/select_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/slice_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/split_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/split_with_sizes_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/squeeze_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/t_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/transpose_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/unbind_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/unfold_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/unsqueeze_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/values_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/view_as_complex_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/view_as_real_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/CompositeExplicitAutogradNonFunctionalFunctions_inl.h:#include <ATen/ops/view_copy_compositeexplicitautogradnonfunctional_dispatch.h>
include/ATen/SparseTensorUtils.h:inline void copy_into_sparse(
include/ATen/TensorSubclassLikeUtils.h://    >>> torch.zeros(input.sizes(), grad.options()).diag().copy_(input)
include/ATen/TensorIndexing.h:// - `void copy_to(...)`
include/ATen/TensorIndexing.h:static inline void copy_to(const Tensor& dst, const Tensor& src) {
include/ATen/TensorIndexing.h:    dst.copy_(src);
include/ATen/TensorIndexing.h:  dst.copy_(*b_src);
include/ATen/TensorIndexing.h:      copy_to(self, value);
include/ATen/TensorIndexing.h:      copy_to(self.unsqueeze(0), value);
include/ATen/TensorIndexing.h:      copy_to(
include/ATen/TensorIndexing.h:      copy_to(
include/ATen/TensorIndexing.h:    copy_to(sliced, value);
include/ATen/SparseTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/SparseTensorImpl.h:    copy_tensor_metadata(
include/ATen/SparseTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/SparseTensorImpl.h:    copy_tensor_metadata(
include/ATen/SparseTensorImpl.h:  void shallow_copy_from(const c10::intrusive_ptr<TensorImpl>& impl) override {
include/ATen/SparseTensorImpl.h:    AT_ASSERT(has_compatible_shallow_copy_type(impl->key_set()));
include/ATen/SparseTensorImpl.h:    copy_tensor_metadata(
include/ATen/SparseTensorImpl.h:  static void copy_tensor_metadata(
include/ATen/SparseTensorImpl.h:    TensorImpl::copy_tensor_metadata(
include/ATen/RedispatchFunctions.h:    // aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)
include/ATen/RedispatchFunctions.h:    inline at::Tensor & copy_(c10::DispatchKeySet dispatchKeySet, at::Tensor & self, const at::Tensor & src, bool non_blocking=false) {
include/ATen/RedispatchFunctions.h:        return at::_ops::copy_::redispatch(dispatchKeySet, self, src, non_blocking);
include/ATen/RedispatchFunctions.h:    // aten::_copy_from(Tensor self, Tensor dst, bool non_blocking=False) -> Tensor
include/ATen/RedispatchFunctions.h:    inline at::Tensor _copy_from(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, const at::Tensor & dst, bool non_blocking=false) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_copy_from::redispatch(dispatchKeySet, self, dst, non_blocking);
include/ATen/RedispatchFunctions.h:    // aten::_copy_from_and_resize(Tensor self, Tensor dst) -> Tensor
include/ATen/RedispatchFunctions.h:    inline at::Tensor _copy_from_and_resize(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, const at::Tensor & dst) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_copy_from_and_resize::redispatch(dispatchKeySet, self, dst);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & index_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
include/ATen/RedispatchFunctions.h:        return at::_ops::index_copy_out::redispatch(dispatchKeySet, self, dim, index, source, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & index_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::index_copy_out::redispatch(dispatchKeySet, self, dim, index, source, out);
include/ATen/RedispatchFunctions.h:    // aten::index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -> Tensor(a!)
include/ATen/RedispatchFunctions.h:    inline at::Tensor & index_copy_(c10::DispatchKeySet dispatchKeySet, at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source) {
include/ATen/RedispatchFunctions.h:        return at::_ops::index_copy_::redispatch(dispatchKeySet, self, dim, index, source);
include/ATen/RedispatchFunctions.h:    // aten::index_copy_.dimname(Tensor(a!) self, Dimname dim, Tensor index, Tensor source) -> Tensor(a!)
include/ATen/RedispatchFunctions.h:    inline at::Tensor & index_copy_(c10::DispatchKeySet dispatchKeySet, at::Tensor & self, at::Dimname dim, const at::Tensor & index, const at::Tensor & source) {
include/ATen/RedispatchFunctions.h:        return at::_ops::index_copy__dimname::redispatch(dispatchKeySet, self, dim, index, source);
include/ATen/RedispatchFunctions.h:        return at::_ops::index_copy_dimname::redispatch(dispatchKeySet, self, dim, index, source);
include/ATen/RedispatchFunctions.h:    inline at::Tensor narrow_copy_symint(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length) {
include/ATen/RedispatchFunctions.h:    inline at::Tensor & narrow_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dim, int64_t start, int64_t length) {
include/ATen/RedispatchFunctions.h:        return at::_ops::narrow_copy_out::redispatch(dispatchKeySet, self, dim, start, length, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & narrow_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, int64_t start, int64_t length, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::narrow_copy_out::redispatch(dispatchKeySet, self, dim, start, length, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & narrow_copy_symint_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length) {
include/ATen/RedispatchFunctions.h:        return at::_ops::narrow_copy_out::redispatch(dispatchKeySet, self, dim, start, length, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & narrow_copy_symint_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::narrow_copy_out::redispatch(dispatchKeySet, self, dim, start, length, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor _reshape_copy_symint(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef size) {
include/ATen/RedispatchFunctions.h:    // aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool
include/ATen/RedispatchFunctions.h:    inline bool _has_compatible_shallow_copy_type(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, const at::Tensor & from) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_has_compatible_shallow_copy_type::redispatch(dispatchKeySet, self, from);
include/ATen/RedispatchFunctions.h:    // aten::copy_sparse_to_sparse_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)
include/ATen/RedispatchFunctions.h:    inline at::Tensor & copy_sparse_to_sparse_(c10::DispatchKeySet dispatchKeySet, at::Tensor & self, const at::Tensor & src, bool non_blocking=false) {
include/ATen/RedispatchFunctions.h:        return at::_ops::copy_sparse_to_sparse_::redispatch(dispatchKeySet, self, src, non_blocking);
include/ATen/RedispatchFunctions.h:    inline at::Tensor as_strided_copy_symint(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset=c10::nullopt) {
include/ATen/RedispatchFunctions.h:    inline at::Tensor expand_copy_symint(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit=false) {
include/ATen/RedispatchFunctions.h:    inline at::Tensor _reshape_alias_copy_symint(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) {
include/ATen/RedispatchFunctions.h:        return at::_ops::select_copy_int::redispatch(dispatchKeySet, self, dim, index);
include/ATen/RedispatchFunctions.h:    inline at::Tensor select_copy_symint(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, c10::SymInt index) {
include/ATen/RedispatchFunctions.h:        return at::_ops::select_copy_int::redispatch(dispatchKeySet, self, dim, index);
include/ATen/RedispatchFunctions.h:        return at::_ops::slice_copy_Tensor::redispatch(dispatchKeySet, self, dim, start.has_value() ? c10::make_optional(c10::SymInt(*start)) : c10::nullopt, end.has_value() ? c10::make_optional(c10::SymInt(*end)) : c10::nullopt, step);
include/ATen/RedispatchFunctions.h:    inline at::Tensor slice_copy_symint(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim=0, c10::optional<c10::SymInt> start=c10::nullopt, c10::optional<c10::SymInt> end=c10::nullopt, c10::SymInt step=1) {
include/ATen/RedispatchFunctions.h:        return at::_ops::slice_copy_Tensor::redispatch(dispatchKeySet, self, dim, start, end, step);
include/ATen/RedispatchFunctions.h:        return at::_ops::split_copy_Tensor::redispatch(dispatchKeySet, self, split_size, dim);
include/ATen/RedispatchFunctions.h:    inline ::std::vector<at::Tensor> split_copy_symint(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymInt split_size, int64_t dim=0) {
include/ATen/RedispatchFunctions.h:        return at::_ops::split_copy_Tensor::redispatch(dispatchKeySet, self, split_size, dim);
include/ATen/RedispatchFunctions.h:    inline ::std::vector<at::Tensor> split_with_sizes_copy_symint(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim=0) {
include/ATen/RedispatchFunctions.h:        return at::_ops::squeeze_copy_dim::redispatch(dispatchKeySet, self, dim);
include/ATen/RedispatchFunctions.h:        return at::_ops::squeeze_copy_dims::redispatch(dispatchKeySet, self, dim);
include/ATen/RedispatchFunctions.h:        return at::_ops::transpose_copy_int::redispatch(dispatchKeySet, self, dim0, dim1);
include/ATen/RedispatchFunctions.h:        return at::_ops::unbind_copy_int::redispatch(dispatchKeySet, self, dim);
include/ATen/RedispatchFunctions.h:    inline at::Tensor view_copy_symint(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef size) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_copy_dtype::redispatch(dispatchKeySet, self, dtype);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _fw_primal_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t level) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_fw_primal_copy_out::redispatch(dispatchKeySet, self, level, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _fw_primal_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t level, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_fw_primal_copy_out::redispatch(dispatchKeySet, self, level, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _make_dual_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & primal, const at::Tensor & tangent, int64_t level) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_make_dual_copy_out::redispatch(dispatchKeySet, primal, tangent, level, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _make_dual_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & primal, const at::Tensor & tangent, int64_t level, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_make_dual_copy_out::redispatch(dispatchKeySet, primal, tangent, level, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & view_as_real_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_as_real_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & view_as_real_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_as_real_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & view_as_complex_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_as_complex_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & view_as_complex_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_as_complex_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _conj_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_conj_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _conj_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_conj_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _neg_view_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_neg_view_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _neg_view_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_neg_view_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & as_strided_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, c10::optional<int64_t> storage_offset=c10::nullopt) {
include/ATen/RedispatchFunctions.h:        return at::_ops::as_strided_copy_out::redispatch(dispatchKeySet, self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? c10::make_optional(c10::SymInt(*storage_offset)) : c10::nullopt, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & as_strided_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, c10::optional<int64_t> storage_offset, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::as_strided_copy_out::redispatch(dispatchKeySet, self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? c10::make_optional(c10::SymInt(*storage_offset)) : c10::nullopt, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & as_strided_copy_symint_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset=c10::nullopt) {
include/ATen/RedispatchFunctions.h:        return at::_ops::as_strided_copy_out::redispatch(dispatchKeySet, self, size, stride, storage_offset, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & as_strided_copy_symint_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::as_strided_copy_out::redispatch(dispatchKeySet, self, size, stride, storage_offset, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _sparse_broadcast_to_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, at::IntArrayRef size) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_sparse_broadcast_to_copy_out::redispatch(dispatchKeySet, self, size, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _sparse_broadcast_to_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::IntArrayRef size, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_sparse_broadcast_to_copy_out::redispatch(dispatchKeySet, self, size, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & diagonal_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t offset=0, int64_t dim1=0, int64_t dim2=1) {
include/ATen/RedispatchFunctions.h:        return at::_ops::diagonal_copy_out::redispatch(dispatchKeySet, self, offset, dim1, dim2, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & diagonal_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t offset, int64_t dim1, int64_t dim2, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::diagonal_copy_out::redispatch(dispatchKeySet, self, offset, dim1, dim2, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & expand_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, bool implicit=false) {
include/ATen/RedispatchFunctions.h:        return at::_ops::expand_copy_out::redispatch(dispatchKeySet, self, c10::fromIntArrayRefSlow(size), implicit, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & expand_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::IntArrayRef size, bool implicit, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::expand_copy_out::redispatch(dispatchKeySet, self, c10::fromIntArrayRefSlow(size), implicit, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & expand_copy_symint_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit=false) {
include/ATen/RedispatchFunctions.h:        return at::_ops::expand_copy_out::redispatch(dispatchKeySet, self, size, implicit, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & expand_copy_symint_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef size, bool implicit, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::expand_copy_out::redispatch(dispatchKeySet, self, size, implicit, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & permute_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, at::IntArrayRef dims) {
include/ATen/RedispatchFunctions.h:        return at::_ops::permute_copy_out::redispatch(dispatchKeySet, self, dims, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & permute_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::IntArrayRef dims, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::permute_copy_out::redispatch(dispatchKeySet, self, dims, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _reshape_alias_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_reshape_alias_copy_out::redispatch(dispatchKeySet, self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _reshape_alias_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::IntArrayRef size, at::IntArrayRef stride, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_reshape_alias_copy_out::redispatch(dispatchKeySet, self, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _reshape_alias_copy_symint_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_reshape_alias_copy_out::redispatch(dispatchKeySet, self, size, stride, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _reshape_alias_copy_symint_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_reshape_alias_copy_out::redispatch(dispatchKeySet, self, size, stride, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & select_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dim, int64_t index) {
include/ATen/RedispatchFunctions.h:        return at::_ops::select_copy_int_out::redispatch(dispatchKeySet, self, dim, index, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & select_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, int64_t index, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::select_copy_int_out::redispatch(dispatchKeySet, self, dim, index, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & select_copy_symint_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dim, c10::SymInt index) {
include/ATen/RedispatchFunctions.h:        return at::_ops::select_copy_int_out::redispatch(dispatchKeySet, self, dim, index, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & select_copy_symint_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, c10::SymInt index, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::select_copy_int_out::redispatch(dispatchKeySet, self, dim, index, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & detach_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::detach_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & detach_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::detach_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & slice_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dim=0, c10::optional<int64_t> start=c10::nullopt, c10::optional<int64_t> end=c10::nullopt, int64_t step=1) {
include/ATen/RedispatchFunctions.h:        return at::_ops::slice_copy_Tensor_out::redispatch(dispatchKeySet, self, dim, start.has_value() ? c10::make_optional(c10::SymInt(*start)) : c10::nullopt, end.has_value() ? c10::make_optional(c10::SymInt(*end)) : c10::nullopt, step, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & slice_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, c10::optional<int64_t> start, c10::optional<int64_t> end, int64_t step, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::slice_copy_Tensor_out::redispatch(dispatchKeySet, self, dim, start.has_value() ? c10::make_optional(c10::SymInt(*start)) : c10::nullopt, end.has_value() ? c10::make_optional(c10::SymInt(*end)) : c10::nullopt, step, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & slice_copy_symint_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dim=0, c10::optional<c10::SymInt> start=c10::nullopt, c10::optional<c10::SymInt> end=c10::nullopt, c10::SymInt step=1) {
include/ATen/RedispatchFunctions.h:        return at::_ops::slice_copy_Tensor_out::redispatch(dispatchKeySet, self, dim, start, end, step, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & slice_copy_symint_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::slice_copy_Tensor_out::redispatch(dispatchKeySet, self, dim, start, end, step, out);
include/ATen/RedispatchFunctions.h:    inline void split_copy_out(c10::DispatchKeySet dispatchKeySet, at::TensorList out, const at::Tensor & self, int64_t split_size, int64_t dim=0) {
include/ATen/RedispatchFunctions.h:        return at::_ops::split_copy_Tensor_out::redispatch(dispatchKeySet, self, split_size, dim, out);
include/ATen/RedispatchFunctions.h:    inline void split_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t split_size, int64_t dim, at::TensorList out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::split_copy_Tensor_out::redispatch(dispatchKeySet, self, split_size, dim, out);
include/ATen/RedispatchFunctions.h:    inline void split_copy_symint_out(c10::DispatchKeySet dispatchKeySet, at::TensorList out, const at::Tensor & self, c10::SymInt split_size, int64_t dim=0) {
include/ATen/RedispatchFunctions.h:        return at::_ops::split_copy_Tensor_out::redispatch(dispatchKeySet, self, split_size, dim, out);
include/ATen/RedispatchFunctions.h:    inline void split_copy_symint_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymInt split_size, int64_t dim, at::TensorList out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::split_copy_Tensor_out::redispatch(dispatchKeySet, self, split_size, dim, out);
include/ATen/RedispatchFunctions.h:    inline void split_with_sizes_copy_out(c10::DispatchKeySet dispatchKeySet, at::TensorList out, const at::Tensor & self, at::IntArrayRef split_sizes, int64_t dim=0) {
include/ATen/RedispatchFunctions.h:        return at::_ops::split_with_sizes_copy_out::redispatch(dispatchKeySet, self, c10::fromIntArrayRefSlow(split_sizes), dim, out);
include/ATen/RedispatchFunctions.h:    inline void split_with_sizes_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::IntArrayRef split_sizes, int64_t dim, at::TensorList out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::split_with_sizes_copy_out::redispatch(dispatchKeySet, self, c10::fromIntArrayRefSlow(split_sizes), dim, out);
include/ATen/RedispatchFunctions.h:    inline void split_with_sizes_copy_symint_out(c10::DispatchKeySet dispatchKeySet, at::TensorList out, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim=0) {
include/ATen/RedispatchFunctions.h:        return at::_ops::split_with_sizes_copy_out::redispatch(dispatchKeySet, self, split_sizes, dim, out);
include/ATen/RedispatchFunctions.h:    inline void split_with_sizes_copy_symint_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef split_sizes, int64_t dim, at::TensorList out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::split_with_sizes_copy_out::redispatch(dispatchKeySet, self, split_sizes, dim, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & squeeze_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::squeeze_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & squeeze_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::squeeze_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & squeeze_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dim) {
include/ATen/RedispatchFunctions.h:        return at::_ops::squeeze_copy_dim_out::redispatch(dispatchKeySet, self, dim, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & squeeze_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::squeeze_copy_dim_out::redispatch(dispatchKeySet, self, dim, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & squeeze_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, at::IntArrayRef dim) {
include/ATen/RedispatchFunctions.h:        return at::_ops::squeeze_copy_dims_out::redispatch(dispatchKeySet, self, dim, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & squeeze_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::IntArrayRef dim, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::squeeze_copy_dims_out::redispatch(dispatchKeySet, self, dim, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & t_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::t_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & t_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::t_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & transpose_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dim0, int64_t dim1) {
include/ATen/RedispatchFunctions.h:        return at::_ops::transpose_copy_int_out::redispatch(dispatchKeySet, self, dim0, dim1, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & transpose_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim0, int64_t dim1, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::transpose_copy_int_out::redispatch(dispatchKeySet, self, dim0, dim1, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & unsqueeze_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dim) {
include/ATen/RedispatchFunctions.h:        return at::_ops::unsqueeze_copy_out::redispatch(dispatchKeySet, self, dim, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & unsqueeze_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::unsqueeze_copy_out::redispatch(dispatchKeySet, self, dim, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _indices_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _indices_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _values_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_values_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _values_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_values_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & indices_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & indices_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & values_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::values_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & values_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::values_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & crow_indices_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::crow_indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & crow_indices_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::crow_indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & col_indices_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::col_indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & col_indices_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::col_indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline void unbind_copy_out(c10::DispatchKeySet dispatchKeySet, at::TensorList out, const at::Tensor & self, int64_t dim=0) {
include/ATen/RedispatchFunctions.h:        return at::_ops::unbind_copy_int_out::redispatch(dispatchKeySet, self, dim, out);
include/ATen/RedispatchFunctions.h:    inline void unbind_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dim, at::TensorList out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::unbind_copy_int_out::redispatch(dispatchKeySet, self, dim, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & view_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, at::IntArrayRef size) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_copy_out::redispatch(dispatchKeySet, self, c10::fromIntArrayRefSlow(size), out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & view_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::IntArrayRef size, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_copy_out::redispatch(dispatchKeySet, self, c10::fromIntArrayRefSlow(size), out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & view_copy_symint_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, c10::SymIntArrayRef size) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_copy_out::redispatch(dispatchKeySet, self, size, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & view_copy_symint_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, c10::SymIntArrayRef size, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_copy_out::redispatch(dispatchKeySet, self, size, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & view_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, at::ScalarType dtype) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_copy_dtype_out::redispatch(dispatchKeySet, self, dtype, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & view_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::ScalarType dtype, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::view_copy_dtype_out::redispatch(dispatchKeySet, self, dtype, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & unfold_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step) {
include/ATen/RedispatchFunctions.h:        return at::_ops::unfold_copy_out::redispatch(dispatchKeySet, self, dimension, size, step, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & unfold_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, int64_t dimension, int64_t size, int64_t step, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::unfold_copy_out::redispatch(dispatchKeySet, self, dimension, size, step, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & alias_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::alias_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & alias_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::alias_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, const at::Tensor & src, bool non_blocking=false) {
include/ATen/RedispatchFunctions.h:        return at::_ops::copy_out::redispatch(dispatchKeySet, self, src, non_blocking, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::copy_out::redispatch(dispatchKeySet, self, src, non_blocking, out);
include/ATen/RedispatchFunctions.h:    // aten::_copy_from.out(Tensor self, Tensor dst, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _copy_from_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, const at::Tensor & dst, bool non_blocking=false) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_copy_from_out::redispatch(dispatchKeySet, self, dst, non_blocking, out);
include/ATen/RedispatchFunctions.h:    // aten::_copy_from.out(Tensor self, Tensor dst, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _copy_from_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, const at::Tensor & dst, bool non_blocking, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_copy_from_out::redispatch(dispatchKeySet, self, dst, non_blocking, out);
include/ATen/RedispatchFunctions.h:    // aten::_copy_from_and_resize.out(Tensor self, Tensor dst, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _copy_from_and_resize_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, const at::Tensor & dst) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_copy_from_and_resize_out::redispatch(dispatchKeySet, self, dst, out);
include/ATen/RedispatchFunctions.h:    // aten::_copy_from_and_resize.out(Tensor self, Tensor dst, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _copy_from_and_resize_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, const at::Tensor & dst, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_copy_from_and_resize_out::redispatch(dispatchKeySet, self, dst, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _nested_view_from_buffer_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_nested_view_from_buffer_copy_out::redispatch(dispatchKeySet, self, nested_size, nested_strides, offsets, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _nested_view_from_buffer_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, const at::Tensor & nested_size, const at::Tensor & nested_strides, at::IntArrayRef offsets, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_nested_view_from_buffer_copy_out::redispatch(dispatchKeySet, self, nested_size, nested_strides, offsets, out);
include/ATen/RedispatchFunctions.h:    // aten::copy_sparse_to_sparse.out(Tensor self, Tensor src, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/RedispatchFunctions.h:    inline at::Tensor & copy_sparse_to_sparse_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, const at::Tensor & src, bool non_blocking=false) {
include/ATen/RedispatchFunctions.h:        return at::_ops::copy_sparse_to_sparse_out::redispatch(dispatchKeySet, self, src, non_blocking, out);
include/ATen/RedispatchFunctions.h:    // aten::copy_sparse_to_sparse.out(Tensor self, Tensor src, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)
include/ATen/RedispatchFunctions.h:    inline at::Tensor & copy_sparse_to_sparse_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, const at::Tensor & src, bool non_blocking, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::copy_sparse_to_sparse_out::redispatch(dispatchKeySet, self, src, non_blocking, out);
include/ATen/RedispatchFunctions.h:    // aten::copy_sparse_to_sparse(Tensor self, Tensor src, bool non_blocking=False) -> Tensor
include/ATen/RedispatchFunctions.h:    inline at::Tensor copy_sparse_to_sparse(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, const at::Tensor & src, bool non_blocking=false) {
include/ATen/RedispatchFunctions.h:        return at::_ops::copy_sparse_to_sparse::redispatch(dispatchKeySet, self, src, non_blocking);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _to_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self, bool non_blocking=false, c10::optional<at::MemoryFormat> memory_format=c10::nullopt) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_to_copy_out::redispatch(dispatchKeySet, self, non_blocking, memory_format, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _to_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, bool non_blocking, c10::optional<at::MemoryFormat> memory_format, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_to_copy_out::redispatch(dispatchKeySet, self, non_blocking, memory_format, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & lift_fresh_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::lift_fresh_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & lift_fresh_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::lift_fresh_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _test_autograd_multiple_dispatch_view_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_test_autograd_multiple_dispatch_view_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & _test_autograd_multiple_dispatch_view_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::_test_autograd_multiple_dispatch_view_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & ccol_indices_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::ccol_indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & ccol_indices_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::ccol_indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & row_indices_copy_out(c10::DispatchKeySet dispatchKeySet, at::Tensor & out, const at::Tensor & self) {
include/ATen/RedispatchFunctions.h:        return at::_ops::row_indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/RedispatchFunctions.h:    inline at::Tensor & row_indices_copy_outf(c10::DispatchKeySet dispatchKeySet, const at::Tensor & self, at::Tensor & out) {
include/ATen/RedispatchFunctions.h:        return at::_ops::row_indices_copy_out::redispatch(dispatchKeySet, self, out);
include/ATen/MetaFunctions_inl.h:#include <ATen/ops/copy_sparse_to_sparse_meta_dispatch.h>
include/ATen/MetaFunctions_inl.h:#include <ATen/ops/index_copy_meta_dispatch.h>
include/ATen/quantized/QTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/quantized/QTensorImpl.h:    copy_tensor_metadata(
include/ATen/quantized/QTensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/ATen/quantized/QTensorImpl.h:    copy_tensor_metadata(
include/ATen/quantized/QTensorImpl.h:  void shallow_copy_from(const c10::intrusive_ptr<TensorImpl>& impl) override {
include/ATen/quantized/QTensorImpl.h:    AT_ASSERT(has_compatible_shallow_copy_type(impl->key_set()));
include/ATen/quantized/QTensorImpl.h:    copy_tensor_metadata(
include/ATen/quantized/QTensorImpl.h:  static void copy_tensor_metadata(
include/ATen/quantized/QTensorImpl.h:    TensorImpl::copy_tensor_metadata(src_q_impl, dest_q_impl, version_counter, allow_tensor_metadata_change);
include/pybind11/cast.h:using type_caster_holder = conditional_t<is_copy_constructible<holder_type>::value,
include/pybind11/cast.h:               negation<is_copy_constructible<T>>,
include/pybind11/detail/type_caster_base.h:                                         void *(*copy_constructor)(const void *),
include/pybind11/detail/type_caster_base.h:                if (copy_constructor) {
include/pybind11/detail/type_caster_base.h:                    valueptr = copy_constructor(src);
include/pybind11/detail/type_caster_base.h:                } else if (copy_constructor) {
include/pybind11/detail/type_caster_base.h:                    valueptr = copy_constructor(src);
include/pybind11/detail/type_caster_base.h:// std::is_copy_constructible isn't quite enough: it lets std::vector<T> (and similar) through when
include/pybind11/detail/type_caster_base.h:struct is_copy_constructible : std::is_copy_constructible<T> {};
include/pybind11/detail/type_caster_base.h:struct is_copy_constructible<
include/pybind11/detail/type_caster_base.h:        all_of<std::is_copy_constructible<Container>,
include/pybind11/detail/type_caster_base.h:    : is_copy_constructible<typename Container::value_type> {};
include/pybind11/detail/type_caster_base.h:struct is_copy_constructible<std::pair<T1, T2>>
include/pybind11/detail/type_caster_base.h:    : all_of<is_copy_constructible<T1>, is_copy_constructible<T2>> {};
include/pybind11/detail/type_caster_base.h:// The same problems arise with std::is_copy_assignable, so we use the same workaround.
include/pybind11/detail/type_caster_base.h:struct is_copy_assignable : std::is_copy_assignable<T> {};
include/pybind11/detail/type_caster_base.h:struct is_copy_assignable<Container,
include/pybind11/detail/type_caster_base.h:                          enable_if_t<all_of<std::is_copy_assignable<Container>,
include/pybind11/detail/type_caster_base.h:    : is_copy_assignable<typename Container::value_type> {};
include/pybind11/detail/type_caster_base.h:struct is_copy_assignable<std::pair<T1, T2>>
include/pybind11/detail/type_caster_base.h:    : all_of<is_copy_assignable<T1>, is_copy_assignable<T2>> {};
include/pybind11/detail/type_caster_base.h:                                         make_copy_constructor(src),
include/pybind11/detail/type_caster_base.h:    template <typename T, typename = enable_if_t<is_copy_constructible<T>::value>>
include/pybind11/detail/type_caster_base.h:    static auto make_copy_constructor(const T *)
include/pybind11/detail/type_caster_base.h:    static Constructor make_copy_constructor(...) { return nullptr; }
include/pybind11/numpy.h:             satisfies_any_of<T, std::has_trivial_copy_constructor, std::has_trivial_copy_assign>,
include/pybind11/stl_bind.h:void vector_if_copy_constructible(const Args &...) {}
include/pybind11/stl_bind.h:void vector_if_copy_constructible(enable_if_t<is_copy_constructible<Vector>::value, Class_> &cl) {
include/pybind11/stl_bind.h:    enable_if_t<is_copy_constructible<typename Vector::value_type>::value, Class_> &cl) {
include/pybind11/stl_bind.h:    detail::vector_if_copy_constructible<Vector, Class_>(cl);
include/pybind11/stl_bind.h:    enable_if_t<is_copy_assignable<typename Map::mapped_type>::value, Class_> &cl) {
include/pybind11/stl_bind.h:void map_assignment(enable_if_t<!is_copy_assignable<typename Map::mapped_type>::value
include/pybind11/stl_bind.h:                                    && is_copy_constructible<typename Map::mapped_type>::value,
include/pybind11/eigen.h:    Array copy_or_ref;
include/pybind11/eigen.h:                    copy_or_ref = std::move(aref);
include/pybind11/eigen.h:            copy_or_ref = std::move(copy);
include/pybind11/eigen.h:            loader_life_support::add_patient(copy_or_ref);
include/pybind11/eigen.h:        map.reset(new MapType(data(copy_or_ref),
include/pybind11/pybind11.h:                                          std::true_type /*is_copy_constructible*/) {
include/pybind11/pybind11.h:                                          std::false_type /*is_copy_constructible*/) {
include/pybind11/pybind11.h:            init_holder_from_existing(v_h, holder_ptr, std::is_copy_constructible<holder_type>());
include/torch/csrc/autograd/variable.h:///     base[1] = var  # i.e., base[1].copy_(var)
include/torch/csrc/autograd/variable.h:///     base.copy_(var)
include/torch/csrc/autograd/variable.h:///     base[1] = var  # i.e., base[1].copy_(var)
include/torch/csrc/autograd/variable.h:///     base.copy_(var)
include/torch/csrc/autograd/variable.h:///     view.copy_(var)
include/torch/csrc/autograd/variable.h:    auto data_impl_copy = data.getIntrusivePtr()->shallow_copy_and_detach(
include/torch/csrc/autograd/variable.h:      auto data_impl_copy = data.getIntrusivePtr()->shallow_copy_and_detach(
include/torch/csrc/autograd/variable.h:    auto data_impl_copy = data.getIntrusivePtr()->shallow_copy_and_detach(
include/torch/csrc/autograd/FunctionsManual.h:void copy_range(variable_list& out, IndexRange range, const at::Tensor& t);
include/torch/csrc/autograd/FunctionsManual.h:void copy_range(
include/torch/csrc/autograd/FunctionsManual.h:Tensor _to_copy_backward(
include/torch/csrc/autograd/VariableTypeUtils.h:// a.copy_(b)
include/torch/csrc/autograd/utils/grad_layout_contract.h:                         .copy_(new_grad));
include/torch/csrc/distributed/c10d/reducer.hpp:  // entry points to `copy_()` each grad's data in/out of the flattened
include/torch/csrc/distributed/c10d/reducer.hpp:  void copy_bucket_to_grad(
include/torch/csrc/distributed/c10d/reducer.hpp:    // `bucket_views_in[i].copy_(grad)` and `grad.copy_(bucket_views_out[i])`
include/torch/csrc/jit/ir/ir.h:  // if copy_blocks is false, it will not recursively clone the nested blocks
include/torch/csrc/jit/ir/ir.h:      bool copy_blocks = true);
include/torch/csrc/jit/runtime/static/impl.h:  bool use_copy_variants{true};
include/torch/csrc/jit/runtime/static/impl.h:  // For the same reason as `use_copy_variants`, the ReplaceWithMaybeCopy pass
include/torch/csrc/jit/runtime/static/impl.h:  bool use_maybe_copy_variants{true};
include/torch/csrc/jit/runtime/static/ops.h:at::Tensor& reshape_copy_out(
include/torch/csrc/jit/runtime/static/ops.h:at::Tensor& to_copy_out(
include/torch/csrc/jit/runtime/static/ops.h:    bool copy_strides,
include/torch/csrc/jit/mobile/flatbuffer_loader.h:// If should_copy_tensor_memory is true, then the returned module will NOT have
include/torch/csrc/jit/mobile/flatbuffer_loader.h:// If should_copy_tensor_memory is false, then returned module will have tensors
include/torch/csrc/jit/mobile/flatbuffer_loader.h:    bool should_copy_tensor_memory = false);
include/torch/csrc/jit/mobile/flatbuffer_loader.h:    bool should_copy_tensor_memory);
include/torch/csrc/jit/codegen/cuda/executor_kernel_arg.h:  virtual std::unique_ptr<ArgAbstract> copy_unique_ptr() const = 0;
include/torch/csrc/jit/codegen/cuda/executor_kernel_arg.h:  std::unique_ptr<ArgAbstract> copy_unique_ptr() const override { \
include/torch/csrc/lazy/core/shape_inference.h:TORCH_API std::vector<torch::lazy::Shape> compute_shape_narrow_copy_symint(const at::Tensor & self, int64_t dim, int64_t start, c10::SymInt length);
include/torch/csrc/lazy/core/tensor_impl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/torch/csrc/lazy/core/tensor_impl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/torch/csrc/lazy/core/tensor_impl.h:  void shallow_copy_from(const c10::intrusive_ptr<TensorImpl>& impl) override;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector _reshape_alias_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(_reshape_alias_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return _reshape_alias_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector alias_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(alias_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return alias_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector as_strided_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(as_strided_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return as_strided_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector detach_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(detach_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return detach_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector diagonal_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(diagonal_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return diagonal_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector expand_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(expand_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return expand_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector permute_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(permute_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return permute_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector select_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(select_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return select_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector slice_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(slice_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return slice_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector squeeze_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(squeeze_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return squeeze_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector squeeze_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(squeeze_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return squeeze_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector squeeze_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(squeeze_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return squeeze_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector t_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(t_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return t_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector transpose_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(transpose_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return transpose_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector unfold_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(unfold_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return unfold_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector unsqueeze_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(unsqueeze_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return unsqueeze_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector view_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(view_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return view_copy_out;
include/torch/csrc/lazy/generated/LazyIr.h:    torch::lazy::TSOpVector view_copy_out = torch::lazy::LowerTSBuiltin(function, op().op, arguments, kwarguments);
include/torch/csrc/lazy/generated/LazyIr.h:    TORCH_CHECK_EQ(view_copy_out.size(), 1);
include/torch/csrc/lazy/generated/LazyIr.h:    return view_copy_out;
include/torch/csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor _copy_from(const at::Tensor & self, const at::Tensor & dst, bool non_blocking);
include/torch/csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor _copy_from_and_resize(const at::Tensor & self, const at::Tensor & dst);
include/torch/csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor _reshape_alias_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride);
include/torch/csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor as_strided_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, c10::optional<c10::SymInt> storage_offset);
include/torch/csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor expand_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size, bool implicit);
include/torch/csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor narrow_copy_symint(const at::Tensor & self, int64_t dim, c10::SymInt start, c10::SymInt length);
include/torch/csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor slice_copy_symint(const at::Tensor & self, int64_t dim, c10::optional<c10::SymInt> start, c10::optional<c10::SymInt> end, c10::SymInt step);
include/torch/csrc/lazy/generated/LazyNativeFunctions.h:static at::Tensor view_copy_symint(const at::Tensor & self, c10::SymIntArrayRef size);
include/torch/csrc/lazy/ts_backend/tensor_aten_ops.h:void copy_(torch::lazy::LazyTensorPtr& input, torch::lazy::LazyTensorPtr& src);
include/torch/csrc/lazy/ts_backend/ops/to_copy.h:    torch::lazy::TSOpVector _to_copy_out =
include/torch/csrc/lazy/ts_backend/ops/to_copy.h:    TORCH_CHECK_EQ(_to_copy_out.size(), 1);
include/torch/csrc/lazy/ts_backend/ops/to_copy.h:    return _to_copy_out;
include/caffe2/core/scope_guard.h:      std::is_nothrow_copy_constructible<FunctionType>::value)
include/caffe2/core/scope_guard.h:            makeFailsafe(std::is_nothrow_copy_constructible<FunctionType>{},
include/caffe2/core/scope_guard.h:      std::is_nothrow_copy_constructible<FunctionType>::value)
include/caffe2/core/scope_guard.h:            makeFailsafe(std::is_nothrow_copy_constructible<FunctionType>{},
include/caffe2/operators/do_op.h:    copy_external_blobs_ =
include/caffe2/operators/do_op.h:        this->template GetSingleArgument<bool>("copy_external_blobs", false);
include/caffe2/operators/do_op.h:        !(copy_external_blobs_ && reuse_workspace_),
include/caffe2/operators/do_op.h:    if (!is_gradient_op_ && copy_external_blobs_) {
include/caffe2/operators/do_op.h:  bool copy_external_blobs_;
include/caffe2/operators/conv_pool_op_base.h:      std::copy_n(input_dims.cbegin() + offset, ndim, kernel->begin());
include/caffe2/operators/conv_pool_op_base.h:      std::copy_n(input_dims.cbegin() + offset, ndim, kernel->begin());
include/caffe2/operators/inference_lstm_op.h:    w_ih = copy_ctor(_w_ih);
include/caffe2/operators/inference_lstm_op.h:    w_hh = copy_ctor(_w_hh);
include/caffe2/operators/inference_lstm_op.h:    b_ih = copy_ctor(_b_ih);
include/caffe2/operators/inference_lstm_op.h:    b_hh = copy_ctor(_b_hh);
include/caffe2/operators/inference_lstm_op.h:    outputs = copy_ctor(_outputs);
include/caffe2/operators/inference_lstm_op.h:    final_hidden = copy_ctor(_hidden);
include/caffe2/operators/inference_lstm_op.h:    auto hidden = copy_ctor(input_hidden);
include/caffe2/operators/inference_lstm_op.h:      step_outputs.push_back(copy_ctor(std::get<0>(hidden)));
include/caffe2/operators/inference_lstm_op.h:    outputs.push_back(copy_ctor(fw_output));
include/caffe2/operators/inference_lstm_op.h:    outputs.push_back(copy_ctor(rev_output));
include/caffe2/operators/utility_ops.h:    // pointing to the right instantiation. Note that tensor_copy_if_needed
include/caffe2/operators/utility_ops.h:    Tensor tensor_copy_if_needed(CPU);
include/caffe2/operators/utility_ops.h:      tensor_copy_if_needed.CopyFrom(Input(0));
include/caffe2/operators/utility_ops.h:      tensor = &tensor_copy_if_needed;
include/caffe2/operators/batch_matmul_op.h:        std::copy_n(B_dims.cbegin(), B_ndim - 1, Y_dims.begin());
include/caffe2/operators/batch_matmul_op.h:        std::copy_n(B_dims.cbegin(), B_ndim - 2, Y_dims.begin());
include/caffe2/operators/lstm_utils.h:T copy_ctor(const T& x) {
include/caffe2/operators/lstm_utils.h:Tensor copy_ctor(const Tensor& X) {
include/caffe2/operators/lstm_utils.h:t_tuple copy_ctor(const t_tuple& X) {
include/caffe2/operators/lstm_utils.h:  return std::make_tuple(copy_ctor(std::get<0>(X)), copy_ctor(std::get<1>(X)));
include/caffe2/operators/lstm_utils.h:std::pair<t_tuple, t_tuple> copy_ctor(const std::pair<t_tuple, t_tuple>& X) {
include/caffe2/operators/lstm_utils.h:  return std::make_pair(copy_ctor(X.first), copy_ctor(X.second));
include/caffe2/operators/lstm_utils.h:std::vector<Tensor> copy_ctor(const std::vector<Tensor>& X) {
include/caffe2/operators/lstm_utils.h:    return copy_ctor(x);
include/caffe2/operators/lstm_utils.h:std::vector<t_tuple> copy_ctor(const std::vector<t_tuple>& X) {
include/caffe2/operators/lstm_utils.h:    return copy_ctor(x);
include/caffe2/operators/lstm_utils.h:std::vector<std::pair<t_tuple, t_tuple>> copy_ctor(
include/caffe2/operators/lstm_utils.h:        return copy_ctor(x);
include/caffe2/operators/lstm_utils.h:    result.emplace_back(copy_ctor(vals[i]), copy_ctor(vals[i + 1]));
include/caffe2/operators/lstm_utils.h:  auto input_zero = copy_ctor(tensorList.at(0));
include/caffe2/mobile/contrib/ios/mpscnn/mpscnn_kernels.h:kernel void copy_nchw_to_metal(constant float* in[[buffer(0)]],
include/caffe2/mobile/contrib/ios/mpscnn/mpscnn_kernels.h:kernel void copy_nchw_to_metal_nonarray(constant float* in[[buffer(0)]],
include/caffe2/mobile/contrib/ios/mpscnn/mpscnn_kernels.h:kernel void copy_metal_to_nchw(texture2d_array<half, access::read> in[[texture(0)]],
include/caffe2/mobile/contrib/ios/mpscnn/mpscnn_kernels.h:kernel void copy_metal_to_nchw_nonarray(texture2d<half, access::read> in[[texture(0)]],
include/caffe2/mobile/contrib/snpe/snpe_ffi.h:void snpe_copy_output_to(void* ctx, float* outputData);
include/caffe2/quantization/server/conv_dnnlowp_acc16_op.h:  int copy_to_32bit_frequency_;
include/caffe2/quantization/server/fully_connected_dnnlowp_acc16_op.h:  int copy_to_32bit_frequency_;
include/caffe2/quantization/server/batch_permutation_dnnlowp_op.h:#include "caffe2/operators/copy_op.h"
include/caffe2/contrib/fakelowp/batch_matmul_fp16_fake_op.h:        std::copy_n(B_dims.cbegin(), B_ndim - 1, Y_dims.begin());
include/caffe2/contrib/fakelowp/batch_matmul_fp16_fake_op.h:        std::copy_n(B_dims.cbegin(), B_ndim - 2, Y_dims.begin());
include/c10/core/TensorImpl.h:  //     inference_tensor.copy_(normal_tensor_requires_grad)
include/c10/core/TensorImpl.h:  // 1. `var_detached = var.detach()` uses `shallow_copy_and_detach()` to create
include/c10/core/TensorImpl.h:  // 2. `var.set_data(tensor)` uses `shallow_copy_from()` to copy tensor
include/c10/core/TensorImpl.h:  // `shallow_copy_and_detach()` / `shallow_copy_from()` /
include/c10/core/TensorImpl.h:  // `copy_tensor_metadata()`) copy the tensor metadata fields (e.g. sizes /
include/c10/core/TensorImpl.h:  // `shallow_copy_and_detach()` and `copy_tensor_metadata()`), or it is kept
include/c10/core/TensorImpl.h:  // intact (in `shallow_copy_from()`). See NOTE [ Version Counter Sharing ] for
include/c10/core/TensorImpl.h:  // In `shallow_copy_and_detach()` and `copy_tensor_metadata()`, the passed-in
include/c10/core/TensorImpl.h:  // In `shallow_copy_from()`, we don't check the destination TensorImpl's
include/c10/core/TensorImpl.h:  // `allow_tensor_metadata_change_`, because `shallow_copy_from()` is used for
include/c10/core/TensorImpl.h:  inline bool has_compatible_shallow_copy_type(DispatchKeySet from) {
include/c10/core/TensorImpl.h:  c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach_core(
include/c10/core/TensorImpl.h:  virtual c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/c10/core/TensorImpl.h:  virtual c10::intrusive_ptr<TensorImpl> shallow_copy_and_detach(
include/c10/core/TensorImpl.h:  virtual void shallow_copy_from(const c10::intrusive_ptr<TensorImpl>& impl) {
include/c10/core/TensorImpl.h:    copy_tensor_metadata(
include/c10/core/TensorImpl.h:  static void copy_tensor_metadata(
include/c10/core/TensorImpl.h:  static void copy_tensor_metadata(
include/c10/core/TensorImpl.h:  static void copy_tensor_metadata_except_version_counter(
include/c10/core/TensorImpl.h:  static void copy_generic_tensor_metadata(
include/c10/core/TensorImpl.h:  // `copy_tensor_metadata()` in TensorImpl and its subclasses to find
include/c10/core/CopyBytes.h:      g_copy_function)(from, to, __VA_ARGS__);                \
include/c10/util/flat_hash_map.h:            AllocatorTraits::select_on_container_copy_construction(
include/c10/util/flat_hash_map.h:    if (AllocatorTraits::propagate_on_container_copy_assignment::value) {
include/c10/util/flat_hash_map.h:          AllocatorTraits::propagate_on_container_copy_assignment::value>()(
include/c10/util/typeid.h:        copy_(nullptr),
include/c10/util/typeid.h:        copy_(copy),
include/c10/util/typeid.h:  Copy* copy_;
include/c10/util/typeid.h:    std::enable_if_t<std::is_copy_assignable<T>::value>* = nullptr>
include/c10/util/typeid.h:    std::enable_if_t<!std::is_copy_assignable<T>::value>* = nullptr>
include/c10/util/typeid.h:    return data().copy_;
include/c10/util/Optional.h:            // Avoid using is_trivially_copy_{constructible,assignable}
include/c10/util/Optional.h:            std::is_copy_constructible<
include/c10/util/Optional.h:            std::is_copy_assignable<
include/c10/util/Optional.h:              // Avoid using is_trivially_copy_{constructible,assignable}
include/c10/util/Optional.h:              std::is_copy_constructible<
include/c10/util/Optional.h:              std::is_copy_assignable<
include/c10/util/strong_type.h:  struct require_copy_constructible
include/c10/util/strong_type.h:    static constexpr bool value = std::is_copy_constructible<underlying_type_t<T>>::value;
include/c10/util/strong_type.h:  struct require_copy_assignable
include/c10/util/strong_type.h:    static constexpr bool value = std::is_copy_assignable<underlying_type_t<T>>::value;
include/c10/util/strong_type.h:    : valid_type<require_copy_constructible<T>::value &&
include/c10/util/strong_type.h:                 require_copy_assignable<T>::value &&
include/c10/util/string_view.h:    size_type copy_length = std::min(count, size_ - pos);
include/c10/util/string_view.h:    for (auto iter = begin() + pos, end = iter + copy_length; iter != end;) {
include/c10/util/string_view.h:    return copy_length;
include/c10/util/SmallVector.h:    bool = (std::is_trivially_copy_constructible<T>::value) &&
include/c10/util/variant.h:using std::is_trivially_copy_assignable;
include/c10/util/variant.h:using std::is_trivially_copy_constructible;
include/c10/util/variant.h:struct is_trivially_copy_constructible
include/c10/util/variant.h:    : bool_constant<std::is_copy_constructible<T>::value&& __has_trivial_copy(
include/c10/util/variant.h:struct is_trivially_copy_assignable
include/c10/util/variant.h:    : bool_constant<std::is_copy_assignable<T>::value&& __has_trivial_assign(
include/c10/util/variant.h:  static constexpr Trait copy_constructible_trait =
include/c10/util/variant.h:                   lib::is_trivially_copy_constructible,
include/c10/util/variant.h:                   std::is_copy_constructible>()...);
include/c10/util/variant.h:  static constexpr Trait copy_assignable_trait = common_trait(
include/c10/util/variant.h:      copy_constructible_trait,
include/c10/util/variant.h:          lib::is_trivially_copy_assignable,
include/c10/util/variant.h:          std::is_copy_assignable>()...);
include/c10/util/variant.h:template <typename Traits, Trait = Traits::copy_constructible_trait>
include/c10/util/variant.h:class copy_constructor;
include/c10/util/variant.h:    copy_constructible_trait, definition)                           \
include/c10/util/variant.h:  class copy_constructor<traits<Ts...>, copy_constructible_trait>   \
include/c10/util/variant.h:    C10_MPARK_INHERITING_CTOR(copy_constructor, super)              \
include/c10/util/variant.h:    definition copy_constructor(copy_constructor&&) = default;      \
include/c10/util/variant.h:    ~copy_constructor() = default;                                  \
include/c10/util/variant.h:    copy_constructor& operator=(const copy_constructor&) = default; \
include/c10/util/variant.h:    copy_constructor& operator=(copy_constructor&&) = default;      \
include/c10/util/variant.h:    copy_constructor(const copy_constructor& that) = default;);
include/c10/util/variant.h:    Trait::Available, copy_constructor(const copy_constructor& that)
include/c10/util/variant.h:    : copy_constructor(valueless_t{}) {
include/c10/util/variant.h:    Trait::Unavailable, copy_constructor(const copy_constructor&) = delete;);
include/c10/util/variant.h:class assignment : public copy_constructor<Traits> {
include/c10/util/variant.h:  using super = copy_constructor<Traits>;
include/c10/util/variant.h:template <typename Traits, Trait = Traits::copy_assignable_trait>
include/c10/util/variant.h:class copy_assignment;
include/c10/util/variant.h:#define C10_MPARK_VARIANT_COPY_ASSIGNMENT(copy_assignable_trait, definition) \
include/c10/util/variant.h:  class copy_assignment<traits<Ts...>, copy_assignable_trait>                \
include/c10/util/variant.h:    C10_MPARK_INHERITING_CTOR(copy_assignment, super)                        \
include/c10/util/variant.h:    copy_assignment(const copy_assignment&) = default;                       \
include/c10/util/variant.h:    copy_assignment(copy_assignment&&) = default;                            \
include/c10/util/variant.h:    ~copy_assignment() = default;                                            \
include/c10/util/variant.h:    definition copy_assignment& operator=(copy_assignment&&) = default;      \
include/c10/util/variant.h:    copy_assignment& operator=(const copy_assignment& that) = default;);
include/c10/util/variant.h:    copy_assignment&
include/c10/util/variant.h:    operator=(const copy_assignment& that) {
include/c10/util/variant.h:    copy_assignment& operator=(const copy_assignment&) = delete;);
include/c10/util/variant.h:class impl : public copy_assignment<traits<Ts...>> {
include/c10/util/variant.h:  using super = copy_assignment<traits<Ts...>>;
include/c10/util/variant.h:  return std::is_copy_constructible<H>::value &&
include/c10/util/variant.h:      std::is_copy_assignable<H>::value && std::is_move_assignable<H>::value;
include/c10/util/order_preserving_flat_hash_map.h:            AllocatorTraits::select_on_container_copy_construction(
include/c10/util/order_preserving_flat_hash_map.h:    if (AllocatorTraits::propagate_on_container_copy_assignment::value) {
include/c10/util/order_preserving_flat_hash_map.h:          AllocatorTraits::propagate_on_container_copy_assignment::value>()(
_inductor/compile_fx.py:# copy_ fails when trying to write to tensors with memory overlap,
_inductor/compile_fx.py:                    dst.copy_(src)
_inductor/compile_fx.py:        copy_indices = [
_inductor/compile_fx.py:            for idx in copy_indices:
_inductor/compile_fx.py:                dst.copy_(src)
_inductor/overrides.py:        input.copy_(result)
_inductor/codegen/triton.py:        copy_shape=None,
_inductor/codegen/triton.py:            if copy_shape:
_inductor/codegen/triton.py:                index_str = f"{index_str} + tl.zeros({copy_shape}.shape, tl.int32)"
_inductor/codegen/triton.py:        elif not have_loop_vars and copy_shape:
_inductor/codegen/triton.py:            index_str = f"{index_str} + tl.zeros({copy_shape}.shape, tl.int32)"
_inductor/lowering.py:    copy_(output_view, src)
_inductor/lowering.py:@register_lowering(aten.copy_, type_promotion_kind=None)
_inductor/lowering.py:def copy_(dst, src, non_blocking=False):
_inductor/select_algorithm.py:        copy_shape=None,
_inductor/select_algorithm.py:            copy_shape=copy_shape,
_inductor/ir.py:    def copy_input(x):
_inductor/ir.py:        return cls.copy_input(x)
_inductor/ir.py:        return cls.copy_input(x)
_inductor/ir.py:        x = cls.copy_input(x)
_inductor/ir.py:                f"{self.output_view.codegen_reference()}.copy_({args[0]})"
_inductor/ir.py:            wrapper.writeline(f"{self.codegen_reference()}.copy_({args[0]})")
_inductor/decomposition.py:        aten.index_copy_,
_inductor/decomposition.py:    return x.copy_(aten.hardswish(x))
_inductor/decomposition.py:    return x.copy_(aten.hardtanh(x, min_val, max_val))
_inductor/decomposition.py:    return x.copy_(aten.leaky_relu(x, negative_slope))
_inductor/decomposition.py:    return x.copy_(aten.silu(x))
_inductor/decomposition.py:    return self.copy_(torch.rand_like(self, dtype=torch.float32) < p)
jit/_script.py:        def __copy__(self):
jit/_script.py:        def __deepcopy__(self, memo):
Binary file jit/__pycache__/_script.cpython-310.pyc matches
Binary file jit/__pycache__/_recursive.cpython-310.pyc matches
jit/_recursive.py:    torch._jit_internal.copy_torchscript_modifier(unbound_method, lazy_binding_method)
_jit_internal.py:def _copy_to_script_wrapper(fn):
_jit_internal.py:def copy_torchscript_modifier(orig, new) -> None:
_lazy/extract_compiled_graph.py:                arg.copy_(res[i])
Binary file lib/libprotobuf.a matches
Binary file lib/libXNNPACK.a matches
Binary file lib/libtorch_cpu.so matches
Binary file lib/libprotobuf-lite.a matches
Binary file lib/libdnnl.a matches
Binary file lib/libtensorpipe_uv.a matches
Binary file lib/libprotoc.a matches
Binary file lib/libtorch_python.so matches
Binary file lib/libc10.so matches
masked/maskedtensor/_ops_refs.py:@register_dispatch_func([torch.ops.aten.copy_])
masked/maskedtensor/_ops_refs.py:def copy_(func, *args, **kwargs):
_meta_registrations.py:@register_meta(aten.copy_.default)
_meta_registrations.py:def meta_copy_(self, src, non_blocking=False):
_meta_registrations.py:    return out.copy_(torch.index_select(self, dim, index))
_meta_registrations.py:    return out.copy_(torch.angle(self))
_meta_registrations.py:            "aten::copy_",  # Exception not raised, test_torch.py -k test_storage_meta_errors_cpu_int64  # noqa: B950
nn/init.py:        tensor.view_as(q).copy_(q)
nn/parameter.py:    def __deepcopy__(self, memo):
nn/parameter.py:        torch.Tensor.copy_,
nn/parameter.py:        torch._has_compatible_shallow_copy_type,
nn/parameter.py:    def __deepcopy__(self, memo):
Binary file nn/__pycache__/parameter.cpython-310.pyc matches
Binary file nn/__pycache__/init.cpython-310.pyc matches
Binary file nn/utils/__pycache__/parametrize.cpython-310.pyc matches
nn/utils/parametrize.py:        # Just emulate a standard deepcopy procedure when __deepcopy__ doesn't exist in the current class.
nn/utils/parametrize.py:    # Default 'deepcopy' function invokes __deepcopy__ method instead of __getstate__ when it exists.
nn/utils/parametrize.py:    if not hasattr(cls, "__deepcopy__"):
nn/utils/parametrize.py:        dct["__deepcopy__"] = default_deepcopy  # type: ignore[assignment]
nn/modules/_functions.py:            scale_current.copy_(scale_previous)
nn/modules/container.py:from torch._jit_internal import _copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/container.py:    @_copy_to_script_wrapper
nn/modules/adaptive.py:                gather_inds.index_copy_(0, row_indices, target[target_mask])
nn/modules/adaptive.py:                output.index_copy_(0, row_indices, local_logprob.squeeze(1))
nn/modules/module.py:            if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):
nn/modules/module.py:                        param.copy_(input_param)
nn/modules/upsampling.py:        >>> input_3x3[:, :, :2, :2].copy_(input)
Binary file nn/modules/__pycache__/upsampling.cpython-310.pyc matches
Binary file nn/modules/__pycache__/container.cpython-310.pyc matches
Binary file nn/modules/__pycache__/adaptive.cpython-310.pyc matches
Binary file nn/modules/__pycache__/module.cpython-310.pyc matches
Binary file nn/modules/__pycache__/_functions.cpython-310.pyc matches
_ops.py:    def __deepcopy__(self, memo=None):
_ops.py:    def __deepcopy__(self, memo=None):
optim/lbfgs.py:            p.copy_(pdata)
optim/lbfgs.py:                prev_flat_grad.copy_(flat_grad)
optim/adam.py:                max_exp_avg_sqs[i].copy_(torch.maximum(max_exp_avg_sqs_i, exp_avg_sq))
optim/asgd.py:            ax.copy_(param)
optim/asgd.py:        eta.copy_(new_eta)
optim/asgd.py:        mu.copy_(new_mu)
optim/asgd.py:            axs[i].copy_(params[i])
optim/asgd.py:        etas[i].copy_(new_eta)
optim/asgd.py:        mus[i].copy_(new_mu)
Binary file optim/__pycache__/rprop.cpython-310.pyc matches
Binary file optim/__pycache__/adamw.cpython-310.pyc matches
Binary file optim/__pycache__/lbfgs.cpython-310.pyc matches
Binary file optim/__pycache__/asgd.cpython-310.pyc matches
Binary file optim/__pycache__/swa_utils.cpython-310.pyc matches
Binary file optim/__pycache__/adam.cpython-310.pyc matches
Binary file optim/__pycache__/adamax.cpython-310.pyc matches
optim/adamw.py:                max_exp_avg_sqs[i].copy_(torch.maximum(max_exp_avg_sqs_i, exp_avg_sq))
optim/swa_utils.py:                p_swa.detach().copy_(p_model_)
optim/swa_utils.py:                p_swa.detach().copy_(self.avg_fn(p_swa.detach(), p_model_,
optim/swa_utils.py:                b_swa.detach().copy_(b_model.detach().to(device))
optim/rprop.py:        prev.copy_(grad)
optim/rprop.py:        prevs[i].copy_(grads[i])
optim/adamax.py:            exp_inf.copy_(torch.amax(norm_buf, 0, keepdim=False))
overrides.py:        Tensor.__deepcopy__: lambda self, memo: -1,
overrides.py:        Tensor.copy_: lambda self, src, non_blocking=False: -1,
package/_mock.py:    "__copy__",
package/_mock.py:    "__deepcopy__",
Binary file _prims/__pycache__/__init__.cpython-310.pyc matches
_prims/context.py:        torch.Tensor.copy_: torch._prims.copy_to,
_prims/__init__.py:    "copy_to",
_prims/__init__.py:    ``out.as_strided(size, stride, storage_offset).copy_(src)``.
_prims/__init__.py:        return copy_to(result, a)
_prims/__init__.py:def _copy_to_meta(a: TensorLikeType, b: TensorLikeType):
_prims/__init__.py:def _copy_to_aten(a: Tensor, b: Tensor) -> Tensor:
_prims/__init__.py:    return a.copy_(b)
_prims/__init__.py:_copy_to_doc = """
_prims/__init__.py:copy_to = _make_prim(
_prims/__init__.py:    schema="copy_to(Tensor(a!) a, Tensor b) -> Tensor(a!)",
_prims/__init__.py:    meta=_copy_to_meta,
_prims/__init__.py:    impl_aten=_copy_to_aten,
_prims/__init__.py:    doc=_copy_to_doc,
Binary file _prims_common/__pycache__/wrappers.cpython-310.pyc matches
_prims_common/wrappers.py:def _safe_copy_out(
_prims_common/wrappers.py:    *, copy_from: TensorLikeType, copy_to: TensorLikeType, exact_dtype: bool = False
_prims_common/wrappers.py:    if copy_from.device != copy_to.device:
_prims_common/wrappers.py:            copy_from.device, copy_to.device
_prims_common/wrappers.py:            copy_from.dtype == copy_to.dtype,
_prims_common/wrappers.py:            lambda: f"Expected out tensor to have dtype {copy_from.dtype} "
_prims_common/wrappers.py:            f"but got {copy_to.dtype} instead",
_prims_common/wrappers.py:            utils.can_safe_cast_to(cast_from=copy_from.dtype, cast_to=copy_to.dtype),
_prims_common/wrappers.py:            lambda: f"Attempting to cast from {copy_from.dtype} to out tensor with dtype {copy_to.dtype}, "
_prims_common/wrappers.py:    return copy_to.copy_(copy_from)
_prims_common/wrappers.py:                    _safe_copy_out(copy_from=result, copy_to=out, exact_dtype=exact_dtype)  # type: ignore[arg-type]
_prims_common/wrappers.py:                        _safe_copy_out(copy_from=r, copy_to=o, exact_dtype=exact_dtype)  # type: ignore[arg-type]
_prims_common/wrappers.py:            # TODO: There is a subtle bug here: prims like copy_to
profiler/_pattern_matcher.py:        if event.name != "aten::copy_":
profiler/_pattern_matcher.py:        # aten::copy_ should have the first 2 args dtype the same
Binary file __pycache__/_tensor.cpython-310.pyc matches
Binary file __pycache__/_utils.cpython-310.pyc matches
Binary file __pycache__/quasirandom.cpython-310.pyc matches
Binary file __pycache__/_utils.cpython-38.pyc matches
Binary file __pycache__/overrides.cpython-310.pyc matches
Binary file __pycache__/_jit_internal.cpython-310.pyc matches
Binary file __pycache__/storage.cpython-310.pyc matches
Binary file __pycache__/functional.cpython-310.pyc matches
Binary file __pycache__/_ops.cpython-310.pyc matches
Binary file __pycache__/_tensor_docs.cpython-310.pyc matches
Binary file __pycache__/_guards.cpython-310.pyc matches
Binary file __pycache__/_meta_registrations.cpython-310.pyc matches
Binary file __pycache__/types.cpython-310.pyc matches
quasirandom.py:            out.resize_as_(result).copy_(result)
quasirandom.py:        self.quasi.copy_(self.shift)
Binary file _refs/__pycache__/__init__.cpython-310.pyc matches
_refs/__init__.py:    _safe_copy_out,
_refs/__init__.py:    "index_copy_",
_refs/__init__.py:    "copy_to",  # TODO: add OpInfo (or implement .to)
_refs/__init__.py:    prims.copy_to(a, r)
_refs/__init__.py:    prims.copy_to(a, r)
_refs/__init__.py:def copy_to(a: Tensor, b: Tensor, *, allow_cross_device=True):
_refs/__init__.py:    return prims.copy_to(a, b)
_refs/__init__.py:    # TODO: non_blocking should be handled by `copy_to`
_refs/__init__.py:    copy_to(result, a)
_refs/__init__.py:        return _safe_copy_out(copy_from=result, copy_to=out)  # type: ignore[arg-type]
_refs/__init__.py:def _make_copy_from_view(fn):
_refs/__init__.py:    copy_name = f"{name}_copy"
_refs/__init__.py:    _fn.__name__ = copy_name
_refs/__init__.py:    _fn = register_decomposition(getattr(aten, copy_name))(_fn)
_refs/__init__.py:        return _safe_copy_out(copy_from=result, copy_to=out)  # type: ignore[arg-type]
_refs/__init__.py:    prims.copy_to(c_output, c_input)
_refs/__init__.py:# no sparse support. See narrow_copy_sparse in core.
_refs/__init__.py:narrow_copy = _make_copy_from_view(narrow)
_refs/__init__.py:    return x.clone(memory_format=torch.contiguous_format).index_copy_(
_refs/__init__.py:def index_copy_(x: TensorLike, dim: int, index: TensorLike, tensor: TensorLike):
_refs/__init__.py:    index_copy = Tensor.index_copy_ if inplace else torch.index_copy
_refs/__init__.py:            new_out.copy_(out)
_refs/__init__.py:    copy_to(diag, src)
_refs/__init__.py:diagonal_copy = _make_copy_from_view(diagonal)
_refs/__init__.py:    a.copy_(b)
share/cmake/Caffe2/Modules_CUDA_fix/upstream/FindCUDA/run_nvcc.cmake:  COMMAND "${CMAKE_COMMAND}" -E copy_if_different "${cmake_dependency_file}.tmp" "${cmake_dependency_file}"
share/ATen/Declarations.yaml:- name: copy_
share/ATen/Declarations.yaml:  operator_name: copy_
share/ATen/Declarations.yaml:  schema_string: aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)
share/ATen/Declarations.yaml:- name: _copy_from
share/ATen/Declarations.yaml:  operator_name: _copy_from
share/ATen/Declarations.yaml:  schema_string: aten::_copy_from(Tensor self, Tensor dst, bool non_blocking=False) -> Tensor
share/ATen/Declarations.yaml:- name: _copy_from_and_resize
share/ATen/Declarations.yaml:  operator_name: _copy_from_and_resize
share/ATen/Declarations.yaml:  schema_string: aten::_copy_from_and_resize(Tensor self, Tensor dst) -> Tensor
share/ATen/Declarations.yaml:- name: index_copy_out
share/ATen/Declarations.yaml:- name: index_copy_
share/ATen/Declarations.yaml:  operator_name: index_copy_
share/ATen/Declarations.yaml:  schema_string: aten::index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -> Tensor(a!)
share/ATen/Declarations.yaml:- name: index_copy_
share/ATen/Declarations.yaml:  operator_name: index_copy_
share/ATen/Declarations.yaml:  schema_string: aten::index_copy_.dimname(Tensor(a!) self, Dimname dim, Tensor index, Tensor source) -> Tensor(a!)
share/ATen/Declarations.yaml:- name: narrow_copy_out
share/ATen/Declarations.yaml:- name: _has_compatible_shallow_copy_type
share/ATen/Declarations.yaml:  operator_name: _has_compatible_shallow_copy_type
share/ATen/Declarations.yaml:  schema_string: aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -> bool
share/ATen/Declarations.yaml:- name: copy_sparse_to_sparse_
share/ATen/Declarations.yaml:  operator_name: copy_sparse_to_sparse_
share/ATen/Declarations.yaml:  schema_string: aten::copy_sparse_to_sparse_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)
share/ATen/Declarations.yaml:- name: _fw_primal_copy_out
share/ATen/Declarations.yaml:- name: _make_dual_copy_out
share/ATen/Declarations.yaml:- name: view_as_real_copy_out
share/ATen/Declarations.yaml:- name: view_as_complex_copy_out
share/ATen/Declarations.yaml:- name: _conj_copy_out
share/ATen/Declarations.yaml:- name: _neg_view_copy_out
share/ATen/Declarations.yaml:- name: as_strided_copy_out
share/ATen/Declarations.yaml:- name: _sparse_broadcast_to_copy_out
share/ATen/Declarations.yaml:- name: diagonal_copy_out
share/ATen/Declarations.yaml:- name: expand_copy_out
share/ATen/Declarations.yaml:- name: permute_copy_out
share/ATen/Declarations.yaml:- name: _reshape_alias_copy_out
share/ATen/Declarations.yaml:- name: select_copy_out
share/ATen/Declarations.yaml:- name: detach_copy_out
share/ATen/Declarations.yaml:- name: slice_copy_out
share/ATen/Declarations.yaml:- name: split_copy_out
share/ATen/Declarations.yaml:- name: split_with_sizes_copy_out
share/ATen/Declarations.yaml:- name: squeeze_copy_out
share/ATen/Declarations.yaml:- name: squeeze_copy_out
share/ATen/Declarations.yaml:- name: squeeze_copy_out
share/ATen/Declarations.yaml:- name: t_copy_out
share/ATen/Declarations.yaml:- name: transpose_copy_out
share/ATen/Declarations.yaml:- name: unsqueeze_copy_out
share/ATen/Declarations.yaml:- name: _indices_copy_out
share/ATen/Declarations.yaml:- name: _values_copy_out
share/ATen/Declarations.yaml:- name: indices_copy_out
share/ATen/Declarations.yaml:- name: values_copy_out
share/ATen/Declarations.yaml:- name: crow_indices_copy_out
share/ATen/Declarations.yaml:- name: col_indices_copy_out
share/ATen/Declarations.yaml:- name: unbind_copy_out
share/ATen/Declarations.yaml:- name: view_copy_out
share/ATen/Declarations.yaml:- name: view_copy_out
share/ATen/Declarations.yaml:- name: unfold_copy_out
share/ATen/Declarations.yaml:- name: alias_copy_out
share/ATen/Declarations.yaml:- name: copy_out
share/ATen/Declarations.yaml:- name: _copy_from_out
share/ATen/Declarations.yaml:  operator_name: _copy_from
share/ATen/Declarations.yaml:  schema_string: aten::_copy_from.out(Tensor self, Tensor dst, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)
share/ATen/Declarations.yaml:- name: _copy_from_and_resize_out
share/ATen/Declarations.yaml:  operator_name: _copy_from_and_resize
share/ATen/Declarations.yaml:  schema_string: aten::_copy_from_and_resize.out(Tensor self, Tensor dst, *, Tensor(a!) out) -> Tensor(a!)
share/ATen/Declarations.yaml:- name: _nested_view_from_buffer_copy_out
share/ATen/Declarations.yaml:- name: copy_sparse_to_sparse_out
share/ATen/Declarations.yaml:  operator_name: copy_sparse_to_sparse
share/ATen/Declarations.yaml:  schema_string: aten::copy_sparse_to_sparse.out(Tensor self, Tensor src, bool non_blocking=False, *, Tensor(a!) out) -> Tensor(a!)
share/ATen/Declarations.yaml:- name: copy_sparse_to_sparse
share/ATen/Declarations.yaml:  operator_name: copy_sparse_to_sparse
share/ATen/Declarations.yaml:  schema_string: aten::copy_sparse_to_sparse(Tensor self, Tensor src, bool non_blocking=False) -> Tensor
share/ATen/Declarations.yaml:- name: _to_copy_out
share/ATen/Declarations.yaml:- name: lift_fresh_copy_out
share/ATen/Declarations.yaml:- name: _test_autograd_multiple_dispatch_view_copy_out
share/ATen/Declarations.yaml:- name: ccol_indices_copy_out
share/ATen/Declarations.yaml:- name: row_indices_copy_out
storage.py:    def copy_(self, source: T, non_blocking: bool = None) -> T: ...  # noqa: E704
storage.py:    def __copy__(self):
storage.py:    def __deepcopy__(self, memo):
storage.py:        return type(self)(self.nbytes(), device=self.device).copy_(self)
storage.py:            return torch.UntypedStorage(self.size()).copy_(self, False)
storage.py:            return torch.UntypedStorage(self.size(), device="mps").copy_(self, False)
storage.py:        return type(self)(self.size(), allocator=allocator).copy_(self)
storage.py:    def copy_(self, source: T, non_blocking: bool = None):
storage.py:            self._untyped_storage.copy_(source._untyped_storage, non_blocking)
storage.py:            self._untyped_storage.copy_(source, non_blocking)
storage.py:    def __copy__(self):
storage.py:    def __deepcopy__(self, memo):
Binary file _subclasses/__pycache__/fake_tensor.cpython-310.pyc matches
_subclasses/fake_tensor.py:        elif func == torch.Tensor.__deepcopy__:
_tensor_docs.py:    "copy_",
_tensor_docs.py:copy_(src, non_blocking=False) -> Tensor
_tensor_docs.py:    "index_copy_",
_tensor_docs.py:index_copy_(dim, index, tensor) -> Tensor
_tensor_docs.py:    >>> x.index_copy_(0, index, t)
_tensor_docs.py:Out-of-place version of :meth:`torch.Tensor.index_copy_`.
_tensor.py:    def __deepcopy__(self, memo):
_tensor.py:            return handle_torch_function(Tensor.__deepcopy__, (self,), self, memo)
_tensor.py:                        "The default implementation of __deepcopy__() for wrapper subclasses "
_tensor.py:                        "properly implement clone() for your subclass or override __deepcopy__() "
_tensor.py:                            "The default implementation of __deepcopy__() for quantized tensors "
_tensor.py:                            "The default implementation of __deepcopy__() for non-wrapper subclasses "
_tensor.py:                            "__deepcopy__() if it is intended behavior for new_empty() to return "
_tensor.py:                new_tensor.grad = self.grad.__deepcopy__(memo)
_tensor.py:      In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the
Binary file test/c10_ordered_preserving_dict_test matches
Binary file test/pow_test matches
Binary file test/undefined_tensor_test matches
Binary file test/c10_string_view_test matches
Binary file test/c10_Metaprogramming_test matches
Binary file test/basic matches
Binary file test/backend_fallback_test matches
testing/_internal/common_utils.py:        return obj.new().resize_(obj.size()).copy_(obj)
testing/_internal/common_utils.py:            #        needed for inplace operations done on `x`, e.g., copy_().
testing/_internal/common_utils.py:            r = tmp[dim_slices].copy_(t)
testing/_internal/common_utils.py:def copy_func(f):
testing/_internal/common_utils.py:            setattr(cls, t, unittest.expectedFailure(copy_func(getattr(cls, t))))
testing/_internal/common_modules.py:            def copy_reference_fn(m, *args, **kwargs):
testing/_internal/common_modules.py:            self.reference_fn = copy_reference_fn
testing/_internal/opinfo/core.py:        lhs_non_contig.copy_(lhs)
testing/_internal/opinfo/core.py:        rhs_non_contig.copy_(rhs)
testing/_internal/opinfo/definitions/linalg.py:        # linalg.solve_triangular cannot be batched over because of a call to out.copy_(result);
testing/_internal/generated/annotated_fn_args.py:    torch._C._VariableFunctions._copy_from: [{'name': 'self', 'simple_type': 'Tensor'}, {'name': 'dst', 'simple_type': 'Tensor'}],
testing/_internal/generated/annotated_fn_args.py:    torch._C._VariableFunctions._copy_from_and_resize: [{'name': 'self', 'simple_type': 'Tensor'}, {'name': 'dst', 'simple_type': 'Tensor'}],
testing/_internal/generated/annotated_fn_args.py:    torch._C._VariableFunctions._has_compatible_shallow_copy_type: [{'name': 'self', 'simple_type': 'Tensor'}, {'name': 'from', 'simple_type': 'Tensor'}],
testing/_internal/generated/annotated_fn_args.py:    torch.Tensor.index_copy_: [{'name': 'self', 'simple_type': 'Tensor'}, {'name': 'dim', 'simple_type': 'int64_t'}, {'name': 'index', 'simple_type': 'Tensor'}, {'name': 'source', 'simple_type': 'Tensor'}],
testing/_internal/generated/annotated_fn_args.py:    torch.Tensor.index_copy_: [{'name': 'self', 'simple_type': 'Tensor'}, {'name': 'dim', 'simple_type': 'Dimname'}, {'name': 'index', 'simple_type': 'Tensor'}, {'name': 'source', 'simple_type': 'Tensor'}],
testing/_internal/distributed/multi_threaded_pg.py:                data[src_rank][0].copy_(res)
testing/_internal/distributed/multi_threaded_pg.py:                    dest_tensor.copy_(src_tensor)
testing/_internal/distributed/multi_threaded_pg.py:                dest_tensor.copy_(src_in_tensors[rank])
testing/_internal/distributed/multi_threaded_pg.py:                        dest_tensor_on_rank_i[0].copy_(to_scatter[i])
testing/_internal/distributed/multi_threaded_pg.py:                    out_tensor_list[j].copy_(in_tensor_list[j])
testing/_internal/distributed/rpc/rpc_test.py:            tensor1.copy_(t0, non_blocking=True)
testing/_internal/distributed/rpc/dist_autograd_test.py:    def test_no_grad_copy_sparse(self):
testing/_internal/distributed/rpc/dist_autograd_test.py:    def test_grad_copy_sparse_indices_extra_ref(self):
testing/_internal/common_methods_invocations.py:        # narrow_copy_dense_cpu_out
testing/_internal/common_methods_invocations.py:        # narrow_copy_dense_cpu_out
testing/_internal/common_methods_invocations.py:        # narrow_copy_dense_cpu_out
testing/_internal/common_methods_invocations.py:               # TypeError: _copy_dispatcher() got an unexpected keyword argument 'memory_format'
testing/_internal/common_methods_invocations.py:           # Needs to construct a 2nx2n matrix by copy_ ing into it
testing/_internal/common_methods_invocations.py:           # Relies on copy_ to broadcast, but the forward AD path calls broadcast_to which
testing/_internal/common_methods_invocations.py:           # Relies on copy_ to broadcast, but the forward AD path calls broadcast_to which
testing/_internal/common_methods_invocations.py:        index.select(index_dim, i).copy_(
testing/_internal/common_methods_invocations.py:        index.select(batch_dim, 0).copy_(index.select(batch_dim, 1))
testing/_internal/common_subclass.py:            if func is torch.Tensor.__deepcopy__:
testing/_internal/common_nn.py:            gpu_p.data.copy_(cpu_p)
testing/_internal/composite_compliance.py:                tmp.copy_(elem.detach())
types.py:    def __deepcopy__(self, memo) -> 'Storage':
utils/weak.py:    __copy__ = copy
utils/weak.py:    def __deepcopy__(self, memo):
utils/data/datapipes/dataframe/dataframes.py:UNIMPLEMENTED_ATTR = ['__deepcopy__', '__setstate__', 'is_shardable', 'apply_sharding']
utils/data/datapipes/dataframe/dataframes.py:        if attrname in ['__deepcopy__']:
Binary file utils/data/datapipes/dataframe/__pycache__/dataframes.cpython-310.pyc matches
utils/hipify/cuda_to_hip_mappings.py:            ("rocblas_scopy_batched", CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED),
utils/hipify/cuda_to_hip_mappings.py:            ("rocblas_dcopy_batched", CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED),
utils/hipify/cuda_to_hip_mappings.py:        ("cublasScopy_v2", ("rocblas_scopy", CONV_MATH_FUNC, API_BLAS)),
utils/hipify/cuda_to_hip_mappings.py:        ("cublasDcopy_v2", ("rocblas_dcopy", CONV_MATH_FUNC, API_BLAS)),
utils/hipify/cuda_to_hip_mappings.py:            "cublasCcopy_v2",
utils/hipify/cuda_to_hip_mappings.py:            "cublasZcopy_v2",
Binary file utils/__pycache__/weak.cpython-310.pyc matches
_utils.py:    return dtype(self.size()).copy_(self, non_blocking)
_utils.py:            untyped_storage.copy_(self, non_blocking)
_VF.pyi:def _copy_from(input: Tensor, dst: Tensor, non_blocking: _bool=False) -> Tensor: ...
_VF.pyi:def _copy_from_and_resize(input: Tensor, dst: Tensor) -> Tensor: ...
_VF.pyi:def _has_compatible_shallow_copy_type(input: Tensor, from_: Tensor) -> _bool: ...
_VF.pyi: '_convolution_mode', '_copy_from', '_copy_from_and_resize', '_ctc_loss', '_cudnn_ctc_loss',
_VF.pyi: '_fw_primal_copy', '_grid_sampler_2d_cpu_fallback', '_has_compatible_shallow_copy_type',
